{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "import random  \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed_num = 42\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        #---------------수정---------------\n",
    "        if sample_weight is not None:\n",
    "            print('sample weight : ', sample_weight)\n",
    "            if sample_weight[0] == 0.00016175994823681658:\n",
    "                print('x, y', x.shape, x.sum().sum())\n",
    "                return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "            weights = sample_weight / sum(sample_weight)\n",
    "            random_range = [(sum(weights[:i]), sum(weights[:i])+weights[i]) if i!=0 else (0, weights[i]) for i in range(len(weights))]\n",
    "            random_nums = [random.random() for _ in range(len(weights))]\n",
    "            idx_list = []\n",
    "            for i in random_nums:\n",
    "                for j in random_range:\n",
    "                    if j[0] < i <= j[1]:\n",
    "                        idx_list.append(random_range.index(j))\n",
    "                        break\n",
    "            new_x = x[idx_list, :, :]\n",
    "            new_y = y[idx_list]\n",
    "            print(new_x.sum().sum())\n",
    "            print('new_x, new_y', new_x.shape, new_y.shape)\n",
    "            return super(MyKerasClassifier, self).fit(new_x, new_y, **kwargs)\n",
    "        \n",
    "    def predict(self, x, **kwargs):\n",
    "        return super(MyKerasClassifier, self).predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "import random  \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed_num = 42\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import random\n",
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, validation_split=0.25, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        #---------------수정---------------\n",
    "        if sample_weight is not None:\n",
    "            print('sample weight : ', sample_weight)\n",
    "            if sample_weight[0] == 0.00016175994823681658:\n",
    "                print('x, y', x.shape, x.sum().sum())\n",
    "                return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "            print('x sum', x.sum().sum())\n",
    "            \n",
    "            idx = np.arange(len(x))\n",
    "            random.shuffle(idx)\n",
    "            i = int(len(x)*0.75)\n",
    "            train_x, train_y = x[idx[:i],:,:], y[idx[:i]]\n",
    "            val_x, val_y = x[idx[i:],:,:], y[idx[i:]]\n",
    "            \n",
    "            \n",
    "            train_sw, val_sw = sample_weight[idx[:i]], sample_weight[idx[i:]]\n",
    "            train_sw, val_sw = train_sw/sum(train_sw)*len(train_sw), val_sw/sum(val_sw)*len(val_sw)\n",
    "            \n",
    "            weights = val_sw / sum(val_sw)\n",
    "            random_range = [(sum(weights[:i]), sum(weights[:i])+weights[i]) if i!=0 else (0, weights[i]) for i in range(len(weights))]\n",
    "            random_nums = [random.random() for _ in range(len(weights))]\n",
    "            idx_list = []\n",
    "            for i in random_nums:\n",
    "                for j in random_range:\n",
    "                    if j[0] < i <= j[1]:\n",
    "                        idx_list.append(random_range.index(j))\n",
    "                        break\n",
    "            new_val_x = val_x[idx_list, :, :]\n",
    "            new_val_y = val_y[idx_list]\n",
    "            \n",
    "            kwargs['validation_data'] = (new_val_x, new_val_y)\n",
    "            kwargs['sample_weight'] = train_sw\n",
    "            return super(MyKerasClassifier, self).fit(train_x, train_y, **kwargs)\n",
    "        \n",
    "        return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, x, **kwargs):\n",
    "        return super(MyKerasClassifier, self).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6182, 10, 4068)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7267, 6914,  990, ..., 2575, 3450, 1696])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(7727)\n",
    "random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single LSTM Start\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/50\n",
      "37/37 [==============================] - 6s 81ms/step - loss: 0.6736 - acc: 0.6055 - val_loss: 0.6657 - val_acc: 0.6177\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.6696 - acc: 0.6100 - val_loss: 0.6509 - val_acc: 0.6177\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.6045 - acc: 0.6706 - val_loss: 0.5288 - val_acc: 0.7510\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.4900 - acc: 0.7821 - val_loss: 0.4942 - val_acc: 0.7639\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.4187 - acc: 0.8261 - val_loss: 0.4894 - val_acc: 0.7743\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.3760 - acc: 0.8503 - val_loss: 0.5036 - val_acc: 0.7743\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.3591 - acc: 0.8613 - val_loss: 0.5329 - val_acc: 0.7587\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.3100 - acc: 0.8865 - val_loss: 0.5534 - val_acc: 0.7762\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2800 - acc: 0.8999 - val_loss: 0.6007 - val_acc: 0.7684\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.2586 - acc: 0.9109 - val_loss: 0.6084 - val_acc: 0.7600\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.2435 - acc: 0.9176 - val_loss: 0.6325 - val_acc: 0.7542\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 0.2243 - acc: 0.9247 - val_loss: 0.6608 - val_acc: 0.7477\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2028 - acc: 0.9359 - val_loss: 0.6891 - val_acc: 0.7561\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.1863 - acc: 0.9439 - val_loss: 0.7386 - val_acc: 0.7529\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1758 - acc: 0.9487Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.1758 - acc: 0.9487 - val_loss: 0.7440 - val_acc: 0.7406\n",
      "Epoch 00015: early stopping\n",
      "accuracy : 0.7618122977346279, precision : 0.8083700440528634, recall : 0.790948275862069, f1 : 0.7995642701525053, roc_auc : 0.7544692756944056\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    print(\"Single LSTM Start\")\n",
    "    model = get_model()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    cb_checkpoint = ModelCheckpoint(filepath='./models/single_lstm.h5', monitor='val_loss',\n",
    "                                    verbose=1, save_best_only=True)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.25, callbacks=[early_stop, cb_checkpoint])\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds>0.5]=1\n",
    "    preds[preds<=0.5]=0\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f'accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost LSTM Start\n",
      "sample weight :  [0.00016176 0.00016176 0.00016176 ... 0.00016176 0.00016176 0.00016176]\n",
      "x, y (6182, 10, 4068) 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 5s 538ms/step - loss: 0.6814 - acc: 0.6104 - val_loss: 0.6666 - val_acc: 0.6177\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6782 - acc: 0.6091 - val_loss: 0.6652 - val_acc: 0.6177\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6753 - acc: 0.6061 - val_loss: 0.6658 - val_acc: 0.6177\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6721 - acc: 0.6025 - val_loss: 0.6665 - val_acc: 0.6177\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6741 - acc: 0.6033 - val_loss: 0.6661 - val_acc: 0.6177\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6744 - acc: 0.6040 - val_loss: 0.6654 - val_acc: 0.6177\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6745 - acc: 0.6025 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6716 - acc: 0.6100 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6735 - acc: 0.6087 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6725 - acc: 0.6091 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 1s 803ms/step - loss: 0.6734 - acc: 0.6089 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6724 - acc: 0.6085 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6737 - acc: 0.6076 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6717 - acc: 0.6096 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6715 - acc: 0.6085 - val_loss: 0.6648 - val_acc: 0.6177\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6681 - acc: 0.6117 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6730 - acc: 0.6107 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6715 - acc: 0.6096 - val_loss: 0.6645 - val_acc: 0.6177\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6701 - acc: 0.6122 - val_loss: 0.6644 - val_acc: 0.6177\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6684 - acc: 0.6132 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6696 - acc: 0.6100 - val_loss: 0.6648 - val_acc: 0.6177\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6689 - acc: 0.6096 - val_loss: 0.6639 - val_acc: 0.6177\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6679 - acc: 0.6109 - val_loss: 0.6625 - val_acc: 0.6177\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6688 - acc: 0.6094 - val_loss: 0.6612 - val_acc: 0.6177\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6666 - acc: 0.6113 - val_loss: 0.6595 - val_acc: 0.6177\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6647 - acc: 0.6111 - val_loss: 0.6575 - val_acc: 0.6177\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6624 - acc: 0.6124 - val_loss: 0.6545 - val_acc: 0.6177\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6591 - acc: 0.6113 - val_loss: 0.6504 - val_acc: 0.6177\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6566 - acc: 0.6119 - val_loss: 0.6456 - val_acc: 0.6177\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6498 - acc: 0.6128 - val_loss: 0.6399 - val_acc: 0.6177\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6423 - acc: 0.6201 - val_loss: 0.6324 - val_acc: 0.6177\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6346 - acc: 0.6277 - val_loss: 0.6236 - val_acc: 0.6177\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6231 - acc: 0.6324 - val_loss: 0.6130 - val_acc: 0.6184\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6117 - acc: 0.6644 - val_loss: 0.6016 - val_acc: 0.6902\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6004 - acc: 0.6808 - val_loss: 0.5871 - val_acc: 0.7147\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5871 - acc: 0.6963 - val_loss: 0.5731 - val_acc: 0.7257\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.5677 - acc: 0.7274 - val_loss: 0.5648 - val_acc: 0.7160\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.5512 - acc: 0.7394 - val_loss: 0.5448 - val_acc: 0.7400\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.5337 - acc: 0.7554 - val_loss: 0.5320 - val_acc: 0.7413\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.5137 - acc: 0.7733 - val_loss: 0.5384 - val_acc: 0.7387\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5077 - acc: 0.7757 - val_loss: 0.5187 - val_acc: 0.7458\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.4907 - acc: 0.7841 - val_loss: 0.5111 - val_acc: 0.7561\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.4755 - acc: 0.7979 - val_loss: 0.5103 - val_acc: 0.7536\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.4649 - acc: 0.8024 - val_loss: 0.5031 - val_acc: 0.7626\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.4515 - acc: 0.8130 - val_loss: 0.5054 - val_acc: 0.7561\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.4400 - acc: 0.8156 - val_loss: 0.5017 - val_acc: 0.7587\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.4278 - acc: 0.8242 - val_loss: 0.5055 - val_acc: 0.7633\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.4193 - acc: 0.8292 - val_loss: 0.5016 - val_acc: 0.7633\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.4114 - acc: 0.8376 - val_loss: 0.5025 - val_acc: 0.7639\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.3978 - acc: 0.8419 - val_loss: 0.5057 - val_acc: 0.7665\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.3904 - acc: 0.8443 - val_loss: 0.5172 - val_acc: 0.7678\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3871 - acc: 0.8471 - val_loss: 0.5111 - val_acc: 0.7691\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3761 - acc: 0.8572 - val_loss: 0.5256 - val_acc: 0.7704\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.3718 - acc: 0.8598 - val_loss: 0.5332 - val_acc: 0.7600\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.3822 - acc: 0.8436 - val_loss: 0.5463 - val_acc: 0.7710\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.3717 - acc: 0.8553 - val_loss: 0.5244 - val_acc: 0.7594\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 135ms/step - loss: 0.3527 - acc: 0.8654 - val_loss: 0.5245 - val_acc: 0.7671\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.3355 - acc: 0.8773 - val_loss: 0.5448 - val_acc: 0.7691\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.3444 - acc: 0.8708 - val_loss: 0.5369 - val_acc: 0.7574\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.3426 - acc: 0.8717 - val_loss: 0.5372 - val_acc: 0.7652\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3239 - acc: 0.8857 - val_loss: 0.5394 - val_acc: 0.7678\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.3149 - acc: 0.8889 - val_loss: 0.5398 - val_acc: 0.7639\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.3164 - acc: 0.8874 - val_loss: 0.5596 - val_acc: 0.7613\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.3104 - acc: 0.8900 - val_loss: 0.5506 - val_acc: 0.7587\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2988 - acc: 0.8973 - val_loss: 0.5600 - val_acc: 0.7607\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.3015 - acc: 0.8984 - val_loss: 0.5781 - val_acc: 0.7665\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.2982 - acc: 0.8954 - val_loss: 0.5687 - val_acc: 0.7633\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2812 - acc: 0.9068 - val_loss: 0.5734 - val_acc: 0.7626\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2789 - acc: 0.9094 - val_loss: 0.5768 - val_acc: 0.7633\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.2742 - acc: 0.9094 - val_loss: 0.5818 - val_acc: 0.7652\n",
      "sample weight :  [1.66481641e-04 5.93050406e-05 2.96461784e-05 ... 3.53268485e-05\n",
      " 2.85590339e-05 4.64938440e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7070 - acc: 0.4757 - val_loss: 0.6709 - val_acc: 0.3814\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6908 - acc: 0.4754 - val_loss: 0.6723 - val_acc: 0.3814\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6966 - acc: 0.4202 - val_loss: 0.6760 - val_acc: 0.3814\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6883 - acc: 0.4101 - val_loss: 0.6813 - val_acc: 0.3814\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6885 - acc: 0.4044 - val_loss: 0.6864 - val_acc: 0.3814\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6915 - acc: 0.3998 - val_loss: 0.6903 - val_acc: 0.3814\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6884 - acc: 0.3929 - val_loss: 0.6921 - val_acc: 0.3814\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6911 - acc: 0.3934 - val_loss: 0.6921 - val_acc: 0.3814\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6881 - acc: 0.3960 - val_loss: 0.6907 - val_acc: 0.3814\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6875 - acc: 0.3900 - val_loss: 0.6883 - val_acc: 0.3814\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6837 - acc: 0.3983 - val_loss: 0.6857 - val_acc: 0.3814\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6904 - acc: 0.3957 - val_loss: 0.6832 - val_acc: 0.3814\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6840 - acc: 0.4035 - val_loss: 0.6809 - val_acc: 0.3814\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6922 - acc: 0.4001 - val_loss: 0.6790 - val_acc: 0.3814\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6872 - acc: 0.4041 - val_loss: 0.6774 - val_acc: 0.3814\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6986 - acc: 0.3963 - val_loss: 0.6763 - val_acc: 0.3814\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6838 - acc: 0.4107 - val_loss: 0.6755 - val_acc: 0.3814\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6878 - acc: 0.3992 - val_loss: 0.6750 - val_acc: 0.3814\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6926 - acc: 0.4107 - val_loss: 0.6748 - val_acc: 0.3814\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6881 - acc: 0.4090 - val_loss: 0.6748 - val_acc: 0.3814\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6851 - acc: 0.4142 - val_loss: 0.6751 - val_acc: 0.3814\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6894 - acc: 0.4093 - val_loss: 0.6755 - val_acc: 0.3814\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6838 - acc: 0.4078 - val_loss: 0.6760 - val_acc: 0.3814\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6835 - acc: 0.4121 - val_loss: 0.6767 - val_acc: 0.3814\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6918 - acc: 0.4055 - val_loss: 0.6776 - val_acc: 0.3814\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6868 - acc: 0.3943 - val_loss: 0.6784 - val_acc: 0.3814\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6891 - acc: 0.4009 - val_loss: 0.6793 - val_acc: 0.3814\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6931 - acc: 0.3960 - val_loss: 0.6800 - val_acc: 0.3814\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6835 - acc: 0.3946 - val_loss: 0.6806 - val_acc: 0.3814\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6833 - acc: 0.3963 - val_loss: 0.6810 - val_acc: 0.3814\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6828 - acc: 0.3920 - val_loss: 0.6813 - val_acc: 0.3814\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6842 - acc: 0.3963 - val_loss: 0.6814 - val_acc: 0.3814\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6861 - acc: 0.3932 - val_loss: 0.6813 - val_acc: 0.3814\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6824 - acc: 0.3943 - val_loss: 0.6811 - val_acc: 0.3814\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6814 - acc: 0.3969 - val_loss: 0.6808 - val_acc: 0.3814\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6899 - acc: 0.3955 - val_loss: 0.6803 - val_acc: 0.3814\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6813 - acc: 0.3934 - val_loss: 0.6799 - val_acc: 0.3814\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6883 - acc: 0.3955 - val_loss: 0.6794 - val_acc: 0.3814\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6798 - acc: 0.3986 - val_loss: 0.6790 - val_acc: 0.3814\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6829 - acc: 0.3975 - val_loss: 0.6786 - val_acc: 0.3814\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6861 - acc: 0.3980 - val_loss: 0.6782 - val_acc: 0.3814\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6831 - acc: 0.3946 - val_loss: 0.6778 - val_acc: 0.3814\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6846 - acc: 0.3980 - val_loss: 0.6776 - val_acc: 0.3814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6863 - acc: 0.3998 - val_loss: 0.6775 - val_acc: 0.3814\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6852 - acc: 0.3955 - val_loss: 0.6775 - val_acc: 0.3814\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6826 - acc: 0.3957 - val_loss: 0.6775 - val_acc: 0.3814\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6843 - acc: 0.3995 - val_loss: 0.6776 - val_acc: 0.3814\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6865 - acc: 0.3995 - val_loss: 0.6778 - val_acc: 0.3814\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6828 - acc: 0.3966 - val_loss: 0.6781 - val_acc: 0.3814\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6858 - acc: 0.3963 - val_loss: 0.6784 - val_acc: 0.3814\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6842 - acc: 0.3960 - val_loss: 0.6788 - val_acc: 0.3814\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6810 - acc: 0.3926 - val_loss: 0.6790 - val_acc: 0.3814\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6822 - acc: 0.3955 - val_loss: 0.6793 - val_acc: 0.3814\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6852 - acc: 0.3940 - val_loss: 0.6795 - val_acc: 0.3814\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6829 - acc: 0.3917 - val_loss: 0.6796 - val_acc: 0.3814\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6833 - acc: 0.3917 - val_loss: 0.6796 - val_acc: 0.3814\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6841 - acc: 0.3934 - val_loss: 0.6795 - val_acc: 0.3814\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6851 - acc: 0.3897 - val_loss: 0.6792 - val_acc: 0.3814\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6816 - acc: 0.3932 - val_loss: 0.6790 - val_acc: 0.3814\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6779 - acc: 0.3934 - val_loss: 0.6786 - val_acc: 0.3814\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6823 - acc: 0.3937 - val_loss: 0.6784 - val_acc: 0.3814\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6790 - acc: 0.3943 - val_loss: 0.6781 - val_acc: 0.3814\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6814 - acc: 0.3900 - val_loss: 0.6779 - val_acc: 0.3814\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6809 - acc: 0.3917 - val_loss: 0.6777 - val_acc: 0.3814\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6830 - acc: 0.3932 - val_loss: 0.6775 - val_acc: 0.3814\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6819 - acc: 0.3906 - val_loss: 0.6773 - val_acc: 0.3814\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6852 - acc: 0.3906 - val_loss: 0.6770 - val_acc: 0.3814\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6790 - acc: 0.3937 - val_loss: 0.6767 - val_acc: 0.3814\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6809 - acc: 0.3914 - val_loss: 0.6763 - val_acc: 0.3814\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6769 - acc: 0.3923 - val_loss: 0.6761 - val_acc: 0.3814\n",
      "sample weight :  [1.34248387e-04 4.77718413e-05 3.89903795e-05 ... 4.59259408e-05\n",
      " 3.74488346e-05 5.91692846e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7242 - acc: 0.6224 - val_loss: 0.7360 - val_acc: 0.5841\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7173 - acc: 0.6232 - val_loss: 0.7222 - val_acc: 0.5841\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7148 - acc: 0.6206 - val_loss: 0.7106 - val_acc: 0.5841\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6986 - acc: 0.6117 - val_loss: 0.7012 - val_acc: 0.5841\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7039 - acc: 0.6074 - val_loss: 0.6942 - val_acc: 0.5841\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6952 - acc: 0.5979 - val_loss: 0.6894 - val_acc: 0.5841\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6990 - acc: 0.5646 - val_loss: 0.6867 - val_acc: 0.5841\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6993 - acc: 0.5266 - val_loss: 0.6854 - val_acc: 0.5841\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7066 - acc: 0.5128 - val_loss: 0.6850 - val_acc: 0.5841\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6961 - acc: 0.5168 - val_loss: 0.6850 - val_acc: 0.5841\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7020 - acc: 0.4981 - val_loss: 0.6852 - val_acc: 0.5841\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6904 - acc: 0.5119 - val_loss: 0.6858 - val_acc: 0.5841\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6879 - acc: 0.5321 - val_loss: 0.6866 - val_acc: 0.5841\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7021 - acc: 0.5433 - val_loss: 0.6877 - val_acc: 0.5841\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6987 - acc: 0.5499 - val_loss: 0.6890 - val_acc: 0.5841\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6957 - acc: 0.5649 - val_loss: 0.6906 - val_acc: 0.5841\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6981 - acc: 0.5672 - val_loss: 0.6922 - val_acc: 0.5841\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6951 - acc: 0.5827 - val_loss: 0.6938 - val_acc: 0.5841\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7037 - acc: 0.5801 - val_loss: 0.6952 - val_acc: 0.5841\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6927 - acc: 0.6043 - val_loss: 0.6964 - val_acc: 0.5841\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6953 - acc: 0.5971 - val_loss: 0.6974 - val_acc: 0.5841\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6967 - acc: 0.6057 - val_loss: 0.6981 - val_acc: 0.5841\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7018 - acc: 0.5979 - val_loss: 0.6984 - val_acc: 0.5841\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6947 - acc: 0.5945 - val_loss: 0.6985 - val_acc: 0.5841\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7010 - acc: 0.6028 - val_loss: 0.6983 - val_acc: 0.5841\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6987 - acc: 0.5991 - val_loss: 0.6978 - val_acc: 0.5841\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6997 - acc: 0.5968 - val_loss: 0.6972 - val_acc: 0.5841\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6941 - acc: 0.6034 - val_loss: 0.6964 - val_acc: 0.5841\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6941 - acc: 0.5953 - val_loss: 0.6957 - val_acc: 0.5841\n",
      "Epoch 30/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6964 - acc: 0.5982 - val_loss: 0.6949 - val_acc: 0.5841\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6991 - acc: 0.5959 - val_loss: 0.6942 - val_acc: 0.5841\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6970 - acc: 0.5959 - val_loss: 0.6934 - val_acc: 0.5841\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6929 - acc: 0.5951 - val_loss: 0.6928 - val_acc: 0.5841\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6960 - acc: 0.5864 - val_loss: 0.6921 - val_acc: 0.5841\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7001 - acc: 0.5804 - val_loss: 0.6916 - val_acc: 0.5841\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6958 - acc: 0.5818 - val_loss: 0.6912 - val_acc: 0.5841\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6926 - acc: 0.5801 - val_loss: 0.6909 - val_acc: 0.5841\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6922 - acc: 0.5784 - val_loss: 0.6907 - val_acc: 0.5841\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7032 - acc: 0.5657 - val_loss: 0.6905 - val_acc: 0.5841\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6988 - acc: 0.5683 - val_loss: 0.6905 - val_acc: 0.5841\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6947 - acc: 0.5700 - val_loss: 0.6905 - val_acc: 0.5841\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6934 - acc: 0.5902 - val_loss: 0.6906 - val_acc: 0.5841\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6952 - acc: 0.5847 - val_loss: 0.6908 - val_acc: 0.5841\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6927 - acc: 0.5772 - val_loss: 0.6910 - val_acc: 0.5841\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6969 - acc: 0.5982 - val_loss: 0.6913 - val_acc: 0.5841\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6963 - acc: 0.5945 - val_loss: 0.6915 - val_acc: 0.5841\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.6880 - acc: 0.5896 - val_loss: 0.6918 - val_acc: 0.5841\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6929 - acc: 0.5853 - val_loss: 0.6920 - val_acc: 0.5841\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6923 - acc: 0.5942 - val_loss: 0.6923 - val_acc: 0.5841\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6948 - acc: 0.5870 - val_loss: 0.6925 - val_acc: 0.5841\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6940 - acc: 0.5864 - val_loss: 0.6926 - val_acc: 0.5841\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6976 - acc: 0.5991 - val_loss: 0.6928 - val_acc: 0.5841\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6878 - acc: 0.6054 - val_loss: 0.6928 - val_acc: 0.5841\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6968 - acc: 0.5962 - val_loss: 0.6929 - val_acc: 0.5841\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6962 - acc: 0.5956 - val_loss: 0.6929 - val_acc: 0.5841\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6880 - acc: 0.6091 - val_loss: 0.6928 - val_acc: 0.5841\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6907 - acc: 0.6020 - val_loss: 0.6928 - val_acc: 0.5841\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6930 - acc: 0.6017 - val_loss: 0.6926 - val_acc: 0.5841\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6907 - acc: 0.6020 - val_loss: 0.6924 - val_acc: 0.5841\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6965 - acc: 0.6037 - val_loss: 0.6922 - val_acc: 0.5841\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6924 - acc: 0.5959 - val_loss: 0.6920 - val_acc: 0.5841\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6894 - acc: 0.5956 - val_loss: 0.6918 - val_acc: 0.5841\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6877 - acc: 0.6043 - val_loss: 0.6916 - val_acc: 0.5841\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6968 - acc: 0.5925 - val_loss: 0.6914 - val_acc: 0.5841\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6887 - acc: 0.5991 - val_loss: 0.6912 - val_acc: 0.5841\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6928 - acc: 0.6037 - val_loss: 0.6911 - val_acc: 0.5841\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6935 - acc: 0.5956 - val_loss: 0.6909 - val_acc: 0.5841\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6916 - acc: 0.5913 - val_loss: 0.6908 - val_acc: 0.5841\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6889 - acc: 0.5982 - val_loss: 0.6907 - val_acc: 0.5841\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6878 - acc: 0.6114 - val_loss: 0.6905 - val_acc: 0.5841\n",
      "sample weight :  [1.51273934e-04 5.39419349e-05 3.50925056e-05 ... 4.11537897e-05\n",
      " 3.38226404e-05 5.28937151e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7670 - acc: 0.3842 - val_loss: 0.6878 - val_acc: 0.3900\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7552 - acc: 0.3840 - val_loss: 0.6811 - val_acc: 0.3900\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7286 - acc: 0.3863 - val_loss: 0.6769 - val_acc: 0.3900\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7299 - acc: 0.3957 - val_loss: 0.6749 - val_acc: 0.3900\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7202 - acc: 0.3992 - val_loss: 0.6752 - val_acc: 0.3900\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7128 - acc: 0.4234 - val_loss: 0.6778 - val_acc: 0.3900\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7031 - acc: 0.4633 - val_loss: 0.6822 - val_acc: 0.3900\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7009 - acc: 0.4786 - val_loss: 0.6879 - val_acc: 0.6100\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7052 - acc: 0.5188 - val_loss: 0.6939 - val_acc: 0.6100\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7026 - acc: 0.5617 - val_loss: 0.6991 - val_acc: 0.6100\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7029 - acc: 0.5585 - val_loss: 0.7023 - val_acc: 0.6100\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7075 - acc: 0.5695 - val_loss: 0.7035 - val_acc: 0.6100\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7071 - acc: 0.5738 - val_loss: 0.7028 - val_acc: 0.6100\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7082 - acc: 0.5738 - val_loss: 0.7010 - val_acc: 0.6100\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7128 - acc: 0.5787 - val_loss: 0.6985 - val_acc: 0.6100\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7044 - acc: 0.5666 - val_loss: 0.6955 - val_acc: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7002 - acc: 0.5580 - val_loss: 0.6927 - val_acc: 0.6100\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7046 - acc: 0.5499 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6997 - acc: 0.5372 - val_loss: 0.6876 - val_acc: 0.6100\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7056 - acc: 0.5240 - val_loss: 0.6856 - val_acc: 0.6100\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6952 - acc: 0.5298 - val_loss: 0.6839 - val_acc: 0.6100\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7072 - acc: 0.4984 - val_loss: 0.6826 - val_acc: 0.3900\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7016 - acc: 0.4820 - val_loss: 0.6814 - val_acc: 0.3900\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6951 - acc: 0.5007 - val_loss: 0.6806 - val_acc: 0.3900\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6949 - acc: 0.4846 - val_loss: 0.6800 - val_acc: 0.3900\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7063 - acc: 0.4766 - val_loss: 0.6796 - val_acc: 0.3900\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7031 - acc: 0.4786 - val_loss: 0.6793 - val_acc: 0.3900\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7011 - acc: 0.4789 - val_loss: 0.6791 - val_acc: 0.3900\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7031 - acc: 0.4515 - val_loss: 0.6791 - val_acc: 0.3900\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7043 - acc: 0.4582 - val_loss: 0.6791 - val_acc: 0.3900\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7075 - acc: 0.4708 - val_loss: 0.6793 - val_acc: 0.3900\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7007 - acc: 0.4760 - val_loss: 0.6795 - val_acc: 0.3900\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7060 - acc: 0.4711 - val_loss: 0.6798 - val_acc: 0.3900\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7052 - acc: 0.4628 - val_loss: 0.6802 - val_acc: 0.3900\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6981 - acc: 0.4780 - val_loss: 0.6806 - val_acc: 0.3900\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7034 - acc: 0.4705 - val_loss: 0.6812 - val_acc: 0.3900\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6962 - acc: 0.4907 - val_loss: 0.6817 - val_acc: 0.3900\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6987 - acc: 0.4886 - val_loss: 0.6824 - val_acc: 0.3900\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6984 - acc: 0.4889 - val_loss: 0.6830 - val_acc: 0.3900\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7000 - acc: 0.4978 - val_loss: 0.6836 - val_acc: 0.5487\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6989 - acc: 0.5125 - val_loss: 0.6842 - val_acc: 0.6100\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7026 - acc: 0.5059 - val_loss: 0.6847 - val_acc: 0.6100\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7000 - acc: 0.5099 - val_loss: 0.6852 - val_acc: 0.6100\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7001 - acc: 0.5171 - val_loss: 0.6855 - val_acc: 0.6100\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6987 - acc: 0.5088 - val_loss: 0.6858 - val_acc: 0.6100\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7039 - acc: 0.5165 - val_loss: 0.6860 - val_acc: 0.6100\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7055 - acc: 0.5073 - val_loss: 0.6860 - val_acc: 0.6100\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6995 - acc: 0.5237 - val_loss: 0.6859 - val_acc: 0.6100\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6975 - acc: 0.5177 - val_loss: 0.6858 - val_acc: 0.6100\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7029 - acc: 0.5186 - val_loss: 0.6856 - val_acc: 0.6100\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6952 - acc: 0.5211 - val_loss: 0.6853 - val_acc: 0.6100\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7036 - acc: 0.5148 - val_loss: 0.6850 - val_acc: 0.6100\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7001 - acc: 0.5332 - val_loss: 0.6847 - val_acc: 0.6100\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6980 - acc: 0.5022 - val_loss: 0.6844 - val_acc: 0.6100\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7035 - acc: 0.5062 - val_loss: 0.6840 - val_acc: 0.6100\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6984 - acc: 0.5001 - val_loss: 0.6838 - val_acc: 0.5979\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7012 - acc: 0.4964 - val_loss: 0.6835 - val_acc: 0.4340\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7003 - acc: 0.5111 - val_loss: 0.6833 - val_acc: 0.4107\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6973 - acc: 0.5151 - val_loss: 0.6832 - val_acc: 0.3995\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7000 - acc: 0.5001 - val_loss: 0.6830 - val_acc: 0.3952\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7026 - acc: 0.4981 - val_loss: 0.6830 - val_acc: 0.3909\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6986 - acc: 0.4892 - val_loss: 0.6829 - val_acc: 0.3952\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6996 - acc: 0.4976 - val_loss: 0.6830 - val_acc: 0.3978\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6962 - acc: 0.5062 - val_loss: 0.6831 - val_acc: 0.4003\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6968 - acc: 0.4932 - val_loss: 0.6832 - val_acc: 0.3952\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6988 - acc: 0.4993 - val_loss: 0.6834 - val_acc: 0.3960\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6942 - acc: 0.5134 - val_loss: 0.6836 - val_acc: 0.4754\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6950 - acc: 0.5088 - val_loss: 0.6837 - val_acc: 0.5487\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6992 - acc: 0.5047 - val_loss: 0.6839 - val_acc: 0.5755\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6972 - acc: 0.5165 - val_loss: 0.6840 - val_acc: 0.5841\n",
      "sample weight :  [1.52565417e-04 5.45718018e-05 3.50955261e-05 ... 4.08456740e-05\n",
      " 3.39091867e-05 5.24944065e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7182 - acc: 0.4012 - val_loss: 0.6413 - val_acc: 0.4012\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7218 - acc: 0.4182 - val_loss: 0.6412 - val_acc: 0.4012\n",
      "Epoch 3/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7196 - acc: 0.4280 - val_loss: 0.6429 - val_acc: 0.4012\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7126 - acc: 0.4743 - val_loss: 0.6457 - val_acc: 0.4012\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7223 - acc: 0.5010 - val_loss: 0.6481 - val_acc: 0.5988\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7131 - acc: 0.5243 - val_loss: 0.6496 - val_acc: 0.5988\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7145 - acc: 0.5243 - val_loss: 0.6497 - val_acc: 0.5988\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7197 - acc: 0.5232 - val_loss: 0.6489 - val_acc: 0.5988\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7202 - acc: 0.5157 - val_loss: 0.6476 - val_acc: 0.5988\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7112 - acc: 0.5125 - val_loss: 0.6462 - val_acc: 0.4012\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7203 - acc: 0.4852 - val_loss: 0.6448 - val_acc: 0.4012\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7232 - acc: 0.4912 - val_loss: 0.6437 - val_acc: 0.4012\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7106 - acc: 0.4708 - val_loss: 0.6429 - val_acc: 0.4012\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7199 - acc: 0.4630 - val_loss: 0.6423 - val_acc: 0.4012\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7159 - acc: 0.4720 - val_loss: 0.6419 - val_acc: 0.4012\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7167 - acc: 0.4498 - val_loss: 0.6417 - val_acc: 0.4012\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7079 - acc: 0.4622 - val_loss: 0.6416 - val_acc: 0.4012\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7106 - acc: 0.4461 - val_loss: 0.6416 - val_acc: 0.4012\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7069 - acc: 0.4498 - val_loss: 0.6417 - val_acc: 0.4012\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7101 - acc: 0.4490 - val_loss: 0.6418 - val_acc: 0.4012\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7239 - acc: 0.4490 - val_loss: 0.6421 - val_acc: 0.4012\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7172 - acc: 0.4251 - val_loss: 0.6424 - val_acc: 0.4012\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7188 - acc: 0.4610 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7142 - acc: 0.4544 - val_loss: 0.6433 - val_acc: 0.4012\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7139 - acc: 0.4685 - val_loss: 0.6437 - val_acc: 0.4012\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7127 - acc: 0.4783 - val_loss: 0.6441 - val_acc: 0.4012\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7165 - acc: 0.4616 - val_loss: 0.6444 - val_acc: 0.4012\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7075 - acc: 0.4766 - val_loss: 0.6447 - val_acc: 0.4012\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7094 - acc: 0.4809 - val_loss: 0.6448 - val_acc: 0.4012\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7135 - acc: 0.4858 - val_loss: 0.6448 - val_acc: 0.4012\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7126 - acc: 0.4886 - val_loss: 0.6448 - val_acc: 0.4012\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7113 - acc: 0.4961 - val_loss: 0.6445 - val_acc: 0.4012\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7133 - acc: 0.4780 - val_loss: 0.6442 - val_acc: 0.4012\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7059 - acc: 0.4892 - val_loss: 0.6439 - val_acc: 0.4012\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7048 - acc: 0.4849 - val_loss: 0.6436 - val_acc: 0.4012\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7145 - acc: 0.4685 - val_loss: 0.6433 - val_acc: 0.4012\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7129 - acc: 0.4484 - val_loss: 0.6430 - val_acc: 0.4012\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7132 - acc: 0.4492 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7091 - acc: 0.4541 - val_loss: 0.6427 - val_acc: 0.4012\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7140 - acc: 0.4406 - val_loss: 0.6426 - val_acc: 0.4012\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7119 - acc: 0.4466 - val_loss: 0.6426 - val_acc: 0.4012\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7100 - acc: 0.4573 - val_loss: 0.6427 - val_acc: 0.4012\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7152 - acc: 0.4420 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7146 - acc: 0.4541 - val_loss: 0.6429 - val_acc: 0.4012\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7086 - acc: 0.4498 - val_loss: 0.6430 - val_acc: 0.4012\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7116 - acc: 0.4360 - val_loss: 0.6431 - val_acc: 0.4012\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7087 - acc: 0.4616 - val_loss: 0.6433 - val_acc: 0.4012\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7115 - acc: 0.4653 - val_loss: 0.6434 - val_acc: 0.4012\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7093 - acc: 0.4602 - val_loss: 0.6435 - val_acc: 0.4012\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7159 - acc: 0.4599 - val_loss: 0.6436 - val_acc: 0.4012\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7101 - acc: 0.4527 - val_loss: 0.6436 - val_acc: 0.4012\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7151 - acc: 0.4743 - val_loss: 0.6436 - val_acc: 0.4012\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7135 - acc: 0.4662 - val_loss: 0.6435 - val_acc: 0.4012\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7093 - acc: 0.4630 - val_loss: 0.6434 - val_acc: 0.4012\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7071 - acc: 0.4731 - val_loss: 0.6433 - val_acc: 0.4012\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7078 - acc: 0.4495 - val_loss: 0.6433 - val_acc: 0.4012\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7072 - acc: 0.4636 - val_loss: 0.6432 - val_acc: 0.4012\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7074 - acc: 0.4582 - val_loss: 0.6431 - val_acc: 0.4012\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7091 - acc: 0.4449 - val_loss: 0.6430 - val_acc: 0.4012\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7081 - acc: 0.4392 - val_loss: 0.6429 - val_acc: 0.4012\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7084 - acc: 0.4351 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7058 - acc: 0.4331 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7103 - acc: 0.4285 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7075 - acc: 0.4156 - val_loss: 0.6428 - val_acc: 0.4012\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7098 - acc: 0.4395 - val_loss: 0.6428 - val_acc: 0.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7052 - acc: 0.4380 - val_loss: 0.6427 - val_acc: 0.4012\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7069 - acc: 0.4380 - val_loss: 0.6427 - val_acc: 0.4012\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7034 - acc: 0.4392 - val_loss: 0.6426 - val_acc: 0.4012\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7055 - acc: 0.4337 - val_loss: 0.6425 - val_acc: 0.4012\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7041 - acc: 0.4265 - val_loss: 0.6425 - val_acc: 0.4012\n",
      "sample weight :  [1.50370248e-04 5.39519851e-05 3.77626008e-05 ... 4.31807863e-05\n",
      " 3.67490996e-05 5.41978420e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9598 - acc: 0.3863 - val_loss: 0.9036 - val_acc: 0.3934\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9177 - acc: 0.3863 - val_loss: 0.8750 - val_acc: 0.3934\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8903 - acc: 0.3863 - val_loss: 0.8492 - val_acc: 0.3934\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8624 - acc: 0.3865 - val_loss: 0.8258 - val_acc: 0.3934\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8370 - acc: 0.3863 - val_loss: 0.8049 - val_acc: 0.3934\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8034 - acc: 0.3863 - val_loss: 0.7863 - val_acc: 0.3934\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7846 - acc: 0.3863 - val_loss: 0.7700 - val_acc: 0.3934\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7648 - acc: 0.3868 - val_loss: 0.7561 - val_acc: 0.3934\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7422 - acc: 0.3863 - val_loss: 0.7448 - val_acc: 0.3934\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7270 - acc: 0.3863 - val_loss: 0.7363 - val_acc: 0.3934\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7091 - acc: 0.3906 - val_loss: 0.7308 - val_acc: 0.3934\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7016 - acc: 0.4029 - val_loss: 0.7282 - val_acc: 0.3934\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6935 - acc: 0.4182 - val_loss: 0.7284 - val_acc: 0.3934\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6819 - acc: 0.4610 - val_loss: 0.7307 - val_acc: 0.3934\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6905 - acc: 0.4907 - val_loss: 0.7345 - val_acc: 0.6066\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6873 - acc: 0.5220 - val_loss: 0.7389 - val_acc: 0.6066\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6894 - acc: 0.5401 - val_loss: 0.7436 - val_acc: 0.6066\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6930 - acc: 0.5580 - val_loss: 0.7480 - val_acc: 0.6066\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6859 - acc: 0.5749 - val_loss: 0.7518 - val_acc: 0.6066\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6975 - acc: 0.5764 - val_loss: 0.7546 - val_acc: 0.6066\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6876 - acc: 0.5824 - val_loss: 0.7565 - val_acc: 0.6066\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6907 - acc: 0.5867 - val_loss: 0.7574 - val_acc: 0.6066\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6934 - acc: 0.5962 - val_loss: 0.7573 - val_acc: 0.6066\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7003 - acc: 0.5873 - val_loss: 0.7564 - val_acc: 0.6066\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6889 - acc: 0.5812 - val_loss: 0.7550 - val_acc: 0.6066\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6933 - acc: 0.5907 - val_loss: 0.7531 - val_acc: 0.6066\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6910 - acc: 0.5965 - val_loss: 0.7511 - val_acc: 0.6066\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6907 - acc: 0.5778 - val_loss: 0.7489 - val_acc: 0.6066\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6950 - acc: 0.5755 - val_loss: 0.7467 - val_acc: 0.6066\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6910 - acc: 0.5683 - val_loss: 0.7445 - val_acc: 0.6066\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6915 - acc: 0.5634 - val_loss: 0.7425 - val_acc: 0.6066\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6850 - acc: 0.5686 - val_loss: 0.7406 - val_acc: 0.6066\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6849 - acc: 0.5565 - val_loss: 0.7389 - val_acc: 0.6066\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6875 - acc: 0.5427 - val_loss: 0.7374 - val_acc: 0.6066\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6828 - acc: 0.5364 - val_loss: 0.7361 - val_acc: 0.6066\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6789 - acc: 0.5433 - val_loss: 0.7350 - val_acc: 0.6066\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6847 - acc: 0.5306 - val_loss: 0.7340 - val_acc: 0.6066\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6859 - acc: 0.5358 - val_loss: 0.7332 - val_acc: 0.6066\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6809 - acc: 0.5137 - val_loss: 0.7326 - val_acc: 0.6066\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6837 - acc: 0.5234 - val_loss: 0.7320 - val_acc: 0.5125\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6874 - acc: 0.4932 - val_loss: 0.7316 - val_acc: 0.3934\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6841 - acc: 0.5033 - val_loss: 0.7313 - val_acc: 0.3934\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6850 - acc: 0.4958 - val_loss: 0.7310 - val_acc: 0.3934\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6857 - acc: 0.4961 - val_loss: 0.7308 - val_acc: 0.3934\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6839 - acc: 0.4915 - val_loss: 0.7307 - val_acc: 0.3934\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6831 - acc: 0.4898 - val_loss: 0.7306 - val_acc: 0.3934\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6870 - acc: 0.4685 - val_loss: 0.7306 - val_acc: 0.3934\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6870 - acc: 0.4978 - val_loss: 0.7307 - val_acc: 0.3934\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6842 - acc: 0.4832 - val_loss: 0.7307 - val_acc: 0.3934\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6835 - acc: 0.4915 - val_loss: 0.7308 - val_acc: 0.3934\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6858 - acc: 0.4915 - val_loss: 0.7310 - val_acc: 0.3934\n",
      "Epoch 52/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6835 - acc: 0.4927 - val_loss: 0.7312 - val_acc: 0.3934\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6798 - acc: 0.4935 - val_loss: 0.7313 - val_acc: 0.3934\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6890 - acc: 0.4826 - val_loss: 0.7316 - val_acc: 0.3934\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6853 - acc: 0.4984 - val_loss: 0.7318 - val_acc: 0.3934\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6834 - acc: 0.5131 - val_loss: 0.7321 - val_acc: 0.5936\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6786 - acc: 0.5033 - val_loss: 0.7323 - val_acc: 0.6066\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6868 - acc: 0.5102 - val_loss: 0.7326 - val_acc: 0.6066\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6818 - acc: 0.5128 - val_loss: 0.7329 - val_acc: 0.6066\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6841 - acc: 0.5214 - val_loss: 0.7332 - val_acc: 0.6066\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6820 - acc: 0.5070 - val_loss: 0.7335 - val_acc: 0.6066\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6889 - acc: 0.5329 - val_loss: 0.7337 - val_acc: 0.6066\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6856 - acc: 0.5263 - val_loss: 0.7339 - val_acc: 0.6066\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6818 - acc: 0.5191 - val_loss: 0.7341 - val_acc: 0.6066\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6840 - acc: 0.5128 - val_loss: 0.7343 - val_acc: 0.6066\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6801 - acc: 0.5352 - val_loss: 0.7344 - val_acc: 0.6066\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6830 - acc: 0.5249 - val_loss: 0.7346 - val_acc: 0.6066\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6839 - acc: 0.5223 - val_loss: 0.7347 - val_acc: 0.6066\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6817 - acc: 0.5381 - val_loss: 0.7348 - val_acc: 0.6066\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6873 - acc: 0.5318 - val_loss: 0.7349 - val_acc: 0.6066\n",
      "sample weight :  [1.55113722e-04 5.56960143e-05 3.65503075e-05 ... 4.17895813e-05\n",
      " 3.55938120e-05 5.24300822e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6977 - acc: 0.4049 - val_loss: 0.7363 - val_acc: 0.3822\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6891 - acc: 0.4170 - val_loss: 0.7321 - val_acc: 0.3822\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6883 - acc: 0.4219 - val_loss: 0.7299 - val_acc: 0.3822\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6824 - acc: 0.4409 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6899 - acc: 0.4691 - val_loss: 0.7299 - val_acc: 0.3822\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6843 - acc: 0.4938 - val_loss: 0.7306 - val_acc: 0.6178\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6860 - acc: 0.4915 - val_loss: 0.7309 - val_acc: 0.6178\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6885 - acc: 0.5154 - val_loss: 0.7308 - val_acc: 0.6178\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6837 - acc: 0.4953 - val_loss: 0.7304 - val_acc: 0.6178\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6854 - acc: 0.5102 - val_loss: 0.7300 - val_acc: 0.3822\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6866 - acc: 0.4886 - val_loss: 0.7296 - val_acc: 0.3822\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6875 - acc: 0.4866 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6881 - acc: 0.4757 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6858 - acc: 0.4567 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6849 - acc: 0.4556 - val_loss: 0.7298 - val_acc: 0.3822\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6824 - acc: 0.4559 - val_loss: 0.7300 - val_acc: 0.3822\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6809 - acc: 0.4415 - val_loss: 0.7302 - val_acc: 0.3822\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6879 - acc: 0.4415 - val_loss: 0.7303 - val_acc: 0.3822\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6807 - acc: 0.4372 - val_loss: 0.7303 - val_acc: 0.3822\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6842 - acc: 0.4219 - val_loss: 0.7303 - val_acc: 0.3822\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6847 - acc: 0.4349 - val_loss: 0.7301 - val_acc: 0.3822\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6825 - acc: 0.4363 - val_loss: 0.7299 - val_acc: 0.3822\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6848 - acc: 0.4268 - val_loss: 0.7297 - val_acc: 0.3822\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6840 - acc: 0.4530 - val_loss: 0.7296 - val_acc: 0.3822\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6850 - acc: 0.4487 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6850 - acc: 0.4466 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6836 - acc: 0.4590 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6855 - acc: 0.4538 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6819 - acc: 0.4694 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6845 - acc: 0.4751 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6846 - acc: 0.4777 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6859 - acc: 0.4777 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6836 - acc: 0.4748 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6817 - acc: 0.4806 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6910 - acc: 0.4676 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6804 - acc: 0.4524 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6834 - acc: 0.4501 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6820 - acc: 0.4527 - val_loss: 0.7294 - val_acc: 0.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6791 - acc: 0.4533 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6828 - acc: 0.4544 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6818 - acc: 0.4429 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6822 - acc: 0.4369 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6790 - acc: 0.4521 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6769 - acc: 0.4403 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6761 - acc: 0.4498 - val_loss: 0.7295 - val_acc: 0.3822\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6819 - acc: 0.4475 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6817 - acc: 0.4513 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6774 - acc: 0.4389 - val_loss: 0.7294 - val_acc: 0.3822\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6820 - acc: 0.4389 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6808 - acc: 0.4282 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6836 - acc: 0.4455 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6810 - acc: 0.4527 - val_loss: 0.7293 - val_acc: 0.3822\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6827 - acc: 0.4561 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6801 - acc: 0.4564 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6857 - acc: 0.4403 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6794 - acc: 0.4490 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6813 - acc: 0.4484 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6773 - acc: 0.4633 - val_loss: 0.7292 - val_acc: 0.3822\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6821 - acc: 0.4300 - val_loss: 0.7291 - val_acc: 0.3822\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6801 - acc: 0.4530 - val_loss: 0.7291 - val_acc: 0.3822\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6806 - acc: 0.4466 - val_loss: 0.7291 - val_acc: 0.3822\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6806 - acc: 0.4435 - val_loss: 0.7291 - val_acc: 0.3822\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6849 - acc: 0.4389 - val_loss: 0.7290 - val_acc: 0.3822\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6807 - acc: 0.4432 - val_loss: 0.7289 - val_acc: 0.3822\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6779 - acc: 0.4357 - val_loss: 0.7289 - val_acc: 0.3822\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6796 - acc: 0.4441 - val_loss: 0.7288 - val_acc: 0.3822\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6846 - acc: 0.4326 - val_loss: 0.7287 - val_acc: 0.3822\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6819 - acc: 0.4484 - val_loss: 0.7286 - val_acc: 0.3822\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6789 - acc: 0.4363 - val_loss: 0.7284 - val_acc: 0.3822\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6804 - acc: 0.4377 - val_loss: 0.7282 - val_acc: 0.3822\n",
      "sample weight :  [1.48059484e-04 5.31340965e-05 3.90834174e-05 ... 4.43631077e-05\n",
      " 3.80682349e-05 5.52253123e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.7005 - acc: 0.4449 - val_loss: 0.6968 - val_acc: 0.3736\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7035 - acc: 0.4760 - val_loss: 0.6959 - val_acc: 0.4953\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7012 - acc: 0.4938 - val_loss: 0.6965 - val_acc: 0.6264\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7063 - acc: 0.5217 - val_loss: 0.6972 - val_acc: 0.6264\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7075 - acc: 0.5407 - val_loss: 0.6974 - val_acc: 0.6264\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7020 - acc: 0.5306 - val_loss: 0.6970 - val_acc: 0.6264\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6992 - acc: 0.5309 - val_loss: 0.6965 - val_acc: 0.6264\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7008 - acc: 0.5252 - val_loss: 0.6961 - val_acc: 0.6264\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6998 - acc: 0.5234 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6937 - acc: 0.4898 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6989 - acc: 0.4912 - val_loss: 0.6960 - val_acc: 0.3736\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.6964 - acc: 0.4918 - val_loss: 0.6961 - val_acc: 0.3736\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6989 - acc: 0.4720 - val_loss: 0.6961 - val_acc: 0.3736\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7043 - acc: 0.4668 - val_loss: 0.6961 - val_acc: 0.3736\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6944 - acc: 0.4996 - val_loss: 0.6961 - val_acc: 0.3736\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7030 - acc: 0.4855 - val_loss: 0.6960 - val_acc: 0.3736\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6984 - acc: 0.4745 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6964 - acc: 0.4990 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6945 - acc: 0.4996 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6981 - acc: 0.4932 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6969 - acc: 0.5177 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6923 - acc: 0.5180 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7014 - acc: 0.5001 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6951 - acc: 0.5157 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 25/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6952 - acc: 0.5278 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6964 - acc: 0.5177 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6953 - acc: 0.5186 - val_loss: 0.6960 - val_acc: 0.6264\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6954 - acc: 0.5027 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7014 - acc: 0.4958 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6969 - acc: 0.4812 - val_loss: 0.6959 - val_acc: 0.6264\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6966 - acc: 0.5045 - val_loss: 0.6959 - val_acc: 0.3253\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6956 - acc: 0.5085 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6945 - acc: 0.4984 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6924 - acc: 0.4987 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6957 - acc: 0.4866 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6923 - acc: 0.4898 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6960 - acc: 0.5053 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6946 - acc: 0.4901 - val_loss: 0.6959 - val_acc: 0.3736\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6887 - acc: 0.5085 - val_loss: 0.6959 - val_acc: 0.3727\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6984 - acc: 0.4904 - val_loss: 0.6959 - val_acc: 0.3615\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6959 - acc: 0.4981 - val_loss: 0.6959 - val_acc: 0.3236\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6963 - acc: 0.4889 - val_loss: 0.6959 - val_acc: 0.3451\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6938 - acc: 0.4990 - val_loss: 0.6959 - val_acc: 0.3218\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6933 - acc: 0.4947 - val_loss: 0.6959 - val_acc: 0.3469\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6937 - acc: 0.5096 - val_loss: 0.6959 - val_acc: 0.3546\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6938 - acc: 0.4944 - val_loss: 0.6959 - val_acc: 0.3857\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6955 - acc: 0.4832 - val_loss: 0.6959 - val_acc: 0.5134\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6903 - acc: 0.5131 - val_loss: 0.6959 - val_acc: 0.5703\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6958 - val_acc: 0.5928\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6931 - acc: 0.4889 - val_loss: 0.6958 - val_acc: 0.6186\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6916 - acc: 0.4984 - val_loss: 0.6958 - val_acc: 0.6195\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6950 - acc: 0.5062 - val_loss: 0.6958 - val_acc: 0.6178\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6906 - acc: 0.5093 - val_loss: 0.6958 - val_acc: 0.6040\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6899 - acc: 0.5039 - val_loss: 0.6958 - val_acc: 0.5962\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6901 - acc: 0.4993 - val_loss: 0.6957 - val_acc: 0.5910\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6880 - acc: 0.5102 - val_loss: 0.6957 - val_acc: 0.5600\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6888 - acc: 0.5085 - val_loss: 0.6956 - val_acc: 0.5186\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6900 - acc: 0.4849 - val_loss: 0.6955 - val_acc: 0.4564\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6904 - acc: 0.4846 - val_loss: 0.6954 - val_acc: 0.4323\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6910 - acc: 0.4774 - val_loss: 0.6953 - val_acc: 0.4323\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6891 - acc: 0.5039 - val_loss: 0.6952 - val_acc: 0.4271\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6871 - acc: 0.4826 - val_loss: 0.6950 - val_acc: 0.4305\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6863 - acc: 0.4829 - val_loss: 0.6948 - val_acc: 0.4202\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6840 - acc: 0.4806 - val_loss: 0.6944 - val_acc: 0.4133\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6835 - acc: 0.4561 - val_loss: 0.6939 - val_acc: 0.4116\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6786 - acc: 0.4743 - val_loss: 0.6932 - val_acc: 0.4064\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6745 - acc: 0.4544 - val_loss: 0.6924 - val_acc: 0.4055\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6747 - acc: 0.4550 - val_loss: 0.6914 - val_acc: 0.4219\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6647 - acc: 0.4648 - val_loss: 0.6900 - val_acc: 0.4202\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6599 - acc: 0.4605 - val_loss: 0.6883 - val_acc: 0.4236\n",
      "sample weight :  [1.64797843e-04 5.94410110e-05 4.31081705e-05 ... 5.16222204e-05\n",
      " 4.60032685e-05 5.24293243e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7005 - acc: 0.5899 - val_loss: 0.7123 - val_acc: 0.6238\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7024 - acc: 0.5568 - val_loss: 0.7101 - val_acc: 0.6238\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6981 - acc: 0.5430 - val_loss: 0.7097 - val_acc: 0.6238\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6967 - acc: 0.5013 - val_loss: 0.7107 - val_acc: 0.3762\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6969 - acc: 0.4708 - val_loss: 0.7124 - val_acc: 0.3762\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6979 - acc: 0.4702 - val_loss: 0.7139 - val_acc: 0.3762\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6923 - acc: 0.4636 - val_loss: 0.7147 - val_acc: 0.3762\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6929 - acc: 0.4435 - val_loss: 0.7149 - val_acc: 0.3762\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6998 - acc: 0.4277 - val_loss: 0.7144 - val_acc: 0.3762\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6967 - acc: 0.4438 - val_loss: 0.7136 - val_acc: 0.3762\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6923 - acc: 0.4538 - val_loss: 0.7127 - val_acc: 0.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6926 - acc: 0.4461 - val_loss: 0.7118 - val_acc: 0.3762\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6902 - acc: 0.4659 - val_loss: 0.7111 - val_acc: 0.3762\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6903 - acc: 0.4757 - val_loss: 0.7106 - val_acc: 0.3762\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6921 - acc: 0.5010 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6946 - acc: 0.4953 - val_loss: 0.7100 - val_acc: 0.6238\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.7098 - val_acc: 0.6238\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6867 - acc: 0.5099 - val_loss: 0.7098 - val_acc: 0.6238\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6921 - acc: 0.5154 - val_loss: 0.7097 - val_acc: 0.6238\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6895 - acc: 0.5171 - val_loss: 0.7097 - val_acc: 0.6238\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6862 - acc: 0.5131 - val_loss: 0.7098 - val_acc: 0.6238\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6922 - acc: 0.5062 - val_loss: 0.7098 - val_acc: 0.6238\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6920 - acc: 0.5200 - val_loss: 0.7098 - val_acc: 0.6238\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6911 - acc: 0.5007 - val_loss: 0.7099 - val_acc: 0.6238\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6910 - acc: 0.5001 - val_loss: 0.7100 - val_acc: 0.3762\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6930 - acc: 0.5010 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6915 - acc: 0.4852 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6925 - acc: 0.4898 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6859 - acc: 0.4981 - val_loss: 0.7107 - val_acc: 0.3762\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6993 - acc: 0.4553 - val_loss: 0.7108 - val_acc: 0.3762\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6905 - acc: 0.4731 - val_loss: 0.7109 - val_acc: 0.3762\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6900 - acc: 0.4846 - val_loss: 0.7110 - val_acc: 0.3762\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6853 - acc: 0.4722 - val_loss: 0.7111 - val_acc: 0.3762\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6870 - acc: 0.4832 - val_loss: 0.7111 - val_acc: 0.3762\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6865 - acc: 0.4702 - val_loss: 0.7111 - val_acc: 0.3762\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6910 - acc: 0.4766 - val_loss: 0.7110 - val_acc: 0.3762\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6935 - acc: 0.4688 - val_loss: 0.7109 - val_acc: 0.3762\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6882 - acc: 0.4791 - val_loss: 0.7108 - val_acc: 0.3762\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6960 - acc: 0.4777 - val_loss: 0.7106 - val_acc: 0.3762\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6929 - acc: 0.4826 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6916 - acc: 0.4734 - val_loss: 0.7104 - val_acc: 0.3762\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6877 - acc: 0.4878 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6892 - acc: 0.4898 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6885 - acc: 0.4771 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6883 - acc: 0.4886 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6923 - acc: 0.4861 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6879 - acc: 0.4889 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6890 - acc: 0.4771 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6885 - acc: 0.4947 - val_loss: 0.7102 - val_acc: 0.3762\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6843 - acc: 0.4964 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6934 - acc: 0.4838 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6896 - acc: 0.4820 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6928 - acc: 0.4869 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6895 - acc: 0.4728 - val_loss: 0.7104 - val_acc: 0.3762\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6931 - acc: 0.4820 - val_loss: 0.7104 - val_acc: 0.3762\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6894 - acc: 0.4774 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6874 - acc: 0.4737 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6888 - acc: 0.4751 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6907 - acc: 0.4679 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6877 - acc: 0.4840 - val_loss: 0.7105 - val_acc: 0.3762\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6901 - acc: 0.4863 - val_loss: 0.7104 - val_acc: 0.3762\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6877 - acc: 0.4961 - val_loss: 0.7104 - val_acc: 0.3762\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6856 - acc: 0.4806 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6891 - acc: 0.4904 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6894 - acc: 0.4846 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6865 - acc: 0.4976 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6844 - acc: 0.4858 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6856 - acc: 0.4912 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6880 - acc: 0.4748 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6908 - acc: 0.4630 - val_loss: 0.7103 - val_acc: 0.3762\n",
      "sample weight :  [1.62378213e-04 5.85697124e-05 4.39288479e-05 ... 5.24239994e-05\n",
      " 4.67718471e-05 5.32119073e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7135 - acc: 0.5870 - val_loss: 0.6995 - val_acc: 0.6428\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7076 - acc: 0.5660 - val_loss: 0.6979 - val_acc: 0.6428\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6956 - acc: 0.5418 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7026 - acc: 0.5105 - val_loss: 0.7008 - val_acc: 0.3572\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7020 - acc: 0.4745 - val_loss: 0.7033 - val_acc: 0.3572\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7062 - acc: 0.4642 - val_loss: 0.7049 - val_acc: 0.3572\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7025 - acc: 0.4524 - val_loss: 0.7053 - val_acc: 0.3572\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7068 - acc: 0.4561 - val_loss: 0.7046 - val_acc: 0.3572\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6974 - acc: 0.4544 - val_loss: 0.7034 - val_acc: 0.3572\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6958 - acc: 0.4751 - val_loss: 0.7020 - val_acc: 0.3572\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7020 - acc: 0.4587 - val_loss: 0.7007 - val_acc: 0.3572\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6932 - acc: 0.4737 - val_loss: 0.6997 - val_acc: 0.3572\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7010 - acc: 0.4884 - val_loss: 0.6989 - val_acc: 0.3572\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6982 - acc: 0.5073 - val_loss: 0.6984 - val_acc: 0.6428\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7030 - acc: 0.5019 - val_loss: 0.6981 - val_acc: 0.6428\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6998 - acc: 0.5255 - val_loss: 0.6980 - val_acc: 0.6428\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6992 - acc: 0.5197 - val_loss: 0.6979 - val_acc: 0.6428\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6944 - acc: 0.5326 - val_loss: 0.6979 - val_acc: 0.6428\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6916 - acc: 0.5301 - val_loss: 0.6979 - val_acc: 0.6428\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7050 - acc: 0.5116 - val_loss: 0.6980 - val_acc: 0.6428\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6996 - acc: 0.5347 - val_loss: 0.6981 - val_acc: 0.6428\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6994 - acc: 0.5180 - val_loss: 0.6982 - val_acc: 0.6428\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6928 - acc: 0.5280 - val_loss: 0.6984 - val_acc: 0.6428\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6972 - acc: 0.5122 - val_loss: 0.6987 - val_acc: 0.6428\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6916 - acc: 0.5148 - val_loss: 0.6990 - val_acc: 0.3572\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6968 - acc: 0.4958 - val_loss: 0.6993 - val_acc: 0.3572\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7013 - acc: 0.5088 - val_loss: 0.6996 - val_acc: 0.3572\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6972 - acc: 0.4823 - val_loss: 0.6998 - val_acc: 0.3572\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6991 - acc: 0.4780 - val_loss: 0.7000 - val_acc: 0.3572\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7028 - acc: 0.4610 - val_loss: 0.7000 - val_acc: 0.3572\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6969 - acc: 0.4878 - val_loss: 0.7000 - val_acc: 0.3572\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7005 - acc: 0.4768 - val_loss: 0.6999 - val_acc: 0.3572\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6918 - acc: 0.5050 - val_loss: 0.6997 - val_acc: 0.3572\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6914 - acc: 0.4976 - val_loss: 0.6994 - val_acc: 0.3572\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6937 - acc: 0.4875 - val_loss: 0.6992 - val_acc: 0.3572\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6965 - acc: 0.4846 - val_loss: 0.6990 - val_acc: 0.3572\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6975 - acc: 0.5099 - val_loss: 0.6988 - val_acc: 0.6428\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6933 - acc: 0.5062 - val_loss: 0.6987 - val_acc: 0.6428\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7056 - acc: 0.4875 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6932 - acc: 0.5059 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6878 - acc: 0.5027 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6904 - acc: 0.5128 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6940 - acc: 0.5142 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6913 - acc: 0.5162 - val_loss: 0.6986 - val_acc: 0.6428\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6974 - acc: 0.5042 - val_loss: 0.6987 - val_acc: 0.6428\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6947 - acc: 0.5093 - val_loss: 0.6988 - val_acc: 0.6428\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6959 - acc: 0.5042 - val_loss: 0.6989 - val_acc: 0.3434\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7025 - acc: 0.4797 - val_loss: 0.6990 - val_acc: 0.3572\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6945 - acc: 0.4892 - val_loss: 0.6991 - val_acc: 0.3572\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6968 - acc: 0.4809 - val_loss: 0.6992 - val_acc: 0.3572\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6948 - acc: 0.4852 - val_loss: 0.6993 - val_acc: 0.3572\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6922 - acc: 0.4999 - val_loss: 0.6993 - val_acc: 0.3572\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6943 - acc: 0.4783 - val_loss: 0.6993 - val_acc: 0.3572\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6971 - acc: 0.4941 - val_loss: 0.6992 - val_acc: 0.3572\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6912 - acc: 0.4832 - val_loss: 0.6991 - val_acc: 0.3572\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6880 - acc: 0.4932 - val_loss: 0.6990 - val_acc: 0.3572\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6945 - acc: 0.5007 - val_loss: 0.6988 - val_acc: 0.3374\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6923 - acc: 0.4935 - val_loss: 0.6988 - val_acc: 0.4866\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7010 - acc: 0.4964 - val_loss: 0.6987 - val_acc: 0.6230\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6903 - acc: 0.4961 - val_loss: 0.6986 - val_acc: 0.6376\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6938 - acc: 0.5122 - val_loss: 0.6986 - val_acc: 0.6350\n",
      "Epoch 62/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6942 - acc: 0.5042 - val_loss: 0.6986 - val_acc: 0.6031\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6880 - acc: 0.5142 - val_loss: 0.6987 - val_acc: 0.4236\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6961 - acc: 0.4938 - val_loss: 0.6988 - val_acc: 0.3443\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6886 - acc: 0.5088 - val_loss: 0.6988 - val_acc: 0.3417\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6938 - acc: 0.4984 - val_loss: 0.6989 - val_acc: 0.3538\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6926 - acc: 0.4984 - val_loss: 0.6989 - val_acc: 0.3572\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6953 - acc: 0.4826 - val_loss: 0.6989 - val_acc: 0.3572\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6918 - acc: 0.4806 - val_loss: 0.6989 - val_acc: 0.3572\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6921 - acc: 0.4728 - val_loss: 0.6989 - val_acc: 0.3572\n",
      "sample weight :  [1.61228592e-04 5.81193775e-05 4.47346547e-05 ... 5.32097199e-05\n",
      " 4.77320728e-05 5.36543065e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7079 - acc: 0.4193 - val_loss: 0.6908 - val_acc: 0.3995\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6985 - acc: 0.4291 - val_loss: 0.6864 - val_acc: 0.3995\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7001 - acc: 0.4544 - val_loss: 0.6835 - val_acc: 0.3995\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6982 - acc: 0.5001 - val_loss: 0.6820 - val_acc: 0.6005\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7032 - acc: 0.5229 - val_loss: 0.6813 - val_acc: 0.6005\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7057 - acc: 0.5275 - val_loss: 0.6811 - val_acc: 0.6005\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7118 - acc: 0.5476 - val_loss: 0.6811 - val_acc: 0.6005\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7061 - acc: 0.5439 - val_loss: 0.6811 - val_acc: 0.6005\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7016 - acc: 0.5577 - val_loss: 0.6811 - val_acc: 0.6005\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7012 - acc: 0.5513 - val_loss: 0.6813 - val_acc: 0.6005\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7017 - acc: 0.5545 - val_loss: 0.6815 - val_acc: 0.6005\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6980 - acc: 0.5531 - val_loss: 0.6818 - val_acc: 0.6005\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7004 - acc: 0.5203 - val_loss: 0.6823 - val_acc: 0.6005\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7039 - acc: 0.5145 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7051 - acc: 0.5036 - val_loss: 0.6833 - val_acc: 0.3995\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7008 - acc: 0.4843 - val_loss: 0.6838 - val_acc: 0.3995\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7004 - acc: 0.4809 - val_loss: 0.6843 - val_acc: 0.3995\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7017 - acc: 0.4636 - val_loss: 0.6846 - val_acc: 0.3995\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7002 - acc: 0.4737 - val_loss: 0.6847 - val_acc: 0.3995\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7011 - acc: 0.4648 - val_loss: 0.6847 - val_acc: 0.3995\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7022 - acc: 0.4760 - val_loss: 0.6846 - val_acc: 0.3995\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6964 - acc: 0.4797 - val_loss: 0.6843 - val_acc: 0.3995\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7003 - acc: 0.4835 - val_loss: 0.6839 - val_acc: 0.3995\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7021 - acc: 0.4806 - val_loss: 0.6835 - val_acc: 0.3995\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6953 - acc: 0.4866 - val_loss: 0.6831 - val_acc: 0.3995\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7002 - acc: 0.4955 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7018 - acc: 0.4884 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7019 - acc: 0.5229 - val_loss: 0.6823 - val_acc: 0.6005\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6993 - acc: 0.5128 - val_loss: 0.6821 - val_acc: 0.6005\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7000 - acc: 0.5217 - val_loss: 0.6820 - val_acc: 0.6005\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6989 - acc: 0.5263 - val_loss: 0.6820 - val_acc: 0.6005\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7023 - acc: 0.5099 - val_loss: 0.6820 - val_acc: 0.6005\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6995 - acc: 0.5266 - val_loss: 0.6820 - val_acc: 0.6005\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6948 - acc: 0.5375 - val_loss: 0.6821 - val_acc: 0.6005\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6979 - acc: 0.5303 - val_loss: 0.6822 - val_acc: 0.6005\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6974 - acc: 0.5413 - val_loss: 0.6824 - val_acc: 0.6005\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6954 - acc: 0.5197 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6965 - acc: 0.5148 - val_loss: 0.6826 - val_acc: 0.6005\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7027 - acc: 0.4930 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6979 - acc: 0.5275 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6958 - acc: 0.5131 - val_loss: 0.6829 - val_acc: 0.6005\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7008 - acc: 0.5036 - val_loss: 0.6830 - val_acc: 0.6005\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6989 - acc: 0.5024 - val_loss: 0.6830 - val_acc: 0.6005\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6989 - acc: 0.5065 - val_loss: 0.6830 - val_acc: 0.5928\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6955 - acc: 0.5131 - val_loss: 0.6831 - val_acc: 0.5807\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6972 - acc: 0.5108 - val_loss: 0.6830 - val_acc: 0.6005\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6982 - acc: 0.5068 - val_loss: 0.6830 - val_acc: 0.6005\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6989 - acc: 0.5004 - val_loss: 0.6829 - val_acc: 0.6005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6973 - acc: 0.5102 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7006 - acc: 0.4987 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6959 - acc: 0.5116 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6981 - acc: 0.5093 - val_loss: 0.6826 - val_acc: 0.6005\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7004 - acc: 0.5134 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6967 - acc: 0.5203 - val_loss: 0.6824 - val_acc: 0.6005\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6979 - acc: 0.5220 - val_loss: 0.6824 - val_acc: 0.6005\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7012 - acc: 0.5237 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7022 - acc: 0.5206 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6983 - acc: 0.5165 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6983 - acc: 0.5223 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6987 - acc: 0.5214 - val_loss: 0.6826 - val_acc: 0.6005\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6991 - acc: 0.5197 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6981 - acc: 0.5073 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6985 - acc: 0.5099 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6971 - acc: 0.5053 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6965 - acc: 0.5093 - val_loss: 0.6828 - val_acc: 0.6005\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6972 - acc: 0.4999 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6981 - acc: 0.4921 - val_loss: 0.6827 - val_acc: 0.6005\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6972 - acc: 0.5093 - val_loss: 0.6826 - val_acc: 0.6005\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6966 - acc: 0.5266 - val_loss: 0.6826 - val_acc: 0.6005\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6952 - acc: 0.5045 - val_loss: 0.6825 - val_acc: 0.6005\n",
      "sample weight :  [1.62837685e-04 5.87314490e-05 4.43587157e-05 ... 5.27443781e-05\n",
      " 4.73867843e-05 5.31492062e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6935 - acc: 0.5068 - val_loss: 0.7060 - val_acc: 0.6074\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6946 - acc: 0.5361 - val_loss: 0.7067 - val_acc: 0.6074\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6949 - acc: 0.5600 - val_loss: 0.7066 - val_acc: 0.6074\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6976 - acc: 0.5482 - val_loss: 0.7063 - val_acc: 0.6074\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6881 - acc: 0.5473 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6916 - acc: 0.5450 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6918 - acc: 0.5349 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6961 - acc: 0.5183 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6981 - acc: 0.4976 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6939 - acc: 0.5047 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6936 - acc: 0.5165 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6924 - acc: 0.5180 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6957 - acc: 0.5329 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6912 - acc: 0.5295 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6944 - acc: 0.5349 - val_loss: 0.7060 - val_acc: 0.6074\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6929 - acc: 0.5462 - val_loss: 0.7061 - val_acc: 0.6074\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6982 - acc: 0.5493 - val_loss: 0.7061 - val_acc: 0.6074\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6960 - acc: 0.5375 - val_loss: 0.7060 - val_acc: 0.6074\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6958 - acc: 0.5361 - val_loss: 0.7060 - val_acc: 0.6074\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6960 - acc: 0.5390 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6963 - acc: 0.5326 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6921 - acc: 0.5367 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6950 - acc: 0.5237 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6879 - acc: 0.5329 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6870 - acc: 0.5324 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6910 - acc: 0.5122 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6908 - acc: 0.5257 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6932 - acc: 0.5338 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6950 - acc: 0.5203 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6936 - acc: 0.5232 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6895 - acc: 0.5424 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6888 - acc: 0.5433 - val_loss: 0.7057 - val_acc: 0.6074\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6926 - acc: 0.5301 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6910 - acc: 0.5355 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 35/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6877 - acc: 0.5473 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6903 - acc: 0.5626 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6922 - acc: 0.5459 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6884 - acc: 0.5387 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6908 - acc: 0.5444 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6901 - acc: 0.5416 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6887 - acc: 0.5551 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6889 - acc: 0.5456 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6903 - acc: 0.5519 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6892 - acc: 0.5499 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6907 - acc: 0.5470 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6893 - acc: 0.5534 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6903 - acc: 0.5542 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6898 - acc: 0.5485 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6903 - acc: 0.5539 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6882 - acc: 0.5568 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6877 - acc: 0.5554 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6915 - acc: 0.5499 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6891 - acc: 0.5571 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6880 - acc: 0.5588 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6887 - acc: 0.5718 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6880 - acc: 0.5611 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6865 - acc: 0.5614 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6891 - acc: 0.5614 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6867 - acc: 0.5689 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6889 - acc: 0.5626 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6899 - acc: 0.5605 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6898 - acc: 0.5697 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6885 - acc: 0.5706 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6890 - acc: 0.5695 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6903 - acc: 0.5680 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6901 - acc: 0.5588 - val_loss: 0.7059 - val_acc: 0.6074\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6893 - acc: 0.5551 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6883 - acc: 0.5634 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6891 - acc: 0.5516 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6877 - acc: 0.5487 - val_loss: 0.7058 - val_acc: 0.6074\n",
      "sample weight :  [1.67790231e-04 6.08152517e-05 4.31329340e-05 ... 5.11469906e-05\n",
      " 4.62365428e-05 5.15417864e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7211 - acc: 0.4418 - val_loss: 0.6480 - val_acc: 0.3822\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7144 - acc: 0.4616 - val_loss: 0.6462 - val_acc: 0.3822\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7089 - acc: 0.4809 - val_loss: 0.6455 - val_acc: 0.3822\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7117 - acc: 0.4852 - val_loss: 0.6453 - val_acc: 0.3822\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7108 - acc: 0.4820 - val_loss: 0.6460 - val_acc: 0.3822\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7121 - acc: 0.4774 - val_loss: 0.6470 - val_acc: 0.3822\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7123 - acc: 0.4628 - val_loss: 0.6480 - val_acc: 0.3822\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7126 - acc: 0.4648 - val_loss: 0.6489 - val_acc: 0.3822\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7195 - acc: 0.4501 - val_loss: 0.6493 - val_acc: 0.3822\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7108 - acc: 0.4642 - val_loss: 0.6489 - val_acc: 0.3822\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7172 - acc: 0.4515 - val_loss: 0.6482 - val_acc: 0.3822\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7203 - acc: 0.4536 - val_loss: 0.6475 - val_acc: 0.3822\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7094 - acc: 0.4599 - val_loss: 0.6467 - val_acc: 0.3822\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7132 - acc: 0.4633 - val_loss: 0.6461 - val_acc: 0.3822\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7116 - acc: 0.4630 - val_loss: 0.6458 - val_acc: 0.3822\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7088 - acc: 0.4679 - val_loss: 0.6458 - val_acc: 0.3822\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7126 - acc: 0.4774 - val_loss: 0.6462 - val_acc: 0.3822\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7152 - acc: 0.4676 - val_loss: 0.6467 - val_acc: 0.3822\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7110 - acc: 0.4665 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7137 - acc: 0.4544 - val_loss: 0.6475 - val_acc: 0.3822\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7142 - acc: 0.4507 - val_loss: 0.6479 - val_acc: 0.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7123 - acc: 0.4518 - val_loss: 0.6483 - val_acc: 0.3822\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7117 - acc: 0.4423 - val_loss: 0.6486 - val_acc: 0.3822\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7110 - acc: 0.4400 - val_loss: 0.6486 - val_acc: 0.3822\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7102 - acc: 0.4323 - val_loss: 0.6484 - val_acc: 0.3822\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7109 - acc: 0.4426 - val_loss: 0.6481 - val_acc: 0.3822\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7139 - acc: 0.4271 - val_loss: 0.6478 - val_acc: 0.3822\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7108 - acc: 0.4487 - val_loss: 0.6475 - val_acc: 0.3822\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7146 - acc: 0.4443 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7157 - acc: 0.4400 - val_loss: 0.6470 - val_acc: 0.3822\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7087 - acc: 0.4406 - val_loss: 0.6469 - val_acc: 0.3822\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7105 - acc: 0.4665 - val_loss: 0.6470 - val_acc: 0.3822\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7132 - acc: 0.4487 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7116 - acc: 0.4349 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7095 - acc: 0.4429 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7075 - acc: 0.4392 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7106 - acc: 0.4458 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7101 - acc: 0.4406 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7096 - acc: 0.4409 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7093 - acc: 0.4274 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7126 - acc: 0.4251 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7102 - acc: 0.4366 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7121 - acc: 0.4369 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7084 - acc: 0.4363 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7111 - acc: 0.4282 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7073 - acc: 0.4311 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7106 - acc: 0.4311 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7131 - acc: 0.4173 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7105 - acc: 0.4271 - val_loss: 0.6475 - val_acc: 0.3822\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7070 - acc: 0.4340 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7091 - acc: 0.4225 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7095 - acc: 0.4176 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7103 - acc: 0.4297 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7091 - acc: 0.4317 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7122 - acc: 0.4098 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7106 - acc: 0.4262 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7083 - acc: 0.4297 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7083 - acc: 0.4205 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7083 - acc: 0.4159 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7097 - acc: 0.4190 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7086 - acc: 0.4179 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7133 - acc: 0.4170 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7097 - acc: 0.4153 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7094 - acc: 0.4150 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7132 - acc: 0.4193 - val_loss: 0.6474 - val_acc: 0.3822\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7095 - acc: 0.4124 - val_loss: 0.6473 - val_acc: 0.3822\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7068 - acc: 0.4268 - val_loss: 0.6472 - val_acc: 0.3822\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7071 - acc: 0.4259 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7098 - acc: 0.4133 - val_loss: 0.6471 - val_acc: 0.3822\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7069 - acc: 0.4211 - val_loss: 0.6470 - val_acc: 0.3822\n",
      "sample weight :  [1.60017410e-04 5.77669611e-05 4.59117752e-05 ... 5.41086189e-05\n",
      " 4.89725929e-05 5.42801764e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6949 - acc: 0.5887 - val_loss: 0.7008 - val_acc: 0.5979\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6987 - acc: 0.5729 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6903 - acc: 0.5482 - val_loss: 0.7006 - val_acc: 0.5979\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6925 - acc: 0.5191 - val_loss: 0.7011 - val_acc: 0.5979\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6946 - acc: 0.5076 - val_loss: 0.7011 - val_acc: 0.5979\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6947 - acc: 0.5082 - val_loss: 0.7007 - val_acc: 0.5979\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6842 - acc: 0.5194 - val_loss: 0.7003 - val_acc: 0.5979\n",
      "Epoch 8/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6934 - acc: 0.5186 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6894 - acc: 0.5499 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6935 - acc: 0.5614 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6934 - acc: 0.5718 - val_loss: 0.7003 - val_acc: 0.5979\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6926 - acc: 0.5631 - val_loss: 0.7004 - val_acc: 0.5979\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6978 - acc: 0.5623 - val_loss: 0.7004 - val_acc: 0.5979\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6866 - acc: 0.5804 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6887 - acc: 0.5686 - val_loss: 0.7001 - val_acc: 0.5979\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7015 - acc: 0.5473 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6965 - acc: 0.5522 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6940 - acc: 0.5441 - val_loss: 0.7001 - val_acc: 0.5979\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6928 - acc: 0.5381 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6933 - acc: 0.5413 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6934 - acc: 0.5214 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6902 - acc: 0.5375 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6924 - acc: 0.5332 - val_loss: 0.7002 - val_acc: 0.5979\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6944 - acc: 0.5211 - val_loss: 0.7001 - val_acc: 0.5979\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6959 - acc: 0.5421 - val_loss: 0.7001 - val_acc: 0.5979\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6946 - acc: 0.5289 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6984 - acc: 0.5321 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6875 - acc: 0.5591 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6949 - acc: 0.5677 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6930 - acc: 0.5557 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6895 - acc: 0.5637 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6952 - acc: 0.5499 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6899 - acc: 0.5628 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6941 - acc: 0.5672 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6935 - acc: 0.5628 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6924 - acc: 0.5588 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6949 - acc: 0.5473 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6931 - acc: 0.5640 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6930 - acc: 0.5574 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6893 - acc: 0.5534 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6910 - acc: 0.5510 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6903 - acc: 0.5666 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6899 - acc: 0.5534 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6916 - acc: 0.5628 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6938 - acc: 0.5608 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6913 - acc: 0.5620 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6900 - acc: 0.5680 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6899 - acc: 0.5608 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6906 - acc: 0.5580 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6905 - acc: 0.5758 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6881 - acc: 0.5706 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6905 - acc: 0.5778 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6875 - acc: 0.5856 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6905 - acc: 0.5732 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6908 - acc: 0.5729 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6917 - acc: 0.5640 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6898 - acc: 0.5703 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6932 - acc: 0.5585 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6890 - acc: 0.5720 - val_loss: 0.7000 - val_acc: 0.5979\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6931 - acc: 0.5643 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6907 - acc: 0.5706 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6906 - acc: 0.5758 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6880 - acc: 0.5830 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6900 - acc: 0.5850 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6894 - acc: 0.5922 - val_loss: 0.6999 - val_acc: 0.5979\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6891 - acc: 0.5815 - val_loss: 0.6998 - val_acc: 0.5979\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6897 - acc: 0.5720 - val_loss: 0.6998 - val_acc: 0.5979\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6900 - acc: 0.6034 - val_loss: 0.6998 - val_acc: 0.5979\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6891 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5979\n",
      "Epoch 70/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6907 - acc: 0.5812 - val_loss: 0.6997 - val_acc: 0.5979\n",
      "sample weight :  [1.71472822e-04 6.18093235e-05 4.36359989e-05 ... 5.10491839e-05\n",
      " 4.59696030e-05 5.08664085e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7058 - acc: 0.4495 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7094 - acc: 0.4978 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7016 - acc: 0.4915 - val_loss: 0.6904 - val_acc: 0.6100\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6990 - acc: 0.5131 - val_loss: 0.6905 - val_acc: 0.6100\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7037 - acc: 0.5099 - val_loss: 0.6904 - val_acc: 0.6100\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7060 - acc: 0.5053 - val_loss: 0.6901 - val_acc: 0.6100\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6988 - acc: 0.5050 - val_loss: 0.6899 - val_acc: 0.6100\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7062 - acc: 0.4996 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6935 - acc: 0.4964 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6911 - acc: 0.4978 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7037 - acc: 0.4771 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7017 - acc: 0.4829 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6970 - acc: 0.4878 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7023 - acc: 0.4872 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6942 - acc: 0.5030 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6930 - acc: 0.5022 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7024 - acc: 0.4938 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7013 - acc: 0.4921 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7004 - acc: 0.4967 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6948 - acc: 0.5036 - val_loss: 0.6901 - val_acc: 0.6100\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6970 - acc: 0.5151 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6977 - acc: 0.5039 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6977 - acc: 0.5047 - val_loss: 0.6899 - val_acc: 0.6074\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6986 - acc: 0.4958 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6938 - acc: 0.4895 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6944 - acc: 0.5085 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6999 - acc: 0.4884 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6960 - acc: 0.4881 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7027 - acc: 0.4829 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6999 - acc: 0.4843 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6962 - acc: 0.4973 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6939 - acc: 0.4978 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7001 - acc: 0.4861 - val_loss: 0.6899 - val_acc: 0.3857\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6942 - acc: 0.4961 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6974 - acc: 0.4973 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6966 - acc: 0.5007 - val_loss: 0.6900 - val_acc: 0.6100\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6954 - acc: 0.4950 - val_loss: 0.6899 - val_acc: 0.6100\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6937 - acc: 0.5088 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6962 - acc: 0.4987 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6970 - acc: 0.4912 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6972 - acc: 0.4927 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6937 - acc: 0.5024 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6980 - acc: 0.4875 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6981 - acc: 0.4789 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6926 - acc: 0.4999 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6965 - acc: 0.4973 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6969 - acc: 0.4993 - val_loss: 0.6899 - val_acc: 0.3917\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6943 - acc: 0.5016 - val_loss: 0.6899 - val_acc: 0.6074\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6942 - acc: 0.4964 - val_loss: 0.6899 - val_acc: 0.6100\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6924 - acc: 0.5033 - val_loss: 0.6899 - val_acc: 0.6100\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6927 - acc: 0.5108 - val_loss: 0.6899 - val_acc: 0.6074\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.6965 - acc: 0.5093 - val_loss: 0.6899 - val_acc: 0.3779\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6991 - acc: 0.4984 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6964 - acc: 0.4861 - val_loss: 0.6899 - val_acc: 0.3900\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6964 - acc: 0.4935 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6929 - acc: 0.4918 - val_loss: 0.6898 - val_acc: 0.3900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6961 - acc: 0.4921 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6959 - acc: 0.4895 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6958 - acc: 0.4817 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6929 - acc: 0.4961 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6962 - acc: 0.4835 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6920 - acc: 0.4961 - val_loss: 0.6898 - val_acc: 0.3900\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6957 - acc: 0.4699 - val_loss: 0.6897 - val_acc: 0.3900\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6918 - acc: 0.4766 - val_loss: 0.6897 - val_acc: 0.3900\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6968 - acc: 0.4760 - val_loss: 0.6897 - val_acc: 0.3900\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6938 - acc: 0.4783 - val_loss: 0.6897 - val_acc: 0.3900\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6944 - acc: 0.4924 - val_loss: 0.6897 - val_acc: 0.3805\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6940 - acc: 0.4889 - val_loss: 0.6897 - val_acc: 0.3693\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6923 - acc: 0.4835 - val_loss: 0.6897 - val_acc: 0.3650\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6923 - acc: 0.4800 - val_loss: 0.6897 - val_acc: 0.3676\n",
      "sample weight :  [1.71807827e-04 6.19105220e-05 4.41050055e-05 ... 5.15652913e-05\n",
      " 4.64087798e-05 5.09599537e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7498 - acc: 0.5976 - val_loss: 0.6831 - val_acc: 0.6169\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7350 - acc: 0.5971 - val_loss: 0.6761 - val_acc: 0.6169\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7200 - acc: 0.5789 - val_loss: 0.6711 - val_acc: 0.6169\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7178 - acc: 0.5605 - val_loss: 0.6680 - val_acc: 0.6169\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7151 - acc: 0.5315 - val_loss: 0.6668 - val_acc: 0.6169\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7125 - acc: 0.5082 - val_loss: 0.6672 - val_acc: 0.3831\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7082 - acc: 0.4737 - val_loss: 0.6689 - val_acc: 0.3831\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7116 - acc: 0.4567 - val_loss: 0.6714 - val_acc: 0.3831\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7076 - acc: 0.4409 - val_loss: 0.6738 - val_acc: 0.3831\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7143 - acc: 0.4167 - val_loss: 0.6756 - val_acc: 0.3831\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7038 - acc: 0.4216 - val_loss: 0.6764 - val_acc: 0.3831\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7123 - acc: 0.4182 - val_loss: 0.6762 - val_acc: 0.3831\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7032 - acc: 0.4248 - val_loss: 0.6755 - val_acc: 0.3831\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7091 - acc: 0.4303 - val_loss: 0.6743 - val_acc: 0.3831\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7110 - acc: 0.4228 - val_loss: 0.6730 - val_acc: 0.3831\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7032 - acc: 0.4326 - val_loss: 0.6716 - val_acc: 0.3831\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7093 - acc: 0.4395 - val_loss: 0.6704 - val_acc: 0.3831\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7076 - acc: 0.4452 - val_loss: 0.6694 - val_acc: 0.3831\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7103 - acc: 0.4613 - val_loss: 0.6685 - val_acc: 0.3831\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7049 - acc: 0.4510 - val_loss: 0.6679 - val_acc: 0.3831\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7025 - acc: 0.4587 - val_loss: 0.6675 - val_acc: 0.3831\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7049 - acc: 0.4855 - val_loss: 0.6672 - val_acc: 0.3831\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7013 - acc: 0.4771 - val_loss: 0.6670 - val_acc: 0.3831\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7052 - acc: 0.5036 - val_loss: 0.6669 - val_acc: 0.3831\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7035 - acc: 0.4898 - val_loss: 0.6668 - val_acc: 0.3831\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7119 - acc: 0.4838 - val_loss: 0.6668 - val_acc: 0.3831\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7039 - acc: 0.4941 - val_loss: 0.6668 - val_acc: 0.3831\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7034 - acc: 0.4878 - val_loss: 0.6668 - val_acc: 0.3831\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7019 - acc: 0.4935 - val_loss: 0.6668 - val_acc: 0.3831\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7104 - acc: 0.4901 - val_loss: 0.6669 - val_acc: 0.3831\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7079 - acc: 0.4740 - val_loss: 0.6669 - val_acc: 0.3831\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7027 - acc: 0.4728 - val_loss: 0.6670 - val_acc: 0.3831\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6996 - acc: 0.4849 - val_loss: 0.6671 - val_acc: 0.3831\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7066 - acc: 0.4757 - val_loss: 0.6673 - val_acc: 0.3831\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7047 - acc: 0.4800 - val_loss: 0.6674 - val_acc: 0.3831\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7121 - acc: 0.4745 - val_loss: 0.6676 - val_acc: 0.3831\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6936 - acc: 0.4737 - val_loss: 0.6678 - val_acc: 0.3831\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7010 - acc: 0.4682 - val_loss: 0.6680 - val_acc: 0.3831\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7013 - acc: 0.4636 - val_loss: 0.6683 - val_acc: 0.3831\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7081 - acc: 0.4582 - val_loss: 0.6684 - val_acc: 0.3831\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7103 - acc: 0.4633 - val_loss: 0.6686 - val_acc: 0.3831\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7045 - acc: 0.4544 - val_loss: 0.6687 - val_acc: 0.3831\n",
      "Epoch 43/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7016 - acc: 0.4659 - val_loss: 0.6687 - val_acc: 0.3831\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6968 - acc: 0.4538 - val_loss: 0.6687 - val_acc: 0.3831\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7060 - acc: 0.4616 - val_loss: 0.6687 - val_acc: 0.3831\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7113 - acc: 0.4423 - val_loss: 0.6686 - val_acc: 0.3831\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6998 - acc: 0.4573 - val_loss: 0.6685 - val_acc: 0.3831\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7001 - acc: 0.4613 - val_loss: 0.6684 - val_acc: 0.3831\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7082 - acc: 0.4441 - val_loss: 0.6683 - val_acc: 0.3831\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7089 - acc: 0.4665 - val_loss: 0.6682 - val_acc: 0.3831\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7013 - acc: 0.4524 - val_loss: 0.6681 - val_acc: 0.3831\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7065 - acc: 0.4610 - val_loss: 0.6680 - val_acc: 0.3831\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7039 - acc: 0.4547 - val_loss: 0.6679 - val_acc: 0.3831\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7072 - acc: 0.4513 - val_loss: 0.6678 - val_acc: 0.3831\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7082 - acc: 0.4616 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7061 - acc: 0.4625 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7112 - acc: 0.4553 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7036 - acc: 0.4665 - val_loss: 0.6676 - val_acc: 0.3831\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7062 - acc: 0.4541 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6999 - acc: 0.4619 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7007 - acc: 0.4622 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7020 - acc: 0.4547 - val_loss: 0.6677 - val_acc: 0.3831\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7053 - acc: 0.4518 - val_loss: 0.6678 - val_acc: 0.3831\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7045 - acc: 0.4628 - val_loss: 0.6678 - val_acc: 0.3831\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7061 - acc: 0.4530 - val_loss: 0.6679 - val_acc: 0.3831\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7034 - acc: 0.4584 - val_loss: 0.6679 - val_acc: 0.3831\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7059 - acc: 0.4495 - val_loss: 0.6679 - val_acc: 0.3831\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7018 - acc: 0.4492 - val_loss: 0.6680 - val_acc: 0.3831\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7000 - acc: 0.4622 - val_loss: 0.6680 - val_acc: 0.3831\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7045 - acc: 0.4518 - val_loss: 0.6681 - val_acc: 0.3831\n",
      "sample weight :  [1.61801656e-04 5.82670050e-05 4.70017343e-05 ... 5.48517213e-05\n",
      " 4.94380045e-05 5.41297640e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7073 - acc: 0.4386 - val_loss: 0.6964 - val_acc: 0.3952\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6959 - acc: 0.4766 - val_loss: 0.6979 - val_acc: 0.6048\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7027 - acc: 0.5042 - val_loss: 0.7004 - val_acc: 0.6048\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6986 - acc: 0.5223 - val_loss: 0.7030 - val_acc: 0.6048\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6943 - acc: 0.5614 - val_loss: 0.7046 - val_acc: 0.6048\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6973 - acc: 0.5683 - val_loss: 0.7049 - val_acc: 0.6048\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7001 - acc: 0.5778 - val_loss: 0.7043 - val_acc: 0.6048\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6950 - acc: 0.5818 - val_loss: 0.7032 - val_acc: 0.6048\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6976 - acc: 0.5660 - val_loss: 0.7020 - val_acc: 0.6048\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6948 - acc: 0.5695 - val_loss: 0.7007 - val_acc: 0.6048\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7013 - acc: 0.5516 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6987 - acc: 0.5303 - val_loss: 0.6988 - val_acc: 0.6048\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6908 - acc: 0.5367 - val_loss: 0.6982 - val_acc: 0.6048\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6953 - acc: 0.5234 - val_loss: 0.6979 - val_acc: 0.6048\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6959 - acc: 0.5139 - val_loss: 0.6978 - val_acc: 0.6048\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6934 - acc: 0.5237 - val_loss: 0.6977 - val_acc: 0.6048\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6931 - acc: 0.5125 - val_loss: 0.6979 - val_acc: 0.6048\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6899 - acc: 0.5134 - val_loss: 0.6981 - val_acc: 0.6048\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6892 - acc: 0.5217 - val_loss: 0.6984 - val_acc: 0.6048\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6971 - acc: 0.5211 - val_loss: 0.6988 - val_acc: 0.6048\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6913 - acc: 0.5381 - val_loss: 0.6993 - val_acc: 0.6048\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6906 - acc: 0.5485 - val_loss: 0.6997 - val_acc: 0.6048\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6926 - acc: 0.5562 - val_loss: 0.7001 - val_acc: 0.6048\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6947 - acc: 0.5395 - val_loss: 0.7006 - val_acc: 0.6048\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6887 - acc: 0.5718 - val_loss: 0.7009 - val_acc: 0.6048\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6943 - acc: 0.5562 - val_loss: 0.7011 - val_acc: 0.6048\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6922 - acc: 0.5700 - val_loss: 0.7012 - val_acc: 0.6048\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6930 - acc: 0.5706 - val_loss: 0.7011 - val_acc: 0.6048\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6950 - acc: 0.5608 - val_loss: 0.7010 - val_acc: 0.6048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6979 - acc: 0.5597 - val_loss: 0.7006 - val_acc: 0.6048\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6957 - acc: 0.5634 - val_loss: 0.7002 - val_acc: 0.6048\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6954 - acc: 0.5605 - val_loss: 0.6999 - val_acc: 0.6048\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6949 - acc: 0.5554 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6964 - acc: 0.5410 - val_loss: 0.6993 - val_acc: 0.6048\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6924 - acc: 0.5542 - val_loss: 0.6991 - val_acc: 0.6048\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6908 - acc: 0.5485 - val_loss: 0.6990 - val_acc: 0.6048\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6942 - acc: 0.5421 - val_loss: 0.6990 - val_acc: 0.6048\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6924 - acc: 0.5444 - val_loss: 0.6990 - val_acc: 0.6048\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6908 - acc: 0.5413 - val_loss: 0.6990 - val_acc: 0.6048\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6970 - acc: 0.5309 - val_loss: 0.6991 - val_acc: 0.6048\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6913 - acc: 0.5525 - val_loss: 0.6992 - val_acc: 0.6048\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6939 - acc: 0.5447 - val_loss: 0.6994 - val_acc: 0.6048\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6932 - acc: 0.5559 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6962 - acc: 0.5424 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6926 - acc: 0.5485 - val_loss: 0.6998 - val_acc: 0.6048\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6929 - acc: 0.5551 - val_loss: 0.6998 - val_acc: 0.6048\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6989 - acc: 0.5557 - val_loss: 0.6998 - val_acc: 0.6048\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6913 - acc: 0.5723 - val_loss: 0.6998 - val_acc: 0.6048\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6935 - acc: 0.5663 - val_loss: 0.6997 - val_acc: 0.6048\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6918 - acc: 0.5689 - val_loss: 0.6997 - val_acc: 0.6048\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6936 - acc: 0.5631 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6892 - acc: 0.5617 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6938 - acc: 0.5703 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6914 - acc: 0.5591 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6907 - acc: 0.5689 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6906 - acc: 0.5743 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6905 - acc: 0.5697 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6944 - acc: 0.5634 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6908 - acc: 0.5686 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6907 - acc: 0.5735 - val_loss: 0.6996 - val_acc: 0.6048\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6941 - acc: 0.5559 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6910 - acc: 0.5588 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6942 - acc: 0.5775 - val_loss: 0.6995 - val_acc: 0.6048\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6915 - acc: 0.5735 - val_loss: 0.6994 - val_acc: 0.6048\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6910 - acc: 0.5646 - val_loss: 0.6994 - val_acc: 0.6048\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6913 - acc: 0.5649 - val_loss: 0.6994 - val_acc: 0.6048\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6914 - acc: 0.5588 - val_loss: 0.6994 - val_acc: 0.6048\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6905 - acc: 0.5554 - val_loss: 0.6993 - val_acc: 0.6048\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6895 - acc: 0.5674 - val_loss: 0.6992 - val_acc: 0.6048\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6888 - acc: 0.5692 - val_loss: 0.6991 - val_acc: 0.6048\n",
      "sample weight :  [1.71824710e-04 6.20142810e-05 4.57510464e-05 ... 5.21302762e-05\n",
      " 4.78002272e-05 5.16093700e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6973 - acc: 0.4049 - val_loss: 0.7272 - val_acc: 0.4193\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6963 - acc: 0.4343 - val_loss: 0.7251 - val_acc: 0.4193\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6923 - acc: 0.4806 - val_loss: 0.7253 - val_acc: 0.5807\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6866 - acc: 0.5131 - val_loss: 0.7266 - val_acc: 0.5807\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6884 - acc: 0.5286 - val_loss: 0.7276 - val_acc: 0.5807\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6892 - acc: 0.5536 - val_loss: 0.7279 - val_acc: 0.5807\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6867 - acc: 0.5496 - val_loss: 0.7275 - val_acc: 0.5807\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6854 - acc: 0.5591 - val_loss: 0.7268 - val_acc: 0.5807\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6849 - acc: 0.5418 - val_loss: 0.7261 - val_acc: 0.5807\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6914 - acc: 0.5171 - val_loss: 0.7255 - val_acc: 0.5807\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6876 - acc: 0.5324 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6849 - acc: 0.5162 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6849 - acc: 0.5108 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6915 - acc: 0.4886 - val_loss: 0.7251 - val_acc: 0.4193\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6927 - acc: 0.4812 - val_loss: 0.7252 - val_acc: 0.4193\n",
      "Epoch 16/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6912 - acc: 0.4708 - val_loss: 0.7252 - val_acc: 0.4193\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6848 - acc: 0.4685 - val_loss: 0.7252 - val_acc: 0.4193\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6889 - acc: 0.4573 - val_loss: 0.7251 - val_acc: 0.4193\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6861 - acc: 0.4932 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6871 - acc: 0.4849 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 0.6858 - acc: 0.4918 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.6944 - acc: 0.5042 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6873 - acc: 0.4843 - val_loss: 0.7253 - val_acc: 0.5807\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6916 - acc: 0.5171 - val_loss: 0.7254 - val_acc: 0.5807\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6822 - acc: 0.5252 - val_loss: 0.7255 - val_acc: 0.5807\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6853 - acc: 0.5257 - val_loss: 0.7255 - val_acc: 0.5807\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6910 - acc: 0.5252 - val_loss: 0.7255 - val_acc: 0.5807\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6874 - acc: 0.5329 - val_loss: 0.7255 - val_acc: 0.5807\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6880 - acc: 0.5226 - val_loss: 0.7254 - val_acc: 0.5807\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6879 - acc: 0.5096 - val_loss: 0.7253 - val_acc: 0.5807\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6849 - acc: 0.5116 - val_loss: 0.7252 - val_acc: 0.5807\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6842 - acc: 0.5030 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6824 - acc: 0.5128 - val_loss: 0.7251 - val_acc: 0.5815\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6827 - acc: 0.5134 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6856 - acc: 0.5027 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6830 - acc: 0.5137 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6887 - acc: 0.4970 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6816 - acc: 0.4895 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6903 - acc: 0.4884 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6824 - acc: 0.4993 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6873 - acc: 0.4993 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6870 - acc: 0.5007 - val_loss: 0.7250 - val_acc: 0.4193\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6855 - acc: 0.5085 - val_loss: 0.7250 - val_acc: 0.4538\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6846 - acc: 0.5047 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6810 - acc: 0.5022 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6839 - acc: 0.4967 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6840 - acc: 0.5022 - val_loss: 0.7252 - val_acc: 0.5807\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6811 - acc: 0.5183 - val_loss: 0.7252 - val_acc: 0.5807\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6863 - acc: 0.5154 - val_loss: 0.7252 - val_acc: 0.5807\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6838 - acc: 0.5137 - val_loss: 0.7252 - val_acc: 0.5807\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6831 - acc: 0.5209 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6859 - acc: 0.4993 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6834 - acc: 0.5260 - val_loss: 0.7251 - val_acc: 0.5807\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6804 - acc: 0.5321 - val_loss: 0.7250 - val_acc: 0.5824\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6866 - acc: 0.5128 - val_loss: 0.7250 - val_acc: 0.5557\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6860 - acc: 0.5004 - val_loss: 0.7250 - val_acc: 0.5332\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6849 - acc: 0.5068 - val_loss: 0.7250 - val_acc: 0.4858\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6843 - acc: 0.5053 - val_loss: 0.7249 - val_acc: 0.4478\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6830 - acc: 0.5108 - val_loss: 0.7249 - val_acc: 0.4349\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6858 - acc: 0.4927 - val_loss: 0.7249 - val_acc: 0.4469\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6867 - acc: 0.4924 - val_loss: 0.7249 - val_acc: 0.4694\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6827 - acc: 0.5039 - val_loss: 0.7248 - val_acc: 0.5022\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6819 - acc: 0.5076 - val_loss: 0.7248 - val_acc: 0.5324\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6826 - acc: 0.5079 - val_loss: 0.7248 - val_acc: 0.5522\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6813 - acc: 0.5065 - val_loss: 0.7248 - val_acc: 0.5582\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6800 - acc: 0.5186 - val_loss: 0.7248 - val_acc: 0.5531\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6799 - acc: 0.5148 - val_loss: 0.7247 - val_acc: 0.5306\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6810 - acc: 0.5234 - val_loss: 0.7246 - val_acc: 0.5142\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6798 - acc: 0.5275 - val_loss: 0.7244 - val_acc: 0.4953\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6789 - acc: 0.5137 - val_loss: 0.7243 - val_acc: 0.4935\n",
      "sample weight :  [1.77392631e-04 6.36017307e-05 4.71189336e-05 ... 5.17815488e-05\n",
      " 4.80667498e-05 5.06385838e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7169 - acc: 0.4231 - val_loss: 0.6858 - val_acc: 0.3676\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7044 - acc: 0.4642 - val_loss: 0.6847 - val_acc: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6964 - acc: 0.4768 - val_loss: 0.6855 - val_acc: 0.6324\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7029 - acc: 0.5013 - val_loss: 0.6869 - val_acc: 0.6324\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6991 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.6324\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6981 - acc: 0.5456 - val_loss: 0.6878 - val_acc: 0.6324\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7093 - acc: 0.5450 - val_loss: 0.6873 - val_acc: 0.6324\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7044 - acc: 0.5326 - val_loss: 0.6865 - val_acc: 0.6324\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7088 - acc: 0.5151 - val_loss: 0.6857 - val_acc: 0.6324\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7077 - acc: 0.5033 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7012 - acc: 0.5076 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6996 - acc: 0.4970 - val_loss: 0.6847 - val_acc: 0.3676\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7026 - acc: 0.4829 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6983 - acc: 0.4711 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6997 - acc: 0.4671 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7050 - acc: 0.4679 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7064 - acc: 0.4688 - val_loss: 0.6847 - val_acc: 0.3676\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7031 - acc: 0.4786 - val_loss: 0.6847 - val_acc: 0.3676\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6995 - acc: 0.4881 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6953 - acc: 0.4823 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6972 - acc: 0.5119 - val_loss: 0.6850 - val_acc: 0.6324\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7050 - acc: 0.4999 - val_loss: 0.6852 - val_acc: 0.6324\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6962 - acc: 0.5091 - val_loss: 0.6854 - val_acc: 0.6324\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7053 - acc: 0.5186 - val_loss: 0.6855 - val_acc: 0.6324\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6996 - acc: 0.5108 - val_loss: 0.6855 - val_acc: 0.6324\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6958 - acc: 0.5200 - val_loss: 0.6855 - val_acc: 0.6324\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7045 - acc: 0.5128 - val_loss: 0.6854 - val_acc: 0.6324\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6979 - acc: 0.5174 - val_loss: 0.6852 - val_acc: 0.6324\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6966 - acc: 0.5076 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6952 - acc: 0.5194 - val_loss: 0.6850 - val_acc: 0.3676\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6973 - acc: 0.5188 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7002 - acc: 0.4763 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7019 - acc: 0.4699 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7020 - acc: 0.4777 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6988 - acc: 0.4705 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6985 - acc: 0.4803 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6996 - acc: 0.4783 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6941 - acc: 0.5024 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7009 - acc: 0.4800 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6994 - acc: 0.4938 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6962 - acc: 0.5171 - val_loss: 0.6850 - val_acc: 0.4374\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7009 - acc: 0.5065 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6959 - acc: 0.5047 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7021 - acc: 0.4872 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6980 - acc: 0.5065 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6965 - acc: 0.5111 - val_loss: 0.6851 - val_acc: 0.6324\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6973 - acc: 0.5091 - val_loss: 0.6850 - val_acc: 0.6324\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7025 - acc: 0.4823 - val_loss: 0.6850 - val_acc: 0.4193\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7000 - acc: 0.4990 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7001 - acc: 0.4993 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6933 - acc: 0.4967 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6992 - acc: 0.4820 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6982 - acc: 0.4898 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6981 - acc: 0.4858 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6993 - acc: 0.4751 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7008 - acc: 0.4976 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6976 - acc: 0.4642 - val_loss: 0.6848 - val_acc: 0.3676\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6980 - acc: 0.4953 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6971 - acc: 0.4993 - val_loss: 0.6849 - val_acc: 0.3676\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6996 - acc: 0.4981 - val_loss: 0.6849 - val_acc: 0.3900\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6970 - acc: 0.4999 - val_loss: 0.6850 - val_acc: 0.4987\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6958 - acc: 0.5030 - val_loss: 0.6850 - val_acc: 0.5513\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6951 - acc: 0.5091 - val_loss: 0.6850 - val_acc: 0.5686\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6978 - acc: 0.5154 - val_loss: 0.6850 - val_acc: 0.5781\n",
      "Epoch 65/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6940 - acc: 0.5068 - val_loss: 0.6850 - val_acc: 0.5677\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6956 - acc: 0.5065 - val_loss: 0.6850 - val_acc: 0.5358\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6973 - acc: 0.4953 - val_loss: 0.6849 - val_acc: 0.4702\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6987 - acc: 0.5160 - val_loss: 0.6849 - val_acc: 0.3960\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6923 - acc: 0.5042 - val_loss: 0.6848 - val_acc: 0.3753\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6956 - acc: 0.4976 - val_loss: 0.6848 - val_acc: 0.3736\n",
      "sample weight :  [1.77218476e-04 6.33034879e-05 4.78809451e-05 ... 5.23360747e-05\n",
      " 4.87189177e-05 5.08926730e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7613 - acc: 0.3857 - val_loss: 0.7353 - val_acc: 0.3891\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7443 - acc: 0.3865 - val_loss: 0.7218 - val_acc: 0.3891\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7343 - acc: 0.3874 - val_loss: 0.7102 - val_acc: 0.3891\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7235 - acc: 0.3877 - val_loss: 0.7004 - val_acc: 0.3891\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7191 - acc: 0.3920 - val_loss: 0.6924 - val_acc: 0.3891\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7153 - acc: 0.3923 - val_loss: 0.6863 - val_acc: 0.3891\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7081 - acc: 0.4153 - val_loss: 0.6822 - val_acc: 0.3891\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7045 - acc: 0.4412 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7009 - acc: 0.4596 - val_loss: 0.6793 - val_acc: 0.6109\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7073 - acc: 0.5027 - val_loss: 0.6800 - val_acc: 0.6109\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7055 - acc: 0.5206 - val_loss: 0.6811 - val_acc: 0.6109\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7035 - acc: 0.5510 - val_loss: 0.6819 - val_acc: 0.6109\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7117 - acc: 0.5536 - val_loss: 0.6821 - val_acc: 0.6109\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7056 - acc: 0.5605 - val_loss: 0.6818 - val_acc: 0.6109\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7075 - acc: 0.5539 - val_loss: 0.6812 - val_acc: 0.6109\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7043 - acc: 0.5536 - val_loss: 0.6805 - val_acc: 0.6109\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7038 - acc: 0.5404 - val_loss: 0.6799 - val_acc: 0.6109\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7049 - acc: 0.5464 - val_loss: 0.6795 - val_acc: 0.6109\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7068 - acc: 0.5217 - val_loss: 0.6793 - val_acc: 0.6109\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7064 - acc: 0.5065 - val_loss: 0.6794 - val_acc: 0.3891\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7009 - acc: 0.4901 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7028 - acc: 0.4763 - val_loss: 0.6798 - val_acc: 0.3891\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7017 - acc: 0.4768 - val_loss: 0.6802 - val_acc: 0.3891\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7032 - acc: 0.4702 - val_loss: 0.6806 - val_acc: 0.3891\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7008 - acc: 0.4593 - val_loss: 0.6809 - val_acc: 0.3891\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7076 - acc: 0.4403 - val_loss: 0.6812 - val_acc: 0.3891\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7003 - acc: 0.4521 - val_loss: 0.6815 - val_acc: 0.3891\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6998 - acc: 0.4443 - val_loss: 0.6816 - val_acc: 0.3891\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7015 - acc: 0.4449 - val_loss: 0.6817 - val_acc: 0.3891\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7050 - acc: 0.4343 - val_loss: 0.6817 - val_acc: 0.3891\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7077 - acc: 0.4397 - val_loss: 0.6816 - val_acc: 0.3891\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7057 - acc: 0.4441 - val_loss: 0.6814 - val_acc: 0.3891\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7027 - acc: 0.4420 - val_loss: 0.6813 - val_acc: 0.3891\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7005 - acc: 0.4334 - val_loss: 0.6811 - val_acc: 0.3891\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7076 - acc: 0.4441 - val_loss: 0.6809 - val_acc: 0.3891\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7000 - acc: 0.4443 - val_loss: 0.6807 - val_acc: 0.3891\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6941 - acc: 0.4720 - val_loss: 0.6805 - val_acc: 0.3891\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7029 - acc: 0.4561 - val_loss: 0.6803 - val_acc: 0.3891\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7048 - acc: 0.4498 - val_loss: 0.6801 - val_acc: 0.3891\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7012 - acc: 0.4602 - val_loss: 0.6800 - val_acc: 0.3891\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6995 - acc: 0.4561 - val_loss: 0.6798 - val_acc: 0.3891\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7016 - acc: 0.4674 - val_loss: 0.6797 - val_acc: 0.3891\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7038 - acc: 0.4559 - val_loss: 0.6797 - val_acc: 0.3891\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7065 - acc: 0.4530 - val_loss: 0.6796 - val_acc: 0.3891\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7040 - acc: 0.4789 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6995 - acc: 0.4812 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7032 - acc: 0.4944 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7031 - acc: 0.4728 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7022 - acc: 0.4797 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7034 - acc: 0.4780 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7007 - acc: 0.4907 - val_loss: 0.6795 - val_acc: 0.3891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6956 - acc: 0.4961 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7003 - acc: 0.4958 - val_loss: 0.6795 - val_acc: 0.3891\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7034 - acc: 0.4783 - val_loss: 0.6796 - val_acc: 0.3891\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6986 - acc: 0.4794 - val_loss: 0.6796 - val_acc: 0.3891\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6975 - acc: 0.4838 - val_loss: 0.6797 - val_acc: 0.3891\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6976 - acc: 0.4780 - val_loss: 0.6797 - val_acc: 0.3891\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7007 - acc: 0.4636 - val_loss: 0.6798 - val_acc: 0.3891\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.7046 - acc: 0.4596 - val_loss: 0.6798 - val_acc: 0.3891\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.7043 - acc: 0.4668 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6956 - acc: 0.4823 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6997 - acc: 0.4697 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7004 - acc: 0.4464 - val_loss: 0.6800 - val_acc: 0.3891\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7062 - acc: 0.4541 - val_loss: 0.6800 - val_acc: 0.3891\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7024 - acc: 0.4544 - val_loss: 0.6800 - val_acc: 0.3891\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6958 - acc: 0.4774 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6997 - acc: 0.4582 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7008 - acc: 0.4648 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6984 - acc: 0.4708 - val_loss: 0.6799 - val_acc: 0.3891\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7004 - acc: 0.4656 - val_loss: 0.6798 - val_acc: 0.3891\n",
      "sample weight :  [1.70384622e-04 6.09209291e-05 4.97878466e-05 ... 5.44380619e-05\n",
      " 5.07213501e-05 5.29126766e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6949 - acc: 0.5139 - val_loss: 0.7080 - val_acc: 0.6290\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7059 - acc: 0.4941 - val_loss: 0.7084 - val_acc: 0.6290\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7077 - acc: 0.5027 - val_loss: 0.7090 - val_acc: 0.3710\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6969 - acc: 0.5047 - val_loss: 0.7097 - val_acc: 0.3710\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6963 - acc: 0.4938 - val_loss: 0.7099 - val_acc: 0.3710\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6932 - acc: 0.4809 - val_loss: 0.7093 - val_acc: 0.3710\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6868 - acc: 0.5062 - val_loss: 0.7087 - val_acc: 0.6290\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6988 - acc: 0.5105 - val_loss: 0.7081 - val_acc: 0.6290\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6876 - acc: 0.5174 - val_loss: 0.7078 - val_acc: 0.6290\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6923 - acc: 0.5053 - val_loss: 0.7079 - val_acc: 0.6290\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6829 - acc: 0.5142 - val_loss: 0.7082 - val_acc: 0.6290\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6879 - acc: 0.5197 - val_loss: 0.7086 - val_acc: 0.6290\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7008 - acc: 0.4909 - val_loss: 0.7091 - val_acc: 0.3710\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6937 - acc: 0.4978 - val_loss: 0.7095 - val_acc: 0.3710\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6922 - acc: 0.4927 - val_loss: 0.7096 - val_acc: 0.3710\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6960 - acc: 0.5062 - val_loss: 0.7096 - val_acc: 0.3710\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6893 - acc: 0.5062 - val_loss: 0.7094 - val_acc: 0.3710\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6900 - acc: 0.4935 - val_loss: 0.7092 - val_acc: 0.3710\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6952 - acc: 0.4996 - val_loss: 0.7089 - val_acc: 0.3710\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6882 - acc: 0.5139 - val_loss: 0.7086 - val_acc: 0.6290\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6915 - acc: 0.5030 - val_loss: 0.7084 - val_acc: 0.6290\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6881 - acc: 0.5214 - val_loss: 0.7083 - val_acc: 0.6290\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6915 - acc: 0.4955 - val_loss: 0.7082 - val_acc: 0.6290\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6930 - acc: 0.4950 - val_loss: 0.7084 - val_acc: 0.6290\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6965 - acc: 0.4898 - val_loss: 0.7088 - val_acc: 0.6290\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6887 - acc: 0.5079 - val_loss: 0.7090 - val_acc: 0.3710\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6941 - acc: 0.4947 - val_loss: 0.7093 - val_acc: 0.3710\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6938 - acc: 0.4990 - val_loss: 0.7093 - val_acc: 0.3710\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6929 - acc: 0.4884 - val_loss: 0.7091 - val_acc: 0.3710\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6882 - acc: 0.5105 - val_loss: 0.7090 - val_acc: 0.3710\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6902 - acc: 0.4947 - val_loss: 0.7090 - val_acc: 0.3710\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6864 - acc: 0.5056 - val_loss: 0.7089 - val_acc: 0.3788\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6905 - acc: 0.5042 - val_loss: 0.7088 - val_acc: 0.4504\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6918 - acc: 0.4872 - val_loss: 0.7088 - val_acc: 0.6109\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6848 - acc: 0.5165 - val_loss: 0.7088 - val_acc: 0.5815\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6897 - acc: 0.4967 - val_loss: 0.7089 - val_acc: 0.3762\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6879 - acc: 0.5062 - val_loss: 0.7089 - val_acc: 0.3710\n",
      "Epoch 38/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6886 - acc: 0.4930 - val_loss: 0.7090 - val_acc: 0.3710\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6865 - acc: 0.4924 - val_loss: 0.7089 - val_acc: 0.3719\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6925 - acc: 0.4886 - val_loss: 0.7089 - val_acc: 0.3658\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6887 - acc: 0.5065 - val_loss: 0.7088 - val_acc: 0.3960\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6911 - acc: 0.5010 - val_loss: 0.7088 - val_acc: 0.4228\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6913 - acc: 0.4927 - val_loss: 0.7087 - val_acc: 0.6195\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6892 - acc: 0.5010 - val_loss: 0.7085 - val_acc: 0.6290\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6915 - acc: 0.5047 - val_loss: 0.7083 - val_acc: 0.6290\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6918 - acc: 0.5137 - val_loss: 0.7082 - val_acc: 0.6290\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6951 - acc: 0.4970 - val_loss: 0.7082 - val_acc: 0.6290\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6891 - acc: 0.5139 - val_loss: 0.7082 - val_acc: 0.6290\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6898 - acc: 0.4973 - val_loss: 0.7083 - val_acc: 0.6290\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6891 - acc: 0.5145 - val_loss: 0.7085 - val_acc: 0.6290\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6926 - acc: 0.4999 - val_loss: 0.7087 - val_acc: 0.5004\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6871 - acc: 0.5137 - val_loss: 0.7088 - val_acc: 0.3598\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6893 - acc: 0.5197 - val_loss: 0.7090 - val_acc: 0.3753\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6890 - acc: 0.5007 - val_loss: 0.7090 - val_acc: 0.3719\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6876 - acc: 0.5030 - val_loss: 0.7089 - val_acc: 0.3745\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6888 - acc: 0.5010 - val_loss: 0.7089 - val_acc: 0.3719\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6888 - acc: 0.4932 - val_loss: 0.7087 - val_acc: 0.3814\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6873 - acc: 0.4955 - val_loss: 0.7085 - val_acc: 0.5487\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6913 - acc: 0.5047 - val_loss: 0.7082 - val_acc: 0.6169\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6848 - acc: 0.5091 - val_loss: 0.7081 - val_acc: 0.6255\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6900 - acc: 0.5024 - val_loss: 0.7081 - val_acc: 0.6100\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6876 - acc: 0.4892 - val_loss: 0.7081 - val_acc: 0.5772\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6872 - acc: 0.5030 - val_loss: 0.7081 - val_acc: 0.5082\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6900 - acc: 0.4909 - val_loss: 0.7080 - val_acc: 0.4582\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6871 - acc: 0.4987 - val_loss: 0.7080 - val_acc: 0.4331\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6846 - acc: 0.5033 - val_loss: 0.7079 - val_acc: 0.4245\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6893 - acc: 0.4757 - val_loss: 0.7077 - val_acc: 0.4124\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6844 - acc: 0.4932 - val_loss: 0.7076 - val_acc: 0.4003\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6835 - acc: 0.4958 - val_loss: 0.7074 - val_acc: 0.3986\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6823 - acc: 0.4780 - val_loss: 0.7070 - val_acc: 0.4055\n",
      "sample weight :  [1.70592059e-04 6.15731621e-05 5.19735793e-05 ... 5.57709676e-05\n",
      " 5.28410333e-05 5.38790403e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7761 - acc: 0.3845 - val_loss: 0.7724 - val_acc: 0.3934\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7693 - acc: 0.3848 - val_loss: 0.7605 - val_acc: 0.3934\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7478 - acc: 0.3845 - val_loss: 0.7503 - val_acc: 0.3934\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7322 - acc: 0.3857 - val_loss: 0.7418 - val_acc: 0.3934\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7277 - acc: 0.3860 - val_loss: 0.7350 - val_acc: 0.3934\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7118 - acc: 0.3926 - val_loss: 0.7299 - val_acc: 0.3934\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7070 - acc: 0.3960 - val_loss: 0.7268 - val_acc: 0.3934\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6930 - acc: 0.4179 - val_loss: 0.7256 - val_acc: 0.3934\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6910 - acc: 0.4495 - val_loss: 0.7264 - val_acc: 0.3934\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6839 - acc: 0.4806 - val_loss: 0.7292 - val_acc: 0.6066\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6885 - acc: 0.5229 - val_loss: 0.7336 - val_acc: 0.6066\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6870 - acc: 0.5600 - val_loss: 0.7390 - val_acc: 0.6066\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6858 - acc: 0.5876 - val_loss: 0.7443 - val_acc: 0.6066\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6922 - acc: 0.5893 - val_loss: 0.7485 - val_acc: 0.6066\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6934 - acc: 0.5976 - val_loss: 0.7510 - val_acc: 0.6066\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6911 - acc: 0.6040 - val_loss: 0.7517 - val_acc: 0.6066\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6904 - acc: 0.6057 - val_loss: 0.7510 - val_acc: 0.6066\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6896 - acc: 0.6117 - val_loss: 0.7493 - val_acc: 0.6066\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6890 - acc: 0.6014 - val_loss: 0.7470 - val_acc: 0.6066\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6884 - acc: 0.6057 - val_loss: 0.7444 - val_acc: 0.6066\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6825 - acc: 0.6014 - val_loss: 0.7417 - val_acc: 0.6066\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6848 - acc: 0.5951 - val_loss: 0.7392 - val_acc: 0.6066\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6845 - acc: 0.5916 - val_loss: 0.7370 - val_acc: 0.6066\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6867 - acc: 0.5700 - val_loss: 0.7351 - val_acc: 0.6066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6830 - acc: 0.5781 - val_loss: 0.7334 - val_acc: 0.6066\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6807 - acc: 0.5792 - val_loss: 0.7321 - val_acc: 0.6066\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6868 - acc: 0.5720 - val_loss: 0.7310 - val_acc: 0.6066\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6840 - acc: 0.5519 - val_loss: 0.7301 - val_acc: 0.6066\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6798 - acc: 0.5536 - val_loss: 0.7294 - val_acc: 0.6066\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6831 - acc: 0.5424 - val_loss: 0.7289 - val_acc: 0.6066\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6810 - acc: 0.5326 - val_loss: 0.7286 - val_acc: 0.6066\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6837 - acc: 0.5341 - val_loss: 0.7283 - val_acc: 0.6066\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6866 - acc: 0.5206 - val_loss: 0.7281 - val_acc: 0.6066\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6865 - acc: 0.5286 - val_loss: 0.7281 - val_acc: 0.6066\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6821 - acc: 0.5165 - val_loss: 0.7281 - val_acc: 0.6066\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6859 - acc: 0.5275 - val_loss: 0.7281 - val_acc: 0.6066\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6817 - acc: 0.5341 - val_loss: 0.7282 - val_acc: 0.6066\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6823 - acc: 0.5139 - val_loss: 0.7284 - val_acc: 0.6066\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6789 - acc: 0.5349 - val_loss: 0.7286 - val_acc: 0.6066\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6816 - acc: 0.5404 - val_loss: 0.7289 - val_acc: 0.6066\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6867 - acc: 0.5298 - val_loss: 0.7292 - val_acc: 0.6066\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6846 - acc: 0.5358 - val_loss: 0.7295 - val_acc: 0.6066\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6837 - acc: 0.5424 - val_loss: 0.7299 - val_acc: 0.6066\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6901 - acc: 0.5358 - val_loss: 0.7303 - val_acc: 0.6066\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6866 - acc: 0.5510 - val_loss: 0.7306 - val_acc: 0.6066\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6842 - acc: 0.5591 - val_loss: 0.7310 - val_acc: 0.6066\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6809 - acc: 0.5680 - val_loss: 0.7314 - val_acc: 0.6066\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6800 - acc: 0.5628 - val_loss: 0.7317 - val_acc: 0.6066\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6780 - acc: 0.5723 - val_loss: 0.7321 - val_acc: 0.6066\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6825 - acc: 0.5623 - val_loss: 0.7323 - val_acc: 0.6066\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6834 - acc: 0.5674 - val_loss: 0.7326 - val_acc: 0.6066\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6839 - acc: 0.5649 - val_loss: 0.7328 - val_acc: 0.6066\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6833 - acc: 0.5643 - val_loss: 0.7329 - val_acc: 0.6066\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6854 - acc: 0.5907 - val_loss: 0.7330 - val_acc: 0.6066\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6814 - acc: 0.5769 - val_loss: 0.7330 - val_acc: 0.6066\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6842 - acc: 0.5608 - val_loss: 0.7329 - val_acc: 0.6066\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6836 - acc: 0.5666 - val_loss: 0.7329 - val_acc: 0.6066\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6843 - acc: 0.5715 - val_loss: 0.7328 - val_acc: 0.6066\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6831 - acc: 0.5649 - val_loss: 0.7327 - val_acc: 0.6066\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6854 - acc: 0.5709 - val_loss: 0.7325 - val_acc: 0.6066\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6773 - acc: 0.5715 - val_loss: 0.7324 - val_acc: 0.6066\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6843 - acc: 0.5683 - val_loss: 0.7322 - val_acc: 0.6066\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6832 - acc: 0.5715 - val_loss: 0.7320 - val_acc: 0.6066\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6816 - acc: 0.5565 - val_loss: 0.7319 - val_acc: 0.6066\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6811 - acc: 0.5643 - val_loss: 0.7318 - val_acc: 0.6066\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6878 - acc: 0.5571 - val_loss: 0.7317 - val_acc: 0.6066\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6820 - acc: 0.5666 - val_loss: 0.7316 - val_acc: 0.6066\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6827 - acc: 0.5594 - val_loss: 0.7315 - val_acc: 0.6066\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6838 - acc: 0.5663 - val_loss: 0.7314 - val_acc: 0.6066\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6845 - acc: 0.5637 - val_loss: 0.7314 - val_acc: 0.6066\n",
      "sample weight :  [1.81552724e-04 6.56338589e-05 4.88177309e-05 ... 5.22812202e-05\n",
      " 4.97282717e-05 5.05581671e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8734 - acc: 0.3911 - val_loss: 0.8264 - val_acc: 0.3805\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8433 - acc: 0.3911 - val_loss: 0.8042 - val_acc: 0.3805\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8217 - acc: 0.3911 - val_loss: 0.7840 - val_acc: 0.3805\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.7985 - acc: 0.3911 - val_loss: 0.7659 - val_acc: 0.3805\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7849 - acc: 0.3914 - val_loss: 0.7496 - val_acc: 0.3805\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7670 - acc: 0.3911 - val_loss: 0.7352 - val_acc: 0.3805\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7541 - acc: 0.3911 - val_loss: 0.7227 - val_acc: 0.3805\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7384 - acc: 0.3911 - val_loss: 0.7121 - val_acc: 0.3805\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7264 - acc: 0.3917 - val_loss: 0.7036 - val_acc: 0.3805\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7172 - acc: 0.3926 - val_loss: 0.6973 - val_acc: 0.3805\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7023 - acc: 0.4047 - val_loss: 0.6936 - val_acc: 0.3805\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7015 - acc: 0.4248 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6993 - acc: 0.4475 - val_loss: 0.6938 - val_acc: 0.3805\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6994 - acc: 0.5019 - val_loss: 0.6967 - val_acc: 0.6195\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6946 - acc: 0.5381 - val_loss: 0.7002 - val_acc: 0.6195\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7038 - acc: 0.5430 - val_loss: 0.7032 - val_acc: 0.6195\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7075 - acc: 0.5605 - val_loss: 0.7053 - val_acc: 0.6195\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7127 - acc: 0.5611 - val_loss: 0.7064 - val_acc: 0.6195\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7164 - acc: 0.5614 - val_loss: 0.7063 - val_acc: 0.6195\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7087 - acc: 0.5631 - val_loss: 0.7053 - val_acc: 0.6195\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7125 - acc: 0.5605 - val_loss: 0.7038 - val_acc: 0.6195\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7026 - acc: 0.5663 - val_loss: 0.7020 - val_acc: 0.6195\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7049 - acc: 0.5485 - val_loss: 0.7001 - val_acc: 0.6195\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6971 - acc: 0.5559 - val_loss: 0.6984 - val_acc: 0.6195\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6978 - acc: 0.5321 - val_loss: 0.6968 - val_acc: 0.6195\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6952 - acc: 0.5349 - val_loss: 0.6955 - val_acc: 0.6195\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6931 - acc: 0.5211 - val_loss: 0.6945 - val_acc: 0.4633\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6983 - acc: 0.5059 - val_loss: 0.6937 - val_acc: 0.3805\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6948 - acc: 0.4961 - val_loss: 0.6932 - val_acc: 0.3805\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6949 - acc: 0.4884 - val_loss: 0.6928 - val_acc: 0.3805\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6936 - acc: 0.4561 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6967 - acc: 0.4628 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6979 - acc: 0.4625 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6926 - acc: 0.4418 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7023 - acc: 0.4334 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6978 - acc: 0.4466 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6936 - acc: 0.4420 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6962 - acc: 0.4248 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6958 - acc: 0.4438 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6983 - acc: 0.4337 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6978 - acc: 0.4415 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6987 - acc: 0.4481 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6955 - acc: 0.4354 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7014 - acc: 0.4504 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6947 - acc: 0.4435 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6994 - acc: 0.4481 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6975 - acc: 0.4745 - val_loss: 0.6925 - val_acc: 0.3805\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6947 - acc: 0.4490 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7001 - acc: 0.4547 - val_loss: 0.6926 - val_acc: 0.3805\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6950 - acc: 0.4547 - val_loss: 0.6927 - val_acc: 0.3805\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6990 - acc: 0.4533 - val_loss: 0.6928 - val_acc: 0.3805\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6990 - acc: 0.4599 - val_loss: 0.6929 - val_acc: 0.3805\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6988 - acc: 0.4642 - val_loss: 0.6930 - val_acc: 0.3805\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6974 - acc: 0.4699 - val_loss: 0.6931 - val_acc: 0.3805\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6960 - acc: 0.4912 - val_loss: 0.6931 - val_acc: 0.3805\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6976 - acc: 0.4757 - val_loss: 0.6932 - val_acc: 0.3805\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6954 - acc: 0.4685 - val_loss: 0.6933 - val_acc: 0.3805\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6949 - acc: 0.4918 - val_loss: 0.6933 - val_acc: 0.3805\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6946 - acc: 0.4791 - val_loss: 0.6934 - val_acc: 0.3805\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6977 - acc: 0.4881 - val_loss: 0.6934 - val_acc: 0.3805\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6974 - acc: 0.4843 - val_loss: 0.6934 - val_acc: 0.3805\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6939 - acc: 0.4901 - val_loss: 0.6934 - val_acc: 0.3805\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6954 - acc: 0.4840 - val_loss: 0.6933 - val_acc: 0.3805\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6973 - acc: 0.4889 - val_loss: 0.6933 - val_acc: 0.3805\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6946 - acc: 0.4745 - val_loss: 0.6932 - val_acc: 0.3805\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6944 - acc: 0.4947 - val_loss: 0.6932 - val_acc: 0.3805\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6978 - acc: 0.4783 - val_loss: 0.6931 - val_acc: 0.3805\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6915 - acc: 0.4817 - val_loss: 0.6930 - val_acc: 0.3805\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6997 - acc: 0.4688 - val_loss: 0.6930 - val_acc: 0.3805\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7000 - acc: 0.4711 - val_loss: 0.6929 - val_acc: 0.3805\n",
      "sample weight :  [1.74532014e-04 6.31447887e-05 5.08978349e-05 ... 5.45003917e-05\n",
      " 5.18799670e-05 5.26770598e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7062 - acc: 0.4449 - val_loss: 0.6645 - val_acc: 0.3995\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7088 - acc: 0.4771 - val_loss: 0.6639 - val_acc: 0.6005\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7115 - acc: 0.4993 - val_loss: 0.6639 - val_acc: 0.6005\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7028 - acc: 0.5039 - val_loss: 0.6639 - val_acc: 0.6005\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7093 - acc: 0.5102 - val_loss: 0.6640 - val_acc: 0.3995\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7124 - acc: 0.4872 - val_loss: 0.6642 - val_acc: 0.3995\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7027 - acc: 0.4881 - val_loss: 0.6646 - val_acc: 0.3995\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7037 - acc: 0.4711 - val_loss: 0.6649 - val_acc: 0.3995\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7139 - acc: 0.4645 - val_loss: 0.6652 - val_acc: 0.3995\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7102 - acc: 0.4415 - val_loss: 0.6652 - val_acc: 0.3995\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7106 - acc: 0.4446 - val_loss: 0.6651 - val_acc: 0.3995\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7040 - acc: 0.4665 - val_loss: 0.6649 - val_acc: 0.3995\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7039 - acc: 0.4573 - val_loss: 0.6647 - val_acc: 0.3995\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7054 - acc: 0.4682 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7075 - acc: 0.4745 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7074 - acc: 0.4927 - val_loss: 0.6641 - val_acc: 0.3995\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7108 - acc: 0.4961 - val_loss: 0.6641 - val_acc: 0.3995\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7113 - acc: 0.4889 - val_loss: 0.6641 - val_acc: 0.3995\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7109 - acc: 0.4950 - val_loss: 0.6641 - val_acc: 0.3995\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7029 - acc: 0.5070 - val_loss: 0.6641 - val_acc: 0.3995\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7095 - acc: 0.4944 - val_loss: 0.6642 - val_acc: 0.3995\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7115 - acc: 0.4846 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7006 - acc: 0.4895 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7031 - acc: 0.4697 - val_loss: 0.6645 - val_acc: 0.3995\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7088 - acc: 0.4639 - val_loss: 0.6646 - val_acc: 0.3995\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7125 - acc: 0.4607 - val_loss: 0.6646 - val_acc: 0.3995\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7028 - acc: 0.4668 - val_loss: 0.6646 - val_acc: 0.3995\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7081 - acc: 0.4587 - val_loss: 0.6646 - val_acc: 0.3995\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7078 - acc: 0.4458 - val_loss: 0.6645 - val_acc: 0.3995\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7060 - acc: 0.4625 - val_loss: 0.6645 - val_acc: 0.3995\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7047 - acc: 0.4760 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7069 - acc: 0.4774 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7032 - acc: 0.4858 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7011 - acc: 0.4826 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7046 - acc: 0.4794 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7033 - acc: 0.4763 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7028 - acc: 0.4794 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7057 - acc: 0.4688 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7018 - acc: 0.4737 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7059 - acc: 0.4806 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7026 - acc: 0.4763 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7024 - acc: 0.4803 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7047 - acc: 0.4835 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7043 - acc: 0.4622 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7038 - acc: 0.4688 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7041 - acc: 0.4584 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7016 - acc: 0.4674 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7052 - acc: 0.4656 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7023 - acc: 0.4602 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7040 - acc: 0.4679 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7031 - acc: 0.4633 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7057 - acc: 0.4567 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7034 - acc: 0.4478 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7025 - acc: 0.4682 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7042 - acc: 0.4656 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7017 - acc: 0.4593 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7037 - acc: 0.4734 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7003 - acc: 0.4699 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7025 - acc: 0.4582 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7042 - acc: 0.4653 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 61/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7015 - acc: 0.4524 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7028 - acc: 0.4518 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7028 - acc: 0.4536 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7017 - acc: 0.4636 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7005 - acc: 0.4737 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7020 - acc: 0.4694 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7045 - acc: 0.4507 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7034 - acc: 0.4633 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7030 - acc: 0.4579 - val_loss: 0.6644 - val_acc: 0.3995\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7005 - acc: 0.4711 - val_loss: 0.6643 - val_acc: 0.3995\n",
      "sample weight :  [1.70640532e-04 6.17426399e-05 5.21530169e-05 ... 5.58064417e-05\n",
      " 5.31893042e-05 5.38889187e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7363 - acc: 0.4006 - val_loss: 0.6850 - val_acc: 0.3831\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7205 - acc: 0.4156 - val_loss: 0.6799 - val_acc: 0.3831\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7041 - acc: 0.4280 - val_loss: 0.6773 - val_acc: 0.3831\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7090 - acc: 0.4472 - val_loss: 0.6771 - val_acc: 0.3831\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7052 - acc: 0.4780 - val_loss: 0.6788 - val_acc: 0.6169\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7017 - acc: 0.5214 - val_loss: 0.6816 - val_acc: 0.6169\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7053 - acc: 0.5318 - val_loss: 0.6844 - val_acc: 0.6169\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7111 - acc: 0.5542 - val_loss: 0.6860 - val_acc: 0.6169\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7092 - acc: 0.5519 - val_loss: 0.6864 - val_acc: 0.6169\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7115 - acc: 0.5534 - val_loss: 0.6856 - val_acc: 0.6169\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7041 - acc: 0.5628 - val_loss: 0.6841 - val_acc: 0.6169\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7141 - acc: 0.5439 - val_loss: 0.6825 - val_acc: 0.6169\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7082 - acc: 0.5315 - val_loss: 0.6809 - val_acc: 0.6169\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7101 - acc: 0.5177 - val_loss: 0.6795 - val_acc: 0.6169\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7087 - acc: 0.5240 - val_loss: 0.6785 - val_acc: 0.6169\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7010 - acc: 0.5085 - val_loss: 0.6778 - val_acc: 0.3831\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6999 - acc: 0.4904 - val_loss: 0.6773 - val_acc: 0.3831\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7012 - acc: 0.5062 - val_loss: 0.6771 - val_acc: 0.3831\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7033 - acc: 0.4774 - val_loss: 0.6770 - val_acc: 0.3831\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7006 - acc: 0.4797 - val_loss: 0.6769 - val_acc: 0.3831\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7076 - acc: 0.4840 - val_loss: 0.6769 - val_acc: 0.3831\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7010 - acc: 0.4803 - val_loss: 0.6769 - val_acc: 0.3831\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7087 - acc: 0.4582 - val_loss: 0.6769 - val_acc: 0.3831\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7043 - acc: 0.4567 - val_loss: 0.6769 - val_acc: 0.3831\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7038 - acc: 0.4674 - val_loss: 0.6770 - val_acc: 0.3831\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7085 - acc: 0.4722 - val_loss: 0.6770 - val_acc: 0.3831\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7014 - acc: 0.4783 - val_loss: 0.6771 - val_acc: 0.3831\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7026 - acc: 0.4806 - val_loss: 0.6773 - val_acc: 0.3831\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7027 - acc: 0.4955 - val_loss: 0.6775 - val_acc: 0.3831\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7034 - acc: 0.4953 - val_loss: 0.6777 - val_acc: 0.3831\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7059 - acc: 0.4754 - val_loss: 0.6780 - val_acc: 0.4167\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7052 - acc: 0.4953 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6991 - acc: 0.5045 - val_loss: 0.6785 - val_acc: 0.6169\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7041 - acc: 0.5142 - val_loss: 0.6787 - val_acc: 0.6169\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7019 - acc: 0.5137 - val_loss: 0.6789 - val_acc: 0.6169\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7153 - acc: 0.5073 - val_loss: 0.6790 - val_acc: 0.6169\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7044 - acc: 0.5125 - val_loss: 0.6790 - val_acc: 0.6169\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7043 - acc: 0.5148 - val_loss: 0.6790 - val_acc: 0.6169\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6957 - acc: 0.5329 - val_loss: 0.6789 - val_acc: 0.6169\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7111 - acc: 0.5162 - val_loss: 0.6788 - val_acc: 0.6169\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6992 - acc: 0.5168 - val_loss: 0.6786 - val_acc: 0.6169\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6981 - acc: 0.5125 - val_loss: 0.6784 - val_acc: 0.6169\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7072 - acc: 0.4970 - val_loss: 0.6783 - val_acc: 0.6169\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7062 - acc: 0.5116 - val_loss: 0.6781 - val_acc: 0.6169\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7057 - acc: 0.4904 - val_loss: 0.6780 - val_acc: 0.4072\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7044 - acc: 0.4921 - val_loss: 0.6778 - val_acc: 0.3831\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7011 - acc: 0.4918 - val_loss: 0.6777 - val_acc: 0.3831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6979 - acc: 0.5194 - val_loss: 0.6777 - val_acc: 0.3831\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7025 - acc: 0.4987 - val_loss: 0.6776 - val_acc: 0.3831\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7015 - acc: 0.4869 - val_loss: 0.6776 - val_acc: 0.3831\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7026 - acc: 0.4866 - val_loss: 0.6776 - val_acc: 0.3831\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6994 - acc: 0.5062 - val_loss: 0.6777 - val_acc: 0.3831\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6987 - acc: 0.4987 - val_loss: 0.6777 - val_acc: 0.3831\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7030 - acc: 0.4918 - val_loss: 0.6778 - val_acc: 0.3831\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6972 - acc: 0.5001 - val_loss: 0.6778 - val_acc: 0.3831\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7004 - acc: 0.4990 - val_loss: 0.6779 - val_acc: 0.3831\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6982 - acc: 0.5042 - val_loss: 0.6780 - val_acc: 0.6169\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6974 - acc: 0.5036 - val_loss: 0.6781 - val_acc: 0.6169\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6994 - acc: 0.5007 - val_loss: 0.6781 - val_acc: 0.6169\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6956 - acc: 0.4999 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6976 - acc: 0.5188 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7050 - acc: 0.4921 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7033 - acc: 0.5001 - val_loss: 0.6783 - val_acc: 0.6169\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7021 - acc: 0.5004 - val_loss: 0.6783 - val_acc: 0.6169\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.6991 - acc: 0.5088 - val_loss: 0.6783 - val_acc: 0.6169\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7055 - acc: 0.5119 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6989 - acc: 0.5068 - val_loss: 0.6782 - val_acc: 0.6169\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6999 - acc: 0.5036 - val_loss: 0.6781 - val_acc: 0.6169\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7039 - acc: 0.4901 - val_loss: 0.6780 - val_acc: 0.5332\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7057 - acc: 0.4907 - val_loss: 0.6779 - val_acc: 0.3917\n",
      "sample weight :  [1.70428765e-04 6.16706300e-05 5.23267285e-05 ... 5.59242562e-05\n",
      " 5.33193187e-05 5.39756056e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6954 - acc: 0.4582 - val_loss: 0.7143 - val_acc: 0.3900\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6861 - acc: 0.4930 - val_loss: 0.7156 - val_acc: 0.6100\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6904 - acc: 0.5361 - val_loss: 0.7169 - val_acc: 0.6100\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6905 - acc: 0.5347 - val_loss: 0.7173 - val_acc: 0.6100\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6852 - acc: 0.5387 - val_loss: 0.7170 - val_acc: 0.6100\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6959 - acc: 0.5312 - val_loss: 0.7164 - val_acc: 0.6100\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6876 - acc: 0.5508 - val_loss: 0.7156 - val_acc: 0.6100\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6965 - acc: 0.4976 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6865 - acc: 0.5232 - val_loss: 0.7145 - val_acc: 0.6100\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6868 - acc: 0.5001 - val_loss: 0.7143 - val_acc: 0.3900\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6897 - acc: 0.4958 - val_loss: 0.7142 - val_acc: 0.3900\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6908 - acc: 0.4970 - val_loss: 0.7142 - val_acc: 0.3900\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6857 - acc: 0.4993 - val_loss: 0.7143 - val_acc: 0.3900\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6899 - acc: 0.4993 - val_loss: 0.7145 - val_acc: 0.6100\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6935 - acc: 0.5047 - val_loss: 0.7147 - val_acc: 0.6100\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6886 - acc: 0.5068 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6929 - acc: 0.5059 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6876 - acc: 0.5257 - val_loss: 0.7156 - val_acc: 0.6100\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6891 - acc: 0.5257 - val_loss: 0.7159 - val_acc: 0.6100\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6893 - acc: 0.5349 - val_loss: 0.7160 - val_acc: 0.6100\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6846 - acc: 0.5349 - val_loss: 0.7159 - val_acc: 0.6100\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6952 - acc: 0.5347 - val_loss: 0.7158 - val_acc: 0.6100\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6914 - acc: 0.5249 - val_loss: 0.7156 - val_acc: 0.6100\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6928 - acc: 0.5174 - val_loss: 0.7154 - val_acc: 0.6100\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6886 - acc: 0.5197 - val_loss: 0.7151 - val_acc: 0.6100\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6903 - acc: 0.5272 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6901 - acc: 0.5027 - val_loss: 0.7148 - val_acc: 0.6100\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6885 - acc: 0.5114 - val_loss: 0.7146 - val_acc: 0.6100\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6868 - acc: 0.5183 - val_loss: 0.7146 - val_acc: 0.6100\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6916 - acc: 0.5045 - val_loss: 0.7145 - val_acc: 0.6100\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6934 - acc: 0.4909 - val_loss: 0.7146 - val_acc: 0.6100\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6879 - acc: 0.5145 - val_loss: 0.7146 - val_acc: 0.6100\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6881 - acc: 0.5134 - val_loss: 0.7148 - val_acc: 0.6100\n",
      "Epoch 34/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6853 - acc: 0.5024 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6879 - acc: 0.5220 - val_loss: 0.7151 - val_acc: 0.6100\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6859 - acc: 0.5234 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6872 - acc: 0.5370 - val_loss: 0.7154 - val_acc: 0.6100\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6890 - acc: 0.5289 - val_loss: 0.7155 - val_acc: 0.6100\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6852 - acc: 0.5387 - val_loss: 0.7155 - val_acc: 0.6100\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6848 - acc: 0.5347 - val_loss: 0.7155 - val_acc: 0.6100\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6856 - acc: 0.5306 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6923 - acc: 0.5191 - val_loss: 0.7152 - val_acc: 0.6100\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6881 - acc: 0.5171 - val_loss: 0.7151 - val_acc: 0.6100\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6851 - acc: 0.5355 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6898 - acc: 0.5183 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6873 - acc: 0.5180 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6877 - acc: 0.5157 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6866 - acc: 0.5160 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6888 - acc: 0.5278 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6873 - acc: 0.5306 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6905 - acc: 0.5226 - val_loss: 0.7151 - val_acc: 0.6100\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6904 - acc: 0.5278 - val_loss: 0.7152 - val_acc: 0.6100\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6863 - acc: 0.5229 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6835 - acc: 0.5459 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6875 - acc: 0.5214 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6853 - acc: 0.5421 - val_loss: 0.7153 - val_acc: 0.6100\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6871 - acc: 0.5341 - val_loss: 0.7152 - val_acc: 0.6100\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6850 - acc: 0.5384 - val_loss: 0.7152 - val_acc: 0.6100\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6865 - acc: 0.5364 - val_loss: 0.7151 - val_acc: 0.6100\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6859 - acc: 0.5272 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6892 - acc: 0.5252 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6878 - acc: 0.5053 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6855 - acc: 0.5255 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6856 - acc: 0.5099 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6883 - acc: 0.5125 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6866 - acc: 0.5220 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6861 - acc: 0.5171 - val_loss: 0.7149 - val_acc: 0.6100\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6868 - acc: 0.5165 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6843 - acc: 0.5295 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6855 - acc: 0.5292 - val_loss: 0.7150 - val_acc: 0.6100\n",
      "sample weight :  [1.74473605e-04 6.31591379e-05 5.13212520e-05 ... 5.47267990e-05\n",
      " 5.23411162e-05 5.27897376e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7175 - acc: 0.3900 - val_loss: 0.7753 - val_acc: 0.3719\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7097 - acc: 0.3946 - val_loss: 0.7603 - val_acc: 0.3719\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6931 - acc: 0.4052 - val_loss: 0.7482 - val_acc: 0.3719\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6915 - acc: 0.4271 - val_loss: 0.7391 - val_acc: 0.3719\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6916 - acc: 0.4363 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6886 - acc: 0.4760 - val_loss: 0.7289 - val_acc: 0.3719\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6948 - acc: 0.4846 - val_loss: 0.7268 - val_acc: 0.6281\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6891 - acc: 0.5211 - val_loss: 0.7258 - val_acc: 0.6281\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6912 - acc: 0.5223 - val_loss: 0.7255 - val_acc: 0.6281\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6862 - acc: 0.5416 - val_loss: 0.7256 - val_acc: 0.6281\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6928 - acc: 0.5148 - val_loss: 0.7260 - val_acc: 0.6281\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6868 - acc: 0.5200 - val_loss: 0.7266 - val_acc: 0.6281\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6941 - acc: 0.4970 - val_loss: 0.7276 - val_acc: 0.6281\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6816 - acc: 0.5099 - val_loss: 0.7289 - val_acc: 0.3719\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6858 - acc: 0.5056 - val_loss: 0.7304 - val_acc: 0.3719\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6882 - acc: 0.4694 - val_loss: 0.7321 - val_acc: 0.3719\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6947 - acc: 0.4668 - val_loss: 0.7338 - val_acc: 0.3719\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6904 - acc: 0.4619 - val_loss: 0.7353 - val_acc: 0.3719\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6868 - acc: 0.4461 - val_loss: 0.7366 - val_acc: 0.3719\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6852 - acc: 0.4481 - val_loss: 0.7377 - val_acc: 0.3719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6872 - acc: 0.4415 - val_loss: 0.7386 - val_acc: 0.3719\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6866 - acc: 0.4438 - val_loss: 0.7391 - val_acc: 0.3719\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6804 - acc: 0.4544 - val_loss: 0.7393 - val_acc: 0.3719\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6870 - acc: 0.4300 - val_loss: 0.7392 - val_acc: 0.3719\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6837 - acc: 0.4314 - val_loss: 0.7389 - val_acc: 0.3719\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6902 - acc: 0.4334 - val_loss: 0.7384 - val_acc: 0.3719\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6854 - acc: 0.4328 - val_loss: 0.7378 - val_acc: 0.3719\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6845 - acc: 0.4395 - val_loss: 0.7370 - val_acc: 0.3719\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6913 - acc: 0.4349 - val_loss: 0.7361 - val_acc: 0.3719\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6939 - acc: 0.4490 - val_loss: 0.7352 - val_acc: 0.3719\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6823 - acc: 0.4510 - val_loss: 0.7343 - val_acc: 0.3719\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6857 - acc: 0.4507 - val_loss: 0.7335 - val_acc: 0.3719\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6815 - acc: 0.4570 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6846 - acc: 0.4645 - val_loss: 0.7320 - val_acc: 0.3719\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6864 - acc: 0.4820 - val_loss: 0.7315 - val_acc: 0.3719\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6873 - acc: 0.4720 - val_loss: 0.7311 - val_acc: 0.3719\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6865 - acc: 0.4768 - val_loss: 0.7309 - val_acc: 0.3719\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6818 - acc: 0.4682 - val_loss: 0.7308 - val_acc: 0.3719\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6876 - acc: 0.4717 - val_loss: 0.7309 - val_acc: 0.3719\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6873 - acc: 0.4725 - val_loss: 0.7311 - val_acc: 0.3719\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6866 - acc: 0.4734 - val_loss: 0.7313 - val_acc: 0.3719\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6911 - acc: 0.4584 - val_loss: 0.7317 - val_acc: 0.3719\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6858 - acc: 0.4636 - val_loss: 0.7320 - val_acc: 0.3719\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6818 - acc: 0.4763 - val_loss: 0.7325 - val_acc: 0.3719\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6853 - acc: 0.4702 - val_loss: 0.7330 - val_acc: 0.3719\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6890 - acc: 0.4446 - val_loss: 0.7334 - val_acc: 0.3719\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6838 - acc: 0.4564 - val_loss: 0.7338 - val_acc: 0.3719\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6874 - acc: 0.4596 - val_loss: 0.7342 - val_acc: 0.3719\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6794 - acc: 0.4587 - val_loss: 0.7344 - val_acc: 0.3719\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6815 - acc: 0.4619 - val_loss: 0.7346 - val_acc: 0.3719\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6818 - acc: 0.4513 - val_loss: 0.7346 - val_acc: 0.3719\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6827 - acc: 0.4386 - val_loss: 0.7347 - val_acc: 0.3719\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6891 - acc: 0.4435 - val_loss: 0.7346 - val_acc: 0.3719\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6856 - acc: 0.4564 - val_loss: 0.7344 - val_acc: 0.3719\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6840 - acc: 0.4501 - val_loss: 0.7342 - val_acc: 0.3719\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6853 - acc: 0.4438 - val_loss: 0.7341 - val_acc: 0.3719\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6888 - acc: 0.4501 - val_loss: 0.7339 - val_acc: 0.3719\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6854 - acc: 0.4443 - val_loss: 0.7337 - val_acc: 0.3719\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6905 - acc: 0.4524 - val_loss: 0.7335 - val_acc: 0.3719\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6851 - acc: 0.4492 - val_loss: 0.7333 - val_acc: 0.3719\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6813 - acc: 0.4484 - val_loss: 0.7331 - val_acc: 0.3719\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6803 - acc: 0.4573 - val_loss: 0.7329 - val_acc: 0.3719\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6814 - acc: 0.4622 - val_loss: 0.7328 - val_acc: 0.3719\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6835 - acc: 0.4561 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6822 - acc: 0.4596 - val_loss: 0.7328 - val_acc: 0.3719\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6871 - acc: 0.4538 - val_loss: 0.7328 - val_acc: 0.3719\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6797 - acc: 0.4607 - val_loss: 0.7328 - val_acc: 0.3719\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6779 - acc: 0.4633 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6865 - acc: 0.4587 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.6874 - acc: 0.4469 - val_loss: 0.7327 - val_acc: 0.3719\n",
      "sample weight :  [1.65048708e-04 5.97388077e-05 5.41743120e-05 ... 5.77139142e-05\n",
      " 5.53306458e-05 5.56960694e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7049 - acc: 0.5580 - val_loss: 0.6589 - val_acc: 0.6238\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7029 - acc: 0.5407 - val_loss: 0.6611 - val_acc: 0.6238\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7112 - acc: 0.4918 - val_loss: 0.6625 - val_acc: 0.3762\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7097 - acc: 0.5102 - val_loss: 0.6627 - val_acc: 0.3762\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7075 - acc: 0.4789 - val_loss: 0.6620 - val_acc: 0.3762\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7079 - acc: 0.4855 - val_loss: 0.6609 - val_acc: 0.6238\n",
      "Epoch 7/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7095 - acc: 0.5019 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7098 - acc: 0.5232 - val_loss: 0.6593 - val_acc: 0.6238\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7058 - acc: 0.5266 - val_loss: 0.6589 - val_acc: 0.6238\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7057 - acc: 0.5139 - val_loss: 0.6587 - val_acc: 0.6238\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7023 - acc: 0.5542 - val_loss: 0.6586 - val_acc: 0.6238\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7095 - acc: 0.5272 - val_loss: 0.6587 - val_acc: 0.6238\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7098 - acc: 0.5209 - val_loss: 0.6590 - val_acc: 0.6238\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7041 - acc: 0.5444 - val_loss: 0.6594 - val_acc: 0.6238\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7109 - acc: 0.5217 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7175 - acc: 0.5042 - val_loss: 0.6602 - val_acc: 0.6238\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7086 - acc: 0.5059 - val_loss: 0.6605 - val_acc: 0.6238\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7012 - acc: 0.5194 - val_loss: 0.6607 - val_acc: 0.6238\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7077 - acc: 0.5093 - val_loss: 0.6607 - val_acc: 0.6238\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6987 - acc: 0.5217 - val_loss: 0.6606 - val_acc: 0.6238\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7061 - acc: 0.4872 - val_loss: 0.6605 - val_acc: 0.6238\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7134 - acc: 0.4964 - val_loss: 0.6604 - val_acc: 0.6238\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7052 - acc: 0.5062 - val_loss: 0.6602 - val_acc: 0.6238\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7140 - acc: 0.4967 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7085 - acc: 0.5154 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7090 - acc: 0.5157 - val_loss: 0.6597 - val_acc: 0.6238\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7042 - acc: 0.5280 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7044 - acc: 0.5329 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7068 - acc: 0.5301 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6989 - acc: 0.5341 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7061 - acc: 0.5413 - val_loss: 0.6597 - val_acc: 0.6238\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7059 - acc: 0.5232 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7086 - acc: 0.5220 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7059 - acc: 0.5214 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7037 - acc: 0.5289 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7090 - acc: 0.5056 - val_loss: 0.6601 - val_acc: 0.6238\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7040 - acc: 0.5125 - val_loss: 0.6602 - val_acc: 0.6238\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7036 - acc: 0.5108 - val_loss: 0.6601 - val_acc: 0.6238\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7092 - acc: 0.5134 - val_loss: 0.6601 - val_acc: 0.6238\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7022 - acc: 0.5145 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7056 - acc: 0.5246 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7050 - acc: 0.5384 - val_loss: 0.6597 - val_acc: 0.6238\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7066 - acc: 0.5240 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7064 - acc: 0.5275 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7053 - acc: 0.5349 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7059 - acc: 0.5286 - val_loss: 0.6596 - val_acc: 0.6238\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7040 - acc: 0.5436 - val_loss: 0.6597 - val_acc: 0.6238\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7072 - acc: 0.5200 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7048 - acc: 0.5128 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7041 - acc: 0.5191 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7062 - acc: 0.5194 - val_loss: 0.6600 - val_acc: 0.6238\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7041 - acc: 0.5209 - val_loss: 0.6599 - val_acc: 0.6238\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7060 - acc: 0.5393 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7047 - acc: 0.5220 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7022 - acc: 0.5344 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7037 - acc: 0.5243 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7058 - acc: 0.5206 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7053 - acc: 0.5229 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7037 - acc: 0.5162 - val_loss: 0.6598 - val_acc: 0.6238\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7021 - acc: 0.5234 - val_loss: 0.6597 - val_acc: 0.6238\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7046 - acc: 0.5096 - val_loss: 0.6596 - val_acc: 0.6238\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7021 - acc: 0.5269 - val_loss: 0.6595 - val_acc: 0.6238\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7009 - acc: 0.5263 - val_loss: 0.6593 - val_acc: 0.6238\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7042 - acc: 0.5200 - val_loss: 0.6591 - val_acc: 0.6238\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7036 - acc: 0.5260 - val_loss: 0.6589 - val_acc: 0.6238\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7007 - acc: 0.5301 - val_loss: 0.6587 - val_acc: 0.6238\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7010 - acc: 0.5272 - val_loss: 0.6584 - val_acc: 0.6238\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6986 - acc: 0.5165 - val_loss: 0.6581 - val_acc: 0.6169\n",
      "Epoch 69/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6960 - acc: 0.5329 - val_loss: 0.6578 - val_acc: 0.6057\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6972 - acc: 0.5177 - val_loss: 0.6573 - val_acc: 0.5884\n",
      "sample weight :  [1.72401457e-04 6.29913768e-05 5.31745842e-05 ... 5.65518822e-05\n",
      " 5.48392160e-05 5.51061434e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7301 - acc: 0.4026 - val_loss: 0.7688 - val_acc: 0.3658\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7176 - acc: 0.4058 - val_loss: 0.7538 - val_acc: 0.3658\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7127 - acc: 0.4118 - val_loss: 0.7415 - val_acc: 0.3658\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7004 - acc: 0.4340 - val_loss: 0.7319 - val_acc: 0.3658\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6916 - acc: 0.4587 - val_loss: 0.7251 - val_acc: 0.3658\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6867 - acc: 0.4904 - val_loss: 0.7207 - val_acc: 0.6342\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6952 - acc: 0.5013 - val_loss: 0.7184 - val_acc: 0.6342\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6914 - acc: 0.5398 - val_loss: 0.7176 - val_acc: 0.6342\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6977 - acc: 0.5513 - val_loss: 0.7175 - val_acc: 0.6342\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7016 - acc: 0.5430 - val_loss: 0.7176 - val_acc: 0.6342\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6961 - acc: 0.5513 - val_loss: 0.7176 - val_acc: 0.6342\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6923 - acc: 0.5551 - val_loss: 0.7175 - val_acc: 0.6342\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6956 - acc: 0.5485 - val_loss: 0.7176 - val_acc: 0.6342\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6866 - acc: 0.5620 - val_loss: 0.7178 - val_acc: 0.6342\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6954 - acc: 0.5255 - val_loss: 0.7182 - val_acc: 0.6342\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6914 - acc: 0.5226 - val_loss: 0.7189 - val_acc: 0.6342\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6910 - acc: 0.5211 - val_loss: 0.7198 - val_acc: 0.6342\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6929 - acc: 0.5047 - val_loss: 0.7208 - val_acc: 0.6342\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6894 - acc: 0.5232 - val_loss: 0.7220 - val_acc: 0.3658\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6923 - acc: 0.4976 - val_loss: 0.7231 - val_acc: 0.3658\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6874 - acc: 0.4814 - val_loss: 0.7241 - val_acc: 0.3658\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6869 - acc: 0.4835 - val_loss: 0.7249 - val_acc: 0.3658\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6856 - acc: 0.4832 - val_loss: 0.7256 - val_acc: 0.3658\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6936 - acc: 0.4780 - val_loss: 0.7260 - val_acc: 0.3658\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6929 - acc: 0.4745 - val_loss: 0.7263 - val_acc: 0.3658\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6931 - acc: 0.4728 - val_loss: 0.7263 - val_acc: 0.3658\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6878 - acc: 0.4763 - val_loss: 0.7261 - val_acc: 0.3658\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6924 - acc: 0.4613 - val_loss: 0.7258 - val_acc: 0.3658\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6848 - acc: 0.4935 - val_loss: 0.7252 - val_acc: 0.3658\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6935 - acc: 0.4728 - val_loss: 0.7246 - val_acc: 0.3658\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6910 - acc: 0.4697 - val_loss: 0.7239 - val_acc: 0.3658\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6924 - acc: 0.4780 - val_loss: 0.7232 - val_acc: 0.3658\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6912 - acc: 0.4768 - val_loss: 0.7226 - val_acc: 0.3658\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6901 - acc: 0.4766 - val_loss: 0.7220 - val_acc: 0.3658\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6886 - acc: 0.4838 - val_loss: 0.7216 - val_acc: 0.3658\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6948 - acc: 0.4984 - val_loss: 0.7212 - val_acc: 0.6342\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6875 - acc: 0.5088 - val_loss: 0.7208 - val_acc: 0.6342\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6913 - acc: 0.5059 - val_loss: 0.7205 - val_acc: 0.6342\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6880 - acc: 0.4987 - val_loss: 0.7204 - val_acc: 0.6342\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6893 - acc: 0.4973 - val_loss: 0.7202 - val_acc: 0.6342\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6855 - acc: 0.5257 - val_loss: 0.7202 - val_acc: 0.6342\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6887 - acc: 0.5102 - val_loss: 0.7202 - val_acc: 0.6342\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6906 - acc: 0.4892 - val_loss: 0.7202 - val_acc: 0.6342\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6834 - acc: 0.5111 - val_loss: 0.7203 - val_acc: 0.6342\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6874 - acc: 0.5108 - val_loss: 0.7204 - val_acc: 0.6342\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6832 - acc: 0.5197 - val_loss: 0.7205 - val_acc: 0.6342\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6888 - acc: 0.5151 - val_loss: 0.7207 - val_acc: 0.6342\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6873 - acc: 0.5073 - val_loss: 0.7209 - val_acc: 0.6342\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6860 - acc: 0.5065 - val_loss: 0.7211 - val_acc: 0.6342\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6868 - acc: 0.4947 - val_loss: 0.7213 - val_acc: 0.6342\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6874 - acc: 0.5016 - val_loss: 0.7215 - val_acc: 0.3667\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6920 - acc: 0.4921 - val_loss: 0.7217 - val_acc: 0.3658\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6860 - acc: 0.4912 - val_loss: 0.7218 - val_acc: 0.3658\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6883 - acc: 0.5079 - val_loss: 0.7219 - val_acc: 0.3658\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6881 - acc: 0.4858 - val_loss: 0.7220 - val_acc: 0.3658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6861 - acc: 0.4886 - val_loss: 0.7221 - val_acc: 0.3658\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6852 - acc: 0.4993 - val_loss: 0.7221 - val_acc: 0.3658\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6902 - acc: 0.4884 - val_loss: 0.7221 - val_acc: 0.3658\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6930 - acc: 0.4789 - val_loss: 0.7221 - val_acc: 0.3658\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6861 - acc: 0.5010 - val_loss: 0.7220 - val_acc: 0.3658\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6898 - acc: 0.5010 - val_loss: 0.7219 - val_acc: 0.3658\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6856 - acc: 0.4944 - val_loss: 0.7218 - val_acc: 0.3658\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6875 - acc: 0.5001 - val_loss: 0.7217 - val_acc: 0.3658\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6867 - acc: 0.4932 - val_loss: 0.7216 - val_acc: 0.3684\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6908 - acc: 0.4987 - val_loss: 0.7214 - val_acc: 0.4107\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6919 - acc: 0.4961 - val_loss: 0.7213 - val_acc: 0.4918\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6875 - acc: 0.4990 - val_loss: 0.7212 - val_acc: 0.6117\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6850 - acc: 0.5096 - val_loss: 0.7212 - val_acc: 0.6333\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6898 - acc: 0.5091 - val_loss: 0.7211 - val_acc: 0.6342\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6910 - acc: 0.5128 - val_loss: 0.7211 - val_acc: 0.6342\n",
      "sample weight :  [1.73122014e-04 6.32432598e-05 5.31485077e-05 ... 5.63753231e-05\n",
      " 5.47939235e-05 5.48379157e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7243 - acc: 0.6066 - val_loss: 0.7105 - val_acc: 0.6014\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7128 - acc: 0.5988 - val_loss: 0.7041 - val_acc: 0.6014\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7098 - acc: 0.5838 - val_loss: 0.6997 - val_acc: 0.6014\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7047 - acc: 0.5623 - val_loss: 0.6972 - val_acc: 0.6014\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6941 - acc: 0.5387 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6988 - acc: 0.5211 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7028 - acc: 0.4829 - val_loss: 0.6980 - val_acc: 0.3986\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6959 - acc: 0.4843 - val_loss: 0.6994 - val_acc: 0.3986\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6984 - acc: 0.4553 - val_loss: 0.7003 - val_acc: 0.3986\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6982 - acc: 0.4418 - val_loss: 0.7006 - val_acc: 0.3986\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7036 - acc: 0.4308 - val_loss: 0.7004 - val_acc: 0.3986\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6981 - acc: 0.4369 - val_loss: 0.6998 - val_acc: 0.3986\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6961 - acc: 0.4420 - val_loss: 0.6990 - val_acc: 0.3986\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6958 - acc: 0.4567 - val_loss: 0.6982 - val_acc: 0.3986\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6937 - acc: 0.4717 - val_loss: 0.6975 - val_acc: 0.3986\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6895 - acc: 0.4789 - val_loss: 0.6970 - val_acc: 0.3986\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6954 - acc: 0.4832 - val_loss: 0.6966 - val_acc: 0.3986\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6971 - acc: 0.4800 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6951 - acc: 0.5065 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6984 - acc: 0.4829 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6996 - acc: 0.5174 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7007 - acc: 0.5079 - val_loss: 0.6965 - val_acc: 0.6014\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6960 - acc: 0.5324 - val_loss: 0.6965 - val_acc: 0.6014\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6969 - acc: 0.5200 - val_loss: 0.6966 - val_acc: 0.6014\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7020 - acc: 0.5160 - val_loss: 0.6966 - val_acc: 0.6014\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7020 - acc: 0.5022 - val_loss: 0.6965 - val_acc: 0.6014\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6944 - acc: 0.5321 - val_loss: 0.6965 - val_acc: 0.6014\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6976 - acc: 0.5211 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6966 - acc: 0.5344 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6945 - acc: 0.5278 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6901 - acc: 0.5301 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6929 - acc: 0.5171 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6945 - acc: 0.5070 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6947 - acc: 0.5096 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6967 - acc: 0.4915 - val_loss: 0.6965 - val_acc: 0.3986\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6931 - acc: 0.5019 - val_loss: 0.6966 - val_acc: 0.3986\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6975 - acc: 0.4794 - val_loss: 0.6967 - val_acc: 0.3986\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6970 - acc: 0.4708 - val_loss: 0.6967 - val_acc: 0.3986\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6946 - acc: 0.4904 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6948 - acc: 0.4875 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6974 - acc: 0.4789 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 42/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6918 - acc: 0.4855 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6969 - acc: 0.4809 - val_loss: 0.6968 - val_acc: 0.3986\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7003 - acc: 0.4771 - val_loss: 0.6967 - val_acc: 0.3986\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6986 - acc: 0.4855 - val_loss: 0.6967 - val_acc: 0.3986\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6945 - acc: 0.4976 - val_loss: 0.6966 - val_acc: 0.3986\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6951 - acc: 0.4863 - val_loss: 0.6966 - val_acc: 0.3986\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6977 - acc: 0.5001 - val_loss: 0.6965 - val_acc: 0.3986\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6938 - acc: 0.4932 - val_loss: 0.6965 - val_acc: 0.3986\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6900 - acc: 0.5024 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6937 - acc: 0.5007 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6964 - acc: 0.4938 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6924 - acc: 0.5134 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6901 - acc: 0.5056 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6957 - acc: 0.4999 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6969 - acc: 0.5016 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6948 - acc: 0.5027 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6983 - acc: 0.4950 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6962 - acc: 0.4904 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6957 - acc: 0.5039 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6977 - acc: 0.4996 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6929 - acc: 0.4967 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6946 - acc: 0.5062 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6951 - acc: 0.5099 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6944 - acc: 0.5030 - val_loss: 0.6964 - val_acc: 0.6014\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6921 - acc: 0.5114 - val_loss: 0.6964 - val_acc: 0.5979\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6945 - acc: 0.4967 - val_loss: 0.6964 - val_acc: 0.5695\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6990 - acc: 0.4901 - val_loss: 0.6964 - val_acc: 0.4849\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6909 - acc: 0.5088 - val_loss: 0.6964 - val_acc: 0.4538\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6926 - acc: 0.4987 - val_loss: 0.6965 - val_acc: 0.4305\n",
      "sample weight :  [1.73285689e-04 6.32581614e-05 5.33153420e-05 ... 5.63923171e-05\n",
      " 5.49110430e-05 5.48401980e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7170 - acc: 0.5672 - val_loss: 0.6748 - val_acc: 0.6238\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7075 - acc: 0.5312 - val_loss: 0.6781 - val_acc: 0.6238\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6937 - acc: 0.5114 - val_loss: 0.6825 - val_acc: 0.3762\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7040 - acc: 0.4694 - val_loss: 0.6866 - val_acc: 0.3762\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7068 - acc: 0.4633 - val_loss: 0.6889 - val_acc: 0.3762\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7107 - acc: 0.4556 - val_loss: 0.6891 - val_acc: 0.3762\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7023 - acc: 0.4527 - val_loss: 0.6881 - val_acc: 0.3762\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7063 - acc: 0.4412 - val_loss: 0.6863 - val_acc: 0.3762\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7000 - acc: 0.4659 - val_loss: 0.6844 - val_acc: 0.3762\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7145 - acc: 0.4676 - val_loss: 0.6825 - val_acc: 0.3762\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7027 - acc: 0.4760 - val_loss: 0.6809 - val_acc: 0.3762\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7039 - acc: 0.4869 - val_loss: 0.6796 - val_acc: 0.3762\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7037 - acc: 0.5004 - val_loss: 0.6786 - val_acc: 0.6238\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7038 - acc: 0.5001 - val_loss: 0.6780 - val_acc: 0.6238\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7071 - acc: 0.5030 - val_loss: 0.6777 - val_acc: 0.6238\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7028 - acc: 0.5289 - val_loss: 0.6777 - val_acc: 0.6238\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6999 - acc: 0.5134 - val_loss: 0.6778 - val_acc: 0.6238\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7062 - acc: 0.5142 - val_loss: 0.6782 - val_acc: 0.6238\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7082 - acc: 0.5062 - val_loss: 0.6787 - val_acc: 0.6238\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6985 - acc: 0.5010 - val_loss: 0.6794 - val_acc: 0.3762\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6974 - acc: 0.5085 - val_loss: 0.6802 - val_acc: 0.3762\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7029 - acc: 0.4852 - val_loss: 0.6809 - val_acc: 0.3762\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7022 - acc: 0.4941 - val_loss: 0.6817 - val_acc: 0.3762\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7044 - acc: 0.4754 - val_loss: 0.6824 - val_acc: 0.3762\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7059 - acc: 0.4674 - val_loss: 0.6828 - val_acc: 0.3762\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6975 - acc: 0.4731 - val_loss: 0.6830 - val_acc: 0.3762\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7032 - acc: 0.4697 - val_loss: 0.6830 - val_acc: 0.3762\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7003 - acc: 0.4679 - val_loss: 0.6829 - val_acc: 0.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7010 - acc: 0.4754 - val_loss: 0.6826 - val_acc: 0.3762\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7076 - acc: 0.4676 - val_loss: 0.6822 - val_acc: 0.3762\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6961 - acc: 0.4846 - val_loss: 0.6817 - val_acc: 0.3762\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6997 - acc: 0.4814 - val_loss: 0.6812 - val_acc: 0.3762\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6986 - acc: 0.4866 - val_loss: 0.6807 - val_acc: 0.3762\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7008 - acc: 0.4892 - val_loss: 0.6803 - val_acc: 0.3762\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7037 - acc: 0.4909 - val_loss: 0.6799 - val_acc: 0.3762\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7015 - acc: 0.5042 - val_loss: 0.6796 - val_acc: 0.3762\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7074 - acc: 0.4901 - val_loss: 0.6794 - val_acc: 0.3762\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7033 - acc: 0.4878 - val_loss: 0.6793 - val_acc: 0.6152\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6999 - acc: 0.5111 - val_loss: 0.6793 - val_acc: 0.4012\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7014 - acc: 0.4912 - val_loss: 0.6795 - val_acc: 0.3762\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6990 - acc: 0.4915 - val_loss: 0.6797 - val_acc: 0.3762\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7030 - acc: 0.4987 - val_loss: 0.6800 - val_acc: 0.3762\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6991 - acc: 0.4993 - val_loss: 0.6803 - val_acc: 0.3762\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6993 - acc: 0.4904 - val_loss: 0.6806 - val_acc: 0.3762\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6966 - acc: 0.4760 - val_loss: 0.6809 - val_acc: 0.3762\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7062 - acc: 0.4826 - val_loss: 0.6811 - val_acc: 0.3762\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7025 - acc: 0.4763 - val_loss: 0.6813 - val_acc: 0.3762\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6989 - acc: 0.4835 - val_loss: 0.6813 - val_acc: 0.3762\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7050 - acc: 0.4743 - val_loss: 0.6814 - val_acc: 0.3762\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7007 - acc: 0.4786 - val_loss: 0.6813 - val_acc: 0.3762\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6971 - acc: 0.4941 - val_loss: 0.6812 - val_acc: 0.3762\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6995 - acc: 0.4751 - val_loss: 0.6810 - val_acc: 0.3762\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6943 - acc: 0.4878 - val_loss: 0.6807 - val_acc: 0.3762\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7012 - acc: 0.4780 - val_loss: 0.6804 - val_acc: 0.3762\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7001 - acc: 0.4814 - val_loss: 0.6803 - val_acc: 0.3762\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7010 - acc: 0.5088 - val_loss: 0.6801 - val_acc: 0.3762\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6992 - acc: 0.4768 - val_loss: 0.6801 - val_acc: 0.3762\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6983 - acc: 0.4999 - val_loss: 0.6801 - val_acc: 0.3762\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7005 - acc: 0.4915 - val_loss: 0.6801 - val_acc: 0.3762\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6973 - acc: 0.4835 - val_loss: 0.6802 - val_acc: 0.3762\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6992 - acc: 0.4912 - val_loss: 0.6804 - val_acc: 0.3762\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7007 - acc: 0.4688 - val_loss: 0.6805 - val_acc: 0.3762\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6986 - acc: 0.4651 - val_loss: 0.6805 - val_acc: 0.3762\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6996 - acc: 0.4754 - val_loss: 0.6805 - val_acc: 0.3762\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6988 - acc: 0.4771 - val_loss: 0.6806 - val_acc: 0.3762\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6964 - acc: 0.5016 - val_loss: 0.6807 - val_acc: 0.3762\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6984 - acc: 0.4809 - val_loss: 0.6809 - val_acc: 0.3762\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6955 - acc: 0.4780 - val_loss: 0.6810 - val_acc: 0.3762\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6980 - acc: 0.4797 - val_loss: 0.6812 - val_acc: 0.3762\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7024 - acc: 0.4699 - val_loss: 0.6812 - val_acc: 0.3762\n",
      "sample weight :  [1.69843790e-04 6.20124898e-05 5.45065538e-05 ... 5.75586018e-05\n",
      " 5.61980138e-05 5.59268163e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6845 - acc: 0.4213 - val_loss: 0.7563 - val_acc: 0.4003\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6878 - acc: 0.4400 - val_loss: 0.7526 - val_acc: 0.4003\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6814 - acc: 0.4731 - val_loss: 0.7510 - val_acc: 0.5997\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6713 - acc: 0.5295 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6806 - acc: 0.5341 - val_loss: 0.7518 - val_acc: 0.5997\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6811 - acc: 0.5605 - val_loss: 0.7527 - val_acc: 0.5997\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6805 - acc: 0.5605 - val_loss: 0.7531 - val_acc: 0.5997\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6744 - acc: 0.5755 - val_loss: 0.7528 - val_acc: 0.5997\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6795 - acc: 0.5732 - val_loss: 0.7523 - val_acc: 0.5997\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6750 - acc: 0.5689 - val_loss: 0.7517 - val_acc: 0.5997\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6879 - acc: 0.5456 - val_loss: 0.7511 - val_acc: 0.5997\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6768 - acc: 0.5536 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6787 - acc: 0.5338 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6782 - acc: 0.5194 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 15/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6734 - acc: 0.5186 - val_loss: 0.7511 - val_acc: 0.4003\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6815 - acc: 0.4955 - val_loss: 0.7514 - val_acc: 0.4003\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6854 - acc: 0.4858 - val_loss: 0.7517 - val_acc: 0.4003\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6813 - acc: 0.4886 - val_loss: 0.7518 - val_acc: 0.4003\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6749 - acc: 0.4892 - val_loss: 0.7518 - val_acc: 0.4003\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6775 - acc: 0.4817 - val_loss: 0.7517 - val_acc: 0.4003\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6813 - acc: 0.4846 - val_loss: 0.7515 - val_acc: 0.4003\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6745 - acc: 0.4990 - val_loss: 0.7513 - val_acc: 0.4003\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6745 - acc: 0.5001 - val_loss: 0.7511 - val_acc: 0.5997\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6796 - acc: 0.5010 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6769 - acc: 0.5122 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6756 - acc: 0.5174 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6800 - acc: 0.5157 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6765 - acc: 0.5283 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6773 - acc: 0.5318 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6792 - acc: 0.5413 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6757 - acc: 0.5528 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6738 - acc: 0.5557 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6758 - acc: 0.5522 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6801 - acc: 0.5352 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.6812 - acc: 0.5416 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.6744 - acc: 0.5344 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6775 - acc: 0.5295 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6726 - acc: 0.5367 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6751 - acc: 0.5390 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6785 - acc: 0.5171 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6772 - acc: 0.5142 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6754 - acc: 0.5151 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6752 - acc: 0.5116 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6772 - acc: 0.4961 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6776 - acc: 0.5019 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6761 - acc: 0.5134 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6748 - acc: 0.5220 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6734 - acc: 0.5289 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6707 - acc: 0.5361 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6690 - acc: 0.5395 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6774 - acc: 0.5165 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6732 - acc: 0.5444 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6764 - acc: 0.5436 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6772 - acc: 0.5341 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6752 - acc: 0.5370 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6756 - acc: 0.5421 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6740 - acc: 0.5490 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6768 - acc: 0.5433 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6789 - acc: 0.5272 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6750 - acc: 0.5338 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6768 - acc: 0.5312 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6766 - acc: 0.5246 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6755 - acc: 0.5344 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6761 - acc: 0.5303 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6751 - acc: 0.5306 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6784 - acc: 0.5349 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6712 - acc: 0.5341 - val_loss: 0.7508 - val_acc: 0.5997\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6747 - acc: 0.5260 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6753 - acc: 0.5298 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6753 - acc: 0.5280 - val_loss: 0.7509 - val_acc: 0.5997\n",
      "sample weight :  [1.73351773e-04 6.32362309e-05 5.35976468e-05 ... 5.64426828e-05\n",
      " 5.51638807e-05 5.48707839e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 0.6917 - acc: 0.4225 - val_loss: 0.7846 - val_acc: 0.3745\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6807 - acc: 0.4386 - val_loss: 0.7801 - val_acc: 0.3745\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6750 - acc: 0.4766 - val_loss: 0.7784 - val_acc: 0.3745\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6734 - acc: 0.5024 - val_loss: 0.7788 - val_acc: 0.6255\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6731 - acc: 0.5309 - val_loss: 0.7802 - val_acc: 0.6255\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6761 - acc: 0.5312 - val_loss: 0.7813 - val_acc: 0.6255\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6685 - acc: 0.5686 - val_loss: 0.7814 - val_acc: 0.6255\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6743 - acc: 0.5706 - val_loss: 0.7810 - val_acc: 0.6255\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6768 - acc: 0.5407 - val_loss: 0.7802 - val_acc: 0.6255\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6743 - acc: 0.5482 - val_loss: 0.7794 - val_acc: 0.6255\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6691 - acc: 0.5378 - val_loss: 0.7788 - val_acc: 0.6255\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6707 - acc: 0.5226 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6700 - acc: 0.5211 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6750 - acc: 0.4898 - val_loss: 0.7785 - val_acc: 0.3745\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6694 - acc: 0.4955 - val_loss: 0.7787 - val_acc: 0.3745\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6719 - acc: 0.4800 - val_loss: 0.7789 - val_acc: 0.3745\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6779 - acc: 0.4907 - val_loss: 0.7789 - val_acc: 0.3745\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6689 - acc: 0.4924 - val_loss: 0.7789 - val_acc: 0.3745\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6687 - acc: 0.4840 - val_loss: 0.7788 - val_acc: 0.3745\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6730 - acc: 0.4809 - val_loss: 0.7787 - val_acc: 0.3745\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6687 - acc: 0.4866 - val_loss: 0.7785 - val_acc: 0.3745\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6666 - acc: 0.4835 - val_loss: 0.7784 - val_acc: 0.3745\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6699 - acc: 0.5013 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6751 - acc: 0.5036 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6710 - acc: 0.5145 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6699 - acc: 0.5162 - val_loss: 0.7785 - val_acc: 0.6255\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6743 - acc: 0.5102 - val_loss: 0.7785 - val_acc: 0.6255\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6658 - acc: 0.5286 - val_loss: 0.7786 - val_acc: 0.6255\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6675 - acc: 0.5272 - val_loss: 0.7786 - val_acc: 0.6255\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6689 - acc: 0.5223 - val_loss: 0.7786 - val_acc: 0.6255\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6735 - acc: 0.5263 - val_loss: 0.7786 - val_acc: 0.6255\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6678 - acc: 0.5355 - val_loss: 0.7785 - val_acc: 0.6255\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6726 - acc: 0.5321 - val_loss: 0.7785 - val_acc: 0.6255\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6643 - acc: 0.5211 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6731 - acc: 0.5260 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6686 - acc: 0.5151 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6661 - acc: 0.5137 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6680 - acc: 0.5088 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6617 - acc: 0.5255 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6673 - acc: 0.5065 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6683 - acc: 0.4947 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6653 - acc: 0.5139 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6678 - acc: 0.5073 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6663 - acc: 0.5131 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6732 - acc: 0.5070 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6687 - acc: 0.5272 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6678 - acc: 0.5088 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6637 - acc: 0.5226 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6699 - acc: 0.5194 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6701 - acc: 0.5234 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6717 - acc: 0.5180 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6668 - acc: 0.5214 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6741 - acc: 0.5137 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6694 - acc: 0.5134 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6684 - acc: 0.5171 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6653 - acc: 0.5240 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6671 - acc: 0.5188 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6664 - acc: 0.5255 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6705 - acc: 0.5122 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6638 - acc: 0.5209 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6667 - acc: 0.5194 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6648 - acc: 0.5280 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6694 - acc: 0.5214 - val_loss: 0.7784 - val_acc: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6691 - acc: 0.5237 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6711 - acc: 0.5203 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6666 - acc: 0.5301 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6637 - acc: 0.5243 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6681 - acc: 0.5160 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6690 - acc: 0.5272 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6702 - acc: 0.5122 - val_loss: 0.7784 - val_acc: 0.6255\n",
      "sample weight :  [1.76560287e-04 6.44077383e-05 5.28020817e-05 ... 5.54408172e-05\n",
      " 5.41582981e-05 5.39201914e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6939 - acc: 0.4717 - val_loss: 0.7122 - val_acc: 0.6074\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6939 - acc: 0.5324 - val_loss: 0.7180 - val_acc: 0.6074\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6912 - acc: 0.5401 - val_loss: 0.7220 - val_acc: 0.6074\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6926 - acc: 0.5729 - val_loss: 0.7234 - val_acc: 0.6074\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6904 - acc: 0.5824 - val_loss: 0.7227 - val_acc: 0.6074\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6932 - acc: 0.5732 - val_loss: 0.7209 - val_acc: 0.6074\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6880 - acc: 0.5784 - val_loss: 0.7189 - val_acc: 0.6074\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6897 - acc: 0.5591 - val_loss: 0.7170 - val_acc: 0.6074\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6962 - acc: 0.5370 - val_loss: 0.7155 - val_acc: 0.6074\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6887 - acc: 0.5508 - val_loss: 0.7144 - val_acc: 0.6074\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6883 - acc: 0.5393 - val_loss: 0.7138 - val_acc: 0.6074\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6886 - acc: 0.5539 - val_loss: 0.7139 - val_acc: 0.6074\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6896 - acc: 0.5407 - val_loss: 0.7143 - val_acc: 0.6074\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6898 - acc: 0.5542 - val_loss: 0.7149 - val_acc: 0.6074\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6906 - acc: 0.5390 - val_loss: 0.7157 - val_acc: 0.6074\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6919 - acc: 0.5367 - val_loss: 0.7166 - val_acc: 0.6074\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6920 - acc: 0.5571 - val_loss: 0.7174 - val_acc: 0.6074\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6915 - acc: 0.5502 - val_loss: 0.7182 - val_acc: 0.6074\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6833 - acc: 0.5761 - val_loss: 0.7187 - val_acc: 0.6074\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6880 - acc: 0.5795 - val_loss: 0.7190 - val_acc: 0.6074\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6916 - acc: 0.5715 - val_loss: 0.7190 - val_acc: 0.6074\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6841 - acc: 0.5735 - val_loss: 0.7189 - val_acc: 0.6074\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6911 - acc: 0.5542 - val_loss: 0.7184 - val_acc: 0.6074\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6890 - acc: 0.5706 - val_loss: 0.7178 - val_acc: 0.6074\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6916 - acc: 0.5623 - val_loss: 0.7171 - val_acc: 0.6074\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6884 - acc: 0.5689 - val_loss: 0.7166 - val_acc: 0.6074\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6878 - acc: 0.5617 - val_loss: 0.7162 - val_acc: 0.6074\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6868 - acc: 0.5649 - val_loss: 0.7160 - val_acc: 0.6074\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6913 - acc: 0.5605 - val_loss: 0.7159 - val_acc: 0.6074\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6861 - acc: 0.5666 - val_loss: 0.7162 - val_acc: 0.6074\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6865 - acc: 0.5605 - val_loss: 0.7165 - val_acc: 0.6074\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6834 - acc: 0.5769 - val_loss: 0.7170 - val_acc: 0.6074\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6886 - acc: 0.5657 - val_loss: 0.7176 - val_acc: 0.6074\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6879 - acc: 0.5706 - val_loss: 0.7181 - val_acc: 0.6074\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6907 - acc: 0.5758 - val_loss: 0.7181 - val_acc: 0.6074\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6883 - acc: 0.5798 - val_loss: 0.7180 - val_acc: 0.6074\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6889 - acc: 0.5674 - val_loss: 0.7178 - val_acc: 0.6074\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6881 - acc: 0.5807 - val_loss: 0.7175 - val_acc: 0.6074\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6836 - acc: 0.5775 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6870 - acc: 0.5890 - val_loss: 0.7170 - val_acc: 0.6074\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6869 - acc: 0.5778 - val_loss: 0.7168 - val_acc: 0.6074\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6893 - acc: 0.5752 - val_loss: 0.7166 - val_acc: 0.6074\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6852 - acc: 0.5815 - val_loss: 0.7165 - val_acc: 0.6074\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6871 - acc: 0.5738 - val_loss: 0.7166 - val_acc: 0.6074\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6920 - acc: 0.5623 - val_loss: 0.7167 - val_acc: 0.6074\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6877 - acc: 0.5752 - val_loss: 0.7168 - val_acc: 0.6074\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.6870 - acc: 0.5787 - val_loss: 0.7169 - val_acc: 0.6074\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.6886 - acc: 0.5738 - val_loss: 0.7170 - val_acc: 0.6074\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6847 - acc: 0.5827 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 50/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6872 - acc: 0.5787 - val_loss: 0.7175 - val_acc: 0.6074\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6882 - acc: 0.5626 - val_loss: 0.7177 - val_acc: 0.6074\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6890 - acc: 0.5899 - val_loss: 0.7179 - val_acc: 0.6074\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6861 - acc: 0.5841 - val_loss: 0.7179 - val_acc: 0.6074\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6871 - acc: 0.5858 - val_loss: 0.7178 - val_acc: 0.6074\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6890 - acc: 0.5818 - val_loss: 0.7177 - val_acc: 0.6074\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6854 - acc: 0.5882 - val_loss: 0.7175 - val_acc: 0.6074\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6868 - acc: 0.5916 - val_loss: 0.7175 - val_acc: 0.6074\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6835 - acc: 0.5913 - val_loss: 0.7174 - val_acc: 0.6074\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6859 - acc: 0.5858 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6859 - acc: 0.5930 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6853 - acc: 0.5893 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6882 - acc: 0.5824 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6875 - acc: 0.5925 - val_loss: 0.7171 - val_acc: 0.6074\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6847 - acc: 0.5939 - val_loss: 0.7169 - val_acc: 0.6074\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6863 - acc: 0.5925 - val_loss: 0.7167 - val_acc: 0.6074\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6855 - acc: 0.5942 - val_loss: 0.7167 - val_acc: 0.6074\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6875 - acc: 0.5844 - val_loss: 0.7168 - val_acc: 0.6074\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6846 - acc: 0.5907 - val_loss: 0.7170 - val_acc: 0.6074\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6837 - acc: 0.5873 - val_loss: 0.7173 - val_acc: 0.6074\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6856 - acc: 0.5867 - val_loss: 0.7177 - val_acc: 0.6074\n",
      "sample weight :  [1.89588224e-04 6.92118503e-05 4.92078088e-05 ... 5.16441414e-05\n",
      " 5.04394092e-05 5.00308416e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7704 - acc: 0.3883 - val_loss: 0.7758 - val_acc: 0.3676\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7508 - acc: 0.3883 - val_loss: 0.7603 - val_acc: 0.3676\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7347 - acc: 0.3883 - val_loss: 0.7472 - val_acc: 0.3676\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7216 - acc: 0.3891 - val_loss: 0.7363 - val_acc: 0.3676\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7137 - acc: 0.3880 - val_loss: 0.7278 - val_acc: 0.3676\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7001 - acc: 0.3914 - val_loss: 0.7215 - val_acc: 0.3676\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7004 - acc: 0.3906 - val_loss: 0.7176 - val_acc: 0.3676\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6896 - acc: 0.3998 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6873 - acc: 0.4167 - val_loss: 0.7164 - val_acc: 0.3676\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6849 - acc: 0.4478 - val_loss: 0.7186 - val_acc: 0.3676\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6887 - acc: 0.4745 - val_loss: 0.7216 - val_acc: 0.3676\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6854 - acc: 0.5111 - val_loss: 0.7243 - val_acc: 0.6324\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6953 - acc: 0.5059 - val_loss: 0.7260 - val_acc: 0.6324\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6925 - acc: 0.5128 - val_loss: 0.7264 - val_acc: 0.6324\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6915 - acc: 0.5266 - val_loss: 0.7258 - val_acc: 0.6324\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6964 - acc: 0.5306 - val_loss: 0.7245 - val_acc: 0.6324\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6883 - acc: 0.5347 - val_loss: 0.7229 - val_acc: 0.6324\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6909 - acc: 0.5223 - val_loss: 0.7213 - val_acc: 0.3676\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6958 - acc: 0.4892 - val_loss: 0.7198 - val_acc: 0.3676\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6845 - acc: 0.5030 - val_loss: 0.7186 - val_acc: 0.3676\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6839 - acc: 0.4737 - val_loss: 0.7176 - val_acc: 0.3676\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6875 - acc: 0.4458 - val_loss: 0.7169 - val_acc: 0.3676\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6881 - acc: 0.4515 - val_loss: 0.7164 - val_acc: 0.3676\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6928 - acc: 0.4294 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6851 - acc: 0.4331 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6824 - acc: 0.4380 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6836 - acc: 0.4199 - val_loss: 0.7158 - val_acc: 0.3676\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6841 - acc: 0.4179 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6879 - acc: 0.4072 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6840 - acc: 0.4104 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6849 - acc: 0.4078 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6851 - acc: 0.4078 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6834 - acc: 0.4104 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6852 - acc: 0.4078 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6853 - acc: 0.4087 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6897 - acc: 0.4029 - val_loss: 0.7158 - val_acc: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6866 - acc: 0.4136 - val_loss: 0.7158 - val_acc: 0.3676\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6874 - acc: 0.4150 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6815 - acc: 0.4173 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6819 - acc: 0.4167 - val_loss: 0.7159 - val_acc: 0.3676\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6793 - acc: 0.4216 - val_loss: 0.7160 - val_acc: 0.3676\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6842 - acc: 0.4182 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6843 - acc: 0.4300 - val_loss: 0.7162 - val_acc: 0.3676\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6797 - acc: 0.4297 - val_loss: 0.7163 - val_acc: 0.3676\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6856 - acc: 0.4179 - val_loss: 0.7165 - val_acc: 0.3676\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6830 - acc: 0.4366 - val_loss: 0.7166 - val_acc: 0.3676\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6802 - acc: 0.4380 - val_loss: 0.7167 - val_acc: 0.3676\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6869 - acc: 0.4363 - val_loss: 0.7168 - val_acc: 0.3676\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6794 - acc: 0.4311 - val_loss: 0.7168 - val_acc: 0.3676\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6879 - acc: 0.4291 - val_loss: 0.7169 - val_acc: 0.3676\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6825 - acc: 0.4429 - val_loss: 0.7169 - val_acc: 0.3676\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6832 - acc: 0.4340 - val_loss: 0.7169 - val_acc: 0.3676\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6820 - acc: 0.4403 - val_loss: 0.7169 - val_acc: 0.3676\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6804 - acc: 0.4441 - val_loss: 0.7168 - val_acc: 0.3676\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6795 - acc: 0.4432 - val_loss: 0.7168 - val_acc: 0.3676\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6843 - acc: 0.4383 - val_loss: 0.7167 - val_acc: 0.3676\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6841 - acc: 0.4374 - val_loss: 0.7166 - val_acc: 0.3676\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6821 - acc: 0.4429 - val_loss: 0.7165 - val_acc: 0.3676\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6811 - acc: 0.4245 - val_loss: 0.7165 - val_acc: 0.3676\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6815 - acc: 0.4280 - val_loss: 0.7164 - val_acc: 0.3676\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6824 - acc: 0.4245 - val_loss: 0.7163 - val_acc: 0.3676\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6821 - acc: 0.4285 - val_loss: 0.7163 - val_acc: 0.3676\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6821 - acc: 0.4219 - val_loss: 0.7162 - val_acc: 0.3676\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6831 - acc: 0.4222 - val_loss: 0.7162 - val_acc: 0.3676\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6800 - acc: 0.4234 - val_loss: 0.7162 - val_acc: 0.3676\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6809 - acc: 0.4231 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6837 - acc: 0.4101 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6821 - acc: 0.4176 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6844 - acc: 0.4121 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6840 - acc: 0.4136 - val_loss: 0.7161 - val_acc: 0.3676\n",
      "sample weight :  [1.71748398e-04 6.26980919e-05 5.46239081e-05 ... 5.73206502e-05\n",
      " 5.60442937e-05 5.54983259e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7160 - acc: 0.4190 - val_loss: 0.7057 - val_acc: 0.3701\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7046 - acc: 0.4320 - val_loss: 0.6961 - val_acc: 0.3701\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7061 - acc: 0.4639 - val_loss: 0.6889 - val_acc: 0.6299\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6981 - acc: 0.5102 - val_loss: 0.6841 - val_acc: 0.6299\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7040 - acc: 0.5441 - val_loss: 0.6814 - val_acc: 0.6299\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7023 - acc: 0.5525 - val_loss: 0.6803 - val_acc: 0.6299\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7037 - acc: 0.5672 - val_loss: 0.6800 - val_acc: 0.6299\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7022 - acc: 0.5674 - val_loss: 0.6800 - val_acc: 0.6299\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7072 - acc: 0.5703 - val_loss: 0.6802 - val_acc: 0.6299\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6990 - acc: 0.5781 - val_loss: 0.6807 - val_acc: 0.6299\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7058 - acc: 0.5706 - val_loss: 0.6816 - val_acc: 0.6299\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7074 - acc: 0.5574 - val_loss: 0.6827 - val_acc: 0.6299\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7001 - acc: 0.5516 - val_loss: 0.6840 - val_acc: 0.6299\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6983 - acc: 0.5390 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6984 - acc: 0.5255 - val_loss: 0.6866 - val_acc: 0.6299\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7009 - acc: 0.5312 - val_loss: 0.6877 - val_acc: 0.6299\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6978 - acc: 0.5188 - val_loss: 0.6886 - val_acc: 0.6299\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6971 - acc: 0.5148 - val_loss: 0.6892 - val_acc: 0.3701\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6981 - acc: 0.4958 - val_loss: 0.6894 - val_acc: 0.3701\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6955 - acc: 0.5151 - val_loss: 0.6894 - val_acc: 0.3701\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6946 - acc: 0.5154 - val_loss: 0.6890 - val_acc: 0.3701\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6977 - acc: 0.4984 - val_loss: 0.6884 - val_acc: 0.6299\n",
      "Epoch 23/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6985 - acc: 0.4953 - val_loss: 0.6878 - val_acc: 0.6299\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6963 - acc: 0.4996 - val_loss: 0.6870 - val_acc: 0.6299\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6982 - acc: 0.5266 - val_loss: 0.6863 - val_acc: 0.6299\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6940 - acc: 0.5329 - val_loss: 0.6855 - val_acc: 0.6299\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6937 - acc: 0.5237 - val_loss: 0.6848 - val_acc: 0.6299\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7009 - acc: 0.5240 - val_loss: 0.6842 - val_acc: 0.6299\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7028 - acc: 0.5309 - val_loss: 0.6837 - val_acc: 0.6299\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6967 - acc: 0.5510 - val_loss: 0.6833 - val_acc: 0.6299\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6950 - acc: 0.5548 - val_loss: 0.6831 - val_acc: 0.6299\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7016 - acc: 0.5531 - val_loss: 0.6830 - val_acc: 0.6299\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6930 - acc: 0.5689 - val_loss: 0.6831 - val_acc: 0.6299\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7027 - acc: 0.5545 - val_loss: 0.6833 - val_acc: 0.6299\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7011 - acc: 0.5534 - val_loss: 0.6836 - val_acc: 0.6299\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6973 - acc: 0.5505 - val_loss: 0.6840 - val_acc: 0.6299\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6999 - acc: 0.5470 - val_loss: 0.6845 - val_acc: 0.6299\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7015 - acc: 0.5289 - val_loss: 0.6849 - val_acc: 0.6299\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6951 - acc: 0.5513 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6943 - acc: 0.5381 - val_loss: 0.6857 - val_acc: 0.6299\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6961 - acc: 0.5393 - val_loss: 0.6859 - val_acc: 0.6299\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6961 - acc: 0.5367 - val_loss: 0.6861 - val_acc: 0.6299\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6962 - acc: 0.5263 - val_loss: 0.6862 - val_acc: 0.6299\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7000 - acc: 0.5278 - val_loss: 0.6862 - val_acc: 0.6299\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6982 - acc: 0.5321 - val_loss: 0.6861 - val_acc: 0.6299\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7018 - acc: 0.5160 - val_loss: 0.6860 - val_acc: 0.6299\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6982 - acc: 0.5217 - val_loss: 0.6858 - val_acc: 0.6299\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6949 - acc: 0.5370 - val_loss: 0.6856 - val_acc: 0.6299\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6947 - acc: 0.5335 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.6973 - acc: 0.5395 - val_loss: 0.6849 - val_acc: 0.6299\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6972 - acc: 0.5375 - val_loss: 0.6846 - val_acc: 0.6299\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6972 - acc: 0.5493 - val_loss: 0.6844 - val_acc: 0.6299\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6904 - acc: 0.5666 - val_loss: 0.6843 - val_acc: 0.6299\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6941 - acc: 0.5554 - val_loss: 0.6842 - val_acc: 0.6299\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6954 - acc: 0.5447 - val_loss: 0.6842 - val_acc: 0.6299\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6942 - acc: 0.5485 - val_loss: 0.6842 - val_acc: 0.6299\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6946 - acc: 0.5660 - val_loss: 0.6843 - val_acc: 0.6299\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6980 - acc: 0.5631 - val_loss: 0.6844 - val_acc: 0.6299\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6949 - acc: 0.5534 - val_loss: 0.6846 - val_acc: 0.6299\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6978 - acc: 0.5487 - val_loss: 0.6847 - val_acc: 0.6299\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6974 - acc: 0.5525 - val_loss: 0.6849 - val_acc: 0.6299\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6972 - acc: 0.5476 - val_loss: 0.6851 - val_acc: 0.6299\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6963 - acc: 0.5364 - val_loss: 0.6852 - val_acc: 0.6299\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6931 - acc: 0.5534 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6923 - acc: 0.5565 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6944 - acc: 0.5513 - val_loss: 0.6853 - val_acc: 0.6299\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6944 - acc: 0.5528 - val_loss: 0.6852 - val_acc: 0.6299\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6962 - acc: 0.5450 - val_loss: 0.6851 - val_acc: 0.6299\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6959 - acc: 0.5427 - val_loss: 0.6850 - val_acc: 0.6299\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6961 - acc: 0.5433 - val_loss: 0.6849 - val_acc: 0.6299\n",
      "sample weight :  [1.79046890e-04 6.53660296e-05 5.25679391e-05 ... 5.50774226e-05\n",
      " 5.38571321e-05 5.32872497e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7016 - acc: 0.4820 - val_loss: 0.6867 - val_acc: 0.3848\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7029 - acc: 0.4803 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7037 - acc: 0.4791 - val_loss: 0.6856 - val_acc: 0.3848\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7052 - acc: 0.4878 - val_loss: 0.6855 - val_acc: 0.3848\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6998 - acc: 0.4935 - val_loss: 0.6856 - val_acc: 0.3848\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7024 - acc: 0.4829 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7015 - acc: 0.4846 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7007 - acc: 0.4809 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7036 - acc: 0.4699 - val_loss: 0.6866 - val_acc: 0.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6943 - acc: 0.4803 - val_loss: 0.6866 - val_acc: 0.3848\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7033 - acc: 0.4573 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7030 - acc: 0.4570 - val_loss: 0.6864 - val_acc: 0.3848\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7000 - acc: 0.4688 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6978 - acc: 0.4849 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6989 - acc: 0.4786 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6958 - acc: 0.4838 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6977 - acc: 0.4915 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7004 - acc: 0.4814 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7009 - acc: 0.4734 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6966 - acc: 0.4766 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6966 - acc: 0.4745 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6990 - acc: 0.4731 - val_loss: 0.6863 - val_acc: 0.3848\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6977 - acc: 0.4691 - val_loss: 0.6864 - val_acc: 0.3848\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6949 - acc: 0.4662 - val_loss: 0.6863 - val_acc: 0.3848\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6949 - acc: 0.4774 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6952 - acc: 0.4866 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7010 - acc: 0.4697 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6973 - acc: 0.4720 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7001 - acc: 0.4786 - val_loss: 0.6859 - val_acc: 0.3848\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6953 - acc: 0.4840 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6946 - acc: 0.4688 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6995 - acc: 0.4593 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6987 - acc: 0.4556 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6957 - acc: 0.4774 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6980 - acc: 0.4685 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7010 - acc: 0.4527 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6949 - acc: 0.4720 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6955 - acc: 0.4711 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6950 - acc: 0.4648 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6969 - acc: 0.4835 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6980 - acc: 0.4607 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6977 - acc: 0.4697 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6939 - acc: 0.4653 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6982 - acc: 0.4625 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6967 - acc: 0.4602 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6939 - acc: 0.4725 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6943 - acc: 0.4590 - val_loss: 0.6863 - val_acc: 0.3848\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6975 - acc: 0.4513 - val_loss: 0.6864 - val_acc: 0.3848\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6946 - acc: 0.4466 - val_loss: 0.6864 - val_acc: 0.3848\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6953 - acc: 0.4553 - val_loss: 0.6863 - val_acc: 0.3848\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6962 - acc: 0.4504 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6965 - acc: 0.4625 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6948 - acc: 0.4688 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6960 - acc: 0.4524 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6961 - acc: 0.4714 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6980 - acc: 0.4550 - val_loss: 0.6860 - val_acc: 0.3848\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6939 - acc: 0.4789 - val_loss: 0.6861 - val_acc: 0.3848\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6941 - acc: 0.4720 - val_loss: 0.6862 - val_acc: 0.3848\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6968 - acc: 0.4599 - val_loss: 0.6863 - val_acc: 0.3848\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6948 - acc: 0.4570 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6945 - acc: 0.4518 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6934 - acc: 0.4420 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6971 - acc: 0.4504 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6952 - acc: 0.4386 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6942 - acc: 0.4556 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6956 - acc: 0.4395 - val_loss: 0.6865 - val_acc: 0.3848\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6964 - acc: 0.4443 - val_loss: 0.6866 - val_acc: 0.3848\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6947 - acc: 0.4469 - val_loss: 0.6866 - val_acc: 0.3848\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6964 - acc: 0.4579 - val_loss: 0.6866 - val_acc: 0.3848\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6949 - acc: 0.4691 - val_loss: 0.6868 - val_acc: 0.3848\n",
      "sample weight :  [1.74232265e-04 6.40729641e-05 5.42423645e-05 ... 5.66465962e-05\n",
      " 5.59453376e-05 5.48732721e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6994 - acc: 0.5352 - val_loss: 0.6868 - val_acc: 0.6100\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6964 - acc: 0.5191 - val_loss: 0.6873 - val_acc: 0.3900\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7017 - acc: 0.4866 - val_loss: 0.6871 - val_acc: 0.3900\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6993 - acc: 0.4881 - val_loss: 0.6868 - val_acc: 0.6100\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7058 - acc: 0.4990 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7049 - acc: 0.4967 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7015 - acc: 0.5165 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6993 - acc: 0.5145 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7007 - acc: 0.5154 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7011 - acc: 0.5180 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6996 - acc: 0.5056 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6985 - acc: 0.5162 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6965 - acc: 0.5165 - val_loss: 0.6868 - val_acc: 0.6100\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6957 - acc: 0.5188 - val_loss: 0.6869 - val_acc: 0.6100\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7014 - acc: 0.4904 - val_loss: 0.6869 - val_acc: 0.6100\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7047 - acc: 0.4866 - val_loss: 0.6869 - val_acc: 0.6100\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7007 - acc: 0.5019 - val_loss: 0.6869 - val_acc: 0.6100\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7010 - acc: 0.5042 - val_loss: 0.6868 - val_acc: 0.6100\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6985 - acc: 0.5070 - val_loss: 0.6868 - val_acc: 0.6100\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7048 - acc: 0.5093 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6966 - acc: 0.5223 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7018 - acc: 0.5134 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6957 - acc: 0.5223 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6954 - acc: 0.5033 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6972 - acc: 0.5255 - val_loss: 0.6865 - val_acc: 0.6100\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6956 - acc: 0.5165 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6996 - acc: 0.5157 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6981 - acc: 0.5174 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6939 - acc: 0.5102 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6988 - acc: 0.5206 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6972 - acc: 0.5105 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7046 - acc: 0.4950 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6937 - acc: 0.5134 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6983 - acc: 0.5082 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6970 - acc: 0.5183 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6985 - acc: 0.5180 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6983 - acc: 0.5093 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6942 - acc: 0.5180 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6977 - acc: 0.5249 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6974 - acc: 0.5318 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6974 - acc: 0.5217 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6945 - acc: 0.5108 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6970 - acc: 0.5200 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6924 - acc: 0.5183 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6965 - acc: 0.5197 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6967 - acc: 0.5194 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6965 - acc: 0.5122 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6954 - acc: 0.5200 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6978 - acc: 0.5272 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6963 - acc: 0.5099 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6987 - acc: 0.5234 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6964 - acc: 0.5168 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6979 - acc: 0.5079 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6968 - acc: 0.5269 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6948 - acc: 0.5332 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6957 - acc: 0.5076 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6982 - acc: 0.5191 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6989 - acc: 0.5160 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6948 - acc: 0.5151 - val_loss: 0.6866 - val_acc: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6973 - acc: 0.5119 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6956 - acc: 0.5260 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6961 - acc: 0.5160 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6961 - acc: 0.5252 - val_loss: 0.6866 - val_acc: 0.6100\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6968 - acc: 0.5186 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6970 - acc: 0.5188 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6983 - acc: 0.5217 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6958 - acc: 0.5027 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6948 - acc: 0.5214 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6972 - acc: 0.5194 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6948 - acc: 0.5068 - val_loss: 0.6867 - val_acc: 0.6100\n",
      "sample weight :  [1.75910434e-04 6.48739015e-05 5.36388439e-05 ... 5.60611972e-05\n",
      " 5.54642302e-05 5.42616683e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7135 - acc: 0.3940 - val_loss: 0.7437 - val_acc: 0.4081\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7003 - acc: 0.4032 - val_loss: 0.7362 - val_acc: 0.4081\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6954 - acc: 0.4271 - val_loss: 0.7316 - val_acc: 0.4081\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6972 - acc: 0.4452 - val_loss: 0.7296 - val_acc: 0.4081\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6857 - acc: 0.4993 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6846 - acc: 0.5410 - val_loss: 0.7316 - val_acc: 0.5919\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6924 - acc: 0.5539 - val_loss: 0.7337 - val_acc: 0.5919\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6958 - acc: 0.5634 - val_loss: 0.7352 - val_acc: 0.5919\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6923 - acc: 0.5680 - val_loss: 0.7357 - val_acc: 0.5919\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6916 - acc: 0.5749 - val_loss: 0.7353 - val_acc: 0.5919\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6995 - acc: 0.5674 - val_loss: 0.7343 - val_acc: 0.5919\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6856 - acc: 0.5784 - val_loss: 0.7331 - val_acc: 0.5919\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6896 - acc: 0.5542 - val_loss: 0.7319 - val_acc: 0.5919\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6842 - acc: 0.5623 - val_loss: 0.7309 - val_acc: 0.5919\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6862 - acc: 0.5467 - val_loss: 0.7301 - val_acc: 0.5919\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6826 - acc: 0.5421 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6882 - acc: 0.5298 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6909 - acc: 0.5045 - val_loss: 0.7294 - val_acc: 0.5919\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6878 - acc: 0.4832 - val_loss: 0.7295 - val_acc: 0.4081\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6822 - acc: 0.5151 - val_loss: 0.7296 - val_acc: 0.4081\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6884 - acc: 0.4987 - val_loss: 0.7296 - val_acc: 0.4081\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6893 - acc: 0.4947 - val_loss: 0.7297 - val_acc: 0.4081\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6832 - acc: 0.4953 - val_loss: 0.7297 - val_acc: 0.4081\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6935 - acc: 0.4722 - val_loss: 0.7296 - val_acc: 0.4081\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6897 - acc: 0.4814 - val_loss: 0.7296 - val_acc: 0.4081\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6816 - acc: 0.4999 - val_loss: 0.7295 - val_acc: 0.4081\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6843 - acc: 0.4932 - val_loss: 0.7295 - val_acc: 0.4081\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6839 - acc: 0.5076 - val_loss: 0.7294 - val_acc: 0.5919\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6914 - acc: 0.4984 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6908 - acc: 0.5096 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6853 - acc: 0.5059 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6885 - acc: 0.5240 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6872 - acc: 0.5338 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6920 - acc: 0.5137 - val_loss: 0.7299 - val_acc: 0.5919\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6840 - acc: 0.5413 - val_loss: 0.7300 - val_acc: 0.5919\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6874 - acc: 0.5309 - val_loss: 0.7300 - val_acc: 0.5919\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6862 - acc: 0.5375 - val_loss: 0.7301 - val_acc: 0.5919\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6833 - acc: 0.5499 - val_loss: 0.7301 - val_acc: 0.5919\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6839 - acc: 0.5554 - val_loss: 0.7301 - val_acc: 0.5919\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6876 - acc: 0.5416 - val_loss: 0.7300 - val_acc: 0.5919\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6874 - acc: 0.5375 - val_loss: 0.7299 - val_acc: 0.5919\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6833 - acc: 0.5306 - val_loss: 0.7299 - val_acc: 0.5919\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6806 - acc: 0.5306 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6864 - acc: 0.5326 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6895 - acc: 0.5249 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 46/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6829 - acc: 0.5289 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6821 - acc: 0.5111 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6838 - acc: 0.5114 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6843 - acc: 0.5347 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6797 - acc: 0.5361 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6838 - acc: 0.5269 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6842 - acc: 0.5249 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6823 - acc: 0.5217 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6900 - acc: 0.5059 - val_loss: 0.7295 - val_acc: 0.5919\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6874 - acc: 0.5125 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6797 - acc: 0.5306 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6865 - acc: 0.5148 - val_loss: 0.7296 - val_acc: 0.5919\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6848 - acc: 0.5200 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6864 - acc: 0.5462 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6818 - acc: 0.5347 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6816 - acc: 0.5240 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6798 - acc: 0.5502 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6846 - acc: 0.5421 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6805 - acc: 0.5467 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6838 - acc: 0.5292 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6871 - acc: 0.5341 - val_loss: 0.7298 - val_acc: 0.5919\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6782 - acc: 0.5312 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6804 - acc: 0.5295 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6823 - acc: 0.5306 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6830 - acc: 0.5280 - val_loss: 0.7297 - val_acc: 0.5919\n",
      "sample weight :  [1.81116861e-04 6.67985275e-05 5.22827976e-05 ... 5.43967923e-05\n",
      " 5.39251701e-05 5.27040743e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7349 - acc: 0.3868 - val_loss: 0.7017 - val_acc: 0.3719\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7214 - acc: 0.3880 - val_loss: 0.6931 - val_acc: 0.3719\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7144 - acc: 0.3894 - val_loss: 0.6866 - val_acc: 0.3719\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7103 - acc: 0.4139 - val_loss: 0.6821 - val_acc: 0.3719\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7064 - acc: 0.4383 - val_loss: 0.6796 - val_acc: 0.3719\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6933 - acc: 0.4863 - val_loss: 0.6788 - val_acc: 0.3719\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6999 - acc: 0.5073 - val_loss: 0.6792 - val_acc: 0.6281\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6979 - acc: 0.5453 - val_loss: 0.6800 - val_acc: 0.6281\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7077 - acc: 0.5485 - val_loss: 0.6806 - val_acc: 0.6281\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7057 - acc: 0.5608 - val_loss: 0.6806 - val_acc: 0.6281\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7053 - acc: 0.5542 - val_loss: 0.6803 - val_acc: 0.6281\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7113 - acc: 0.5390 - val_loss: 0.6798 - val_acc: 0.6281\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7088 - acc: 0.5298 - val_loss: 0.6793 - val_acc: 0.6281\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7114 - acc: 0.5226 - val_loss: 0.6789 - val_acc: 0.6281\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7032 - acc: 0.5352 - val_loss: 0.6788 - val_acc: 0.6281\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7093 - acc: 0.5134 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7047 - acc: 0.4941 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7006 - acc: 0.4679 - val_loss: 0.6795 - val_acc: 0.3719\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7062 - acc: 0.4593 - val_loss: 0.6800 - val_acc: 0.3719\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7114 - acc: 0.4484 - val_loss: 0.6804 - val_acc: 0.3719\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7025 - acc: 0.4656 - val_loss: 0.6808 - val_acc: 0.3719\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7086 - acc: 0.4386 - val_loss: 0.6810 - val_acc: 0.3719\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7020 - acc: 0.4521 - val_loss: 0.6811 - val_acc: 0.3719\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7093 - acc: 0.4277 - val_loss: 0.6811 - val_acc: 0.3719\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6992 - acc: 0.4490 - val_loss: 0.6810 - val_acc: 0.3719\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7026 - acc: 0.4337 - val_loss: 0.6808 - val_acc: 0.3719\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7039 - acc: 0.4357 - val_loss: 0.6806 - val_acc: 0.3719\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7030 - acc: 0.4412 - val_loss: 0.6803 - val_acc: 0.3719\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7051 - acc: 0.4340 - val_loss: 0.6800 - val_acc: 0.3719\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6950 - acc: 0.4674 - val_loss: 0.6797 - val_acc: 0.3719\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7037 - acc: 0.4524 - val_loss: 0.6794 - val_acc: 0.3719\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7058 - acc: 0.4630 - val_loss: 0.6793 - val_acc: 0.3719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7012 - acc: 0.4740 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7009 - acc: 0.4806 - val_loss: 0.6790 - val_acc: 0.3719\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7006 - acc: 0.4846 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6984 - acc: 0.4898 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7054 - acc: 0.4766 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6994 - acc: 0.4771 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7049 - acc: 0.4823 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7035 - acc: 0.4976 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6996 - acc: 0.4872 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6996 - acc: 0.4849 - val_loss: 0.6789 - val_acc: 0.3719\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7045 - acc: 0.4863 - val_loss: 0.6790 - val_acc: 0.3719\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7007 - acc: 0.4838 - val_loss: 0.6790 - val_acc: 0.3719\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7056 - acc: 0.4728 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7010 - acc: 0.4826 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6956 - acc: 0.4835 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6987 - acc: 0.4768 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6973 - acc: 0.4725 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6986 - acc: 0.4766 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7014 - acc: 0.4559 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7024 - acc: 0.4602 - val_loss: 0.6794 - val_acc: 0.3719\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6990 - acc: 0.4760 - val_loss: 0.6794 - val_acc: 0.3719\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7000 - acc: 0.4561 - val_loss: 0.6794 - val_acc: 0.3719\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6976 - acc: 0.4625 - val_loss: 0.6794 - val_acc: 0.3719\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7032 - acc: 0.4513 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6997 - acc: 0.4642 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7014 - acc: 0.4538 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7039 - acc: 0.4648 - val_loss: 0.6793 - val_acc: 0.3719\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7016 - acc: 0.4685 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7035 - acc: 0.4610 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7028 - acc: 0.4561 - val_loss: 0.6792 - val_acc: 0.3719\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7016 - acc: 0.4797 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6990 - acc: 0.4656 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6965 - acc: 0.4639 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7008 - acc: 0.4685 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6974 - acc: 0.4754 - val_loss: 0.6790 - val_acc: 0.3719\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6990 - acc: 0.4858 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7058 - acc: 0.4760 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6983 - acc: 0.4610 - val_loss: 0.6791 - val_acc: 0.3719\n",
      "sample weight :  [1.76614152e-04 6.51119589e-05 5.38417781e-05 ... 5.58782410e-05\n",
      " 5.54231219e-05 5.41119197e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9435 - acc: 0.3963 - val_loss: 0.9155 - val_acc: 0.3814\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9214 - acc: 0.3963 - val_loss: 0.8872 - val_acc: 0.3814\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9012 - acc: 0.3963 - val_loss: 0.8609 - val_acc: 0.3814\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8661 - acc: 0.3963 - val_loss: 0.8362 - val_acc: 0.3814\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8450 - acc: 0.3963 - val_loss: 0.8132 - val_acc: 0.3814\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8165 - acc: 0.3963 - val_loss: 0.7917 - val_acc: 0.3814\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8025 - acc: 0.3963 - val_loss: 0.7716 - val_acc: 0.3814\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7803 - acc: 0.3963 - val_loss: 0.7534 - val_acc: 0.3814\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7647 - acc: 0.3963 - val_loss: 0.7369 - val_acc: 0.3814\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7506 - acc: 0.3966 - val_loss: 0.7222 - val_acc: 0.3814\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7368 - acc: 0.3975 - val_loss: 0.7100 - val_acc: 0.3814\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7239 - acc: 0.3966 - val_loss: 0.7003 - val_acc: 0.3814\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7114 - acc: 0.4001 - val_loss: 0.6932 - val_acc: 0.3814\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7086 - acc: 0.4159 - val_loss: 0.6887 - val_acc: 0.3814\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6996 - acc: 0.4403 - val_loss: 0.6862 - val_acc: 0.3814\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6997 - acc: 0.4630 - val_loss: 0.6851 - val_acc: 0.3814\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7010 - acc: 0.4950 - val_loss: 0.6850 - val_acc: 0.6186\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7066 - acc: 0.5022 - val_loss: 0.6856 - val_acc: 0.6186\n",
      "Epoch 19/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7069 - acc: 0.5341 - val_loss: 0.6865 - val_acc: 0.6186\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7045 - acc: 0.5551 - val_loss: 0.6876 - val_acc: 0.6186\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7067 - acc: 0.5479 - val_loss: 0.6885 - val_acc: 0.6186\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7077 - acc: 0.5490 - val_loss: 0.6892 - val_acc: 0.6186\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7066 - acc: 0.5689 - val_loss: 0.6896 - val_acc: 0.6186\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7043 - acc: 0.5743 - val_loss: 0.6897 - val_acc: 0.6186\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7111 - acc: 0.5634 - val_loss: 0.6895 - val_acc: 0.6186\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7000 - acc: 0.5718 - val_loss: 0.6891 - val_acc: 0.6186\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7054 - acc: 0.5651 - val_loss: 0.6885 - val_acc: 0.6186\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7070 - acc: 0.5605 - val_loss: 0.6879 - val_acc: 0.6186\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7088 - acc: 0.5554 - val_loss: 0.6873 - val_acc: 0.6186\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6980 - acc: 0.5646 - val_loss: 0.6867 - val_acc: 0.6186\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7057 - acc: 0.5600 - val_loss: 0.6862 - val_acc: 0.6186\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7039 - acc: 0.5424 - val_loss: 0.6857 - val_acc: 0.6186\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 0.6978 - acc: 0.5433 - val_loss: 0.6854 - val_acc: 0.6186\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.6978 - acc: 0.5298 - val_loss: 0.6851 - val_acc: 0.6186\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6958 - acc: 0.5283 - val_loss: 0.6850 - val_acc: 0.6186\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7075 - acc: 0.4967 - val_loss: 0.6849 - val_acc: 0.6186\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6963 - acc: 0.5099 - val_loss: 0.6849 - val_acc: 0.3814\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6985 - acc: 0.5065 - val_loss: 0.6850 - val_acc: 0.3814\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6953 - acc: 0.5050 - val_loss: 0.6851 - val_acc: 0.3814\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6945 - acc: 0.4958 - val_loss: 0.6852 - val_acc: 0.3814\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6996 - acc: 0.4794 - val_loss: 0.6854 - val_acc: 0.3814\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7008 - acc: 0.4699 - val_loss: 0.6855 - val_acc: 0.3814\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6964 - acc: 0.4694 - val_loss: 0.6856 - val_acc: 0.3814\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6940 - acc: 0.4734 - val_loss: 0.6858 - val_acc: 0.3814\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7018 - acc: 0.4722 - val_loss: 0.6859 - val_acc: 0.3814\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6962 - acc: 0.4564 - val_loss: 0.6859 - val_acc: 0.3814\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6984 - acc: 0.4602 - val_loss: 0.6860 - val_acc: 0.3814\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6972 - acc: 0.4665 - val_loss: 0.6860 - val_acc: 0.3814\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6972 - acc: 0.4622 - val_loss: 0.6860 - val_acc: 0.3814\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7021 - acc: 0.4466 - val_loss: 0.6859 - val_acc: 0.3814\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7016 - acc: 0.4478 - val_loss: 0.6859 - val_acc: 0.3814\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7006 - acc: 0.4475 - val_loss: 0.6858 - val_acc: 0.3814\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6956 - acc: 0.4780 - val_loss: 0.6858 - val_acc: 0.3814\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7010 - acc: 0.4587 - val_loss: 0.6857 - val_acc: 0.3814\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7014 - acc: 0.4628 - val_loss: 0.6856 - val_acc: 0.3814\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7004 - acc: 0.4688 - val_loss: 0.6855 - val_acc: 0.3814\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6950 - acc: 0.4763 - val_loss: 0.6854 - val_acc: 0.3814\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6988 - acc: 0.4587 - val_loss: 0.6854 - val_acc: 0.3814\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7030 - acc: 0.4745 - val_loss: 0.6853 - val_acc: 0.3814\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6969 - acc: 0.4685 - val_loss: 0.6852 - val_acc: 0.3814\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6999 - acc: 0.4791 - val_loss: 0.6852 - val_acc: 0.3814\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6994 - acc: 0.4800 - val_loss: 0.6851 - val_acc: 0.3814\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6967 - acc: 0.4757 - val_loss: 0.6851 - val_acc: 0.3814\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6976 - acc: 0.4918 - val_loss: 0.6850 - val_acc: 0.3814\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7000 - acc: 0.4863 - val_loss: 0.6850 - val_acc: 0.3814\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6935 - acc: 0.5036 - val_loss: 0.6850 - val_acc: 0.3814\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7016 - acc: 0.4835 - val_loss: 0.6850 - val_acc: 0.3814\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7000 - acc: 0.4978 - val_loss: 0.6849 - val_acc: 0.3814\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6990 - acc: 0.4829 - val_loss: 0.6849 - val_acc: 0.3814\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6966 - acc: 0.4964 - val_loss: 0.6849 - val_acc: 0.3814\n",
      "sample weight :  [1.74107258e-04 6.42085421e-05 5.45998941e-05 ... 5.66552448e-05\n",
      " 5.61948605e-05 5.48653042e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7308 - acc: 0.6158 - val_loss: 0.7397 - val_acc: 0.6204\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7209 - acc: 0.6172 - val_loss: 0.7313 - val_acc: 0.6204\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7098 - acc: 0.6040 - val_loss: 0.7252 - val_acc: 0.6204\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6999 - acc: 0.5962 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6972 - acc: 0.5853 - val_loss: 0.7202 - val_acc: 0.6204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6924 - acc: 0.5493 - val_loss: 0.7208 - val_acc: 0.6204\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6832 - acc: 0.5344 - val_loss: 0.7228 - val_acc: 0.3796\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6953 - acc: 0.4927 - val_loss: 0.7256 - val_acc: 0.3796\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6881 - acc: 0.4832 - val_loss: 0.7285 - val_acc: 0.3796\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6945 - acc: 0.4397 - val_loss: 0.7306 - val_acc: 0.3796\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6943 - acc: 0.4285 - val_loss: 0.7316 - val_acc: 0.3796\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6892 - acc: 0.4360 - val_loss: 0.7315 - val_acc: 0.3796\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6958 - acc: 0.4392 - val_loss: 0.7306 - val_acc: 0.3796\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6939 - acc: 0.4317 - val_loss: 0.7292 - val_acc: 0.3796\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6913 - acc: 0.4559 - val_loss: 0.7277 - val_acc: 0.3796\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6885 - acc: 0.4605 - val_loss: 0.7262 - val_acc: 0.3796\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6900 - acc: 0.4725 - val_loss: 0.7247 - val_acc: 0.3796\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6944 - acc: 0.4852 - val_loss: 0.7236 - val_acc: 0.3796\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6922 - acc: 0.4751 - val_loss: 0.7226 - val_acc: 0.3796\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6934 - acc: 0.4990 - val_loss: 0.7218 - val_acc: 0.6204\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6928 - acc: 0.4955 - val_loss: 0.7213 - val_acc: 0.6204\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6856 - acc: 0.5085 - val_loss: 0.7209 - val_acc: 0.6204\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6947 - acc: 0.5260 - val_loss: 0.7206 - val_acc: 0.6204\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6911 - acc: 0.5349 - val_loss: 0.7205 - val_acc: 0.6204\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6890 - acc: 0.5324 - val_loss: 0.7204 - val_acc: 0.6204\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6848 - acc: 0.5487 - val_loss: 0.7203 - val_acc: 0.6204\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6911 - acc: 0.5257 - val_loss: 0.7203 - val_acc: 0.6204\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6864 - acc: 0.5493 - val_loss: 0.7203 - val_acc: 0.6204\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6877 - acc: 0.5459 - val_loss: 0.7204 - val_acc: 0.6204\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6928 - acc: 0.5413 - val_loss: 0.7204 - val_acc: 0.6204\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6894 - acc: 0.5464 - val_loss: 0.7205 - val_acc: 0.6204\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6887 - acc: 0.5275 - val_loss: 0.7206 - val_acc: 0.6204\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6843 - acc: 0.5197 - val_loss: 0.7207 - val_acc: 0.6204\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6923 - acc: 0.5148 - val_loss: 0.7209 - val_acc: 0.6204\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6882 - acc: 0.5240 - val_loss: 0.7211 - val_acc: 0.6204\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6882 - acc: 0.5229 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6935 - acc: 0.5096 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6878 - acc: 0.5059 - val_loss: 0.7219 - val_acc: 0.6204\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6913 - acc: 0.5030 - val_loss: 0.7221 - val_acc: 0.6204\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6845 - acc: 0.5191 - val_loss: 0.7223 - val_acc: 0.6204\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6858 - acc: 0.5093 - val_loss: 0.7225 - val_acc: 0.6204\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6879 - acc: 0.5036 - val_loss: 0.7226 - val_acc: 0.3796\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6911 - acc: 0.4912 - val_loss: 0.7227 - val_acc: 0.3796\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6840 - acc: 0.4932 - val_loss: 0.7227 - val_acc: 0.3796\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6840 - acc: 0.4973 - val_loss: 0.7227 - val_acc: 0.3796\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6842 - acc: 0.5082 - val_loss: 0.7227 - val_acc: 0.3796\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6862 - acc: 0.4869 - val_loss: 0.7226 - val_acc: 0.3796\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6865 - acc: 0.5001 - val_loss: 0.7225 - val_acc: 0.6204\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6918 - acc: 0.4889 - val_loss: 0.7223 - val_acc: 0.6204\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6826 - acc: 0.4927 - val_loss: 0.7222 - val_acc: 0.6204\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6888 - acc: 0.4984 - val_loss: 0.7221 - val_acc: 0.6204\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6833 - acc: 0.5165 - val_loss: 0.7219 - val_acc: 0.6204\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6867 - acc: 0.5007 - val_loss: 0.7218 - val_acc: 0.6204\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6856 - acc: 0.5019 - val_loss: 0.7217 - val_acc: 0.6204\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6837 - acc: 0.5039 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6821 - acc: 0.5252 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6842 - acc: 0.5278 - val_loss: 0.7215 - val_acc: 0.6204\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6798 - acc: 0.5324 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6867 - acc: 0.5010 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6870 - acc: 0.5298 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6839 - acc: 0.5226 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6819 - acc: 0.5283 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6884 - acc: 0.5229 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6892 - acc: 0.5105 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6884 - acc: 0.5093 - val_loss: 0.7215 - val_acc: 0.6204\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6897 - acc: 0.4964 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6890 - acc: 0.5085 - val_loss: 0.7216 - val_acc: 0.6204\n",
      "Epoch 68/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6840 - acc: 0.5076 - val_loss: 0.7217 - val_acc: 0.6204\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6866 - acc: 0.5151 - val_loss: 0.7217 - val_acc: 0.6204\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6882 - acc: 0.5145 - val_loss: 0.7217 - val_acc: 0.6204\n",
      "sample weight :  [1.76883584e-04 6.51888357e-05 5.39117047e-05 ... 5.58507189e-05\n",
      " 5.54265540e-05 5.40301687e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7430 - acc: 0.3940 - val_loss: 0.7391 - val_acc: 0.3822\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7323 - acc: 0.3940 - val_loss: 0.7259 - val_acc: 0.3822\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7251 - acc: 0.3966 - val_loss: 0.7151 - val_acc: 0.3822\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7125 - acc: 0.4118 - val_loss: 0.7067 - val_acc: 0.3822\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6918 - acc: 0.4308 - val_loss: 0.7006 - val_acc: 0.3822\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7090 - acc: 0.4412 - val_loss: 0.6968 - val_acc: 0.3822\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7033 - acc: 0.4789 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7029 - acc: 0.4981 - val_loss: 0.6949 - val_acc: 0.6178\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7028 - acc: 0.5168 - val_loss: 0.6954 - val_acc: 0.6178\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7038 - acc: 0.5332 - val_loss: 0.6960 - val_acc: 0.6178\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7146 - acc: 0.5427 - val_loss: 0.6963 - val_acc: 0.6178\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7041 - acc: 0.5516 - val_loss: 0.6963 - val_acc: 0.6178\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7070 - acc: 0.5628 - val_loss: 0.6959 - val_acc: 0.6178\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7129 - acc: 0.5424 - val_loss: 0.6955 - val_acc: 0.6178\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7057 - acc: 0.5303 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7057 - acc: 0.5298 - val_loss: 0.6949 - val_acc: 0.6178\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7017 - acc: 0.5295 - val_loss: 0.6948 - val_acc: 0.6178\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7016 - acc: 0.5260 - val_loss: 0.6950 - val_acc: 0.6178\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7003 - acc: 0.5108 - val_loss: 0.6953 - val_acc: 0.3822\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7002 - acc: 0.5065 - val_loss: 0.6958 - val_acc: 0.3822\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6917 - acc: 0.4953 - val_loss: 0.6963 - val_acc: 0.3822\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6978 - acc: 0.4774 - val_loss: 0.6968 - val_acc: 0.3822\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6975 - acc: 0.4881 - val_loss: 0.6974 - val_acc: 0.3822\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6943 - acc: 0.4717 - val_loss: 0.6978 - val_acc: 0.3822\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6975 - acc: 0.4685 - val_loss: 0.6982 - val_acc: 0.3822\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7024 - acc: 0.4550 - val_loss: 0.6985 - val_acc: 0.3822\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7069 - acc: 0.4458 - val_loss: 0.6986 - val_acc: 0.3822\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7027 - acc: 0.4622 - val_loss: 0.6986 - val_acc: 0.3822\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7018 - acc: 0.4679 - val_loss: 0.6985 - val_acc: 0.3822\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6971 - acc: 0.4619 - val_loss: 0.6983 - val_acc: 0.3822\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6944 - acc: 0.4567 - val_loss: 0.6980 - val_acc: 0.3822\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6911 - acc: 0.4628 - val_loss: 0.6976 - val_acc: 0.3822\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6972 - acc: 0.4490 - val_loss: 0.6972 - val_acc: 0.3822\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6913 - acc: 0.4740 - val_loss: 0.6968 - val_acc: 0.3822\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6955 - acc: 0.4754 - val_loss: 0.6964 - val_acc: 0.3822\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6978 - acc: 0.4754 - val_loss: 0.6961 - val_acc: 0.3822\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6951 - acc: 0.4691 - val_loss: 0.6958 - val_acc: 0.3822\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6941 - acc: 0.4806 - val_loss: 0.6956 - val_acc: 0.3822\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6966 - acc: 0.4751 - val_loss: 0.6954 - val_acc: 0.3822\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7031 - acc: 0.4803 - val_loss: 0.6953 - val_acc: 0.3822\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6959 - acc: 0.4930 - val_loss: 0.6952 - val_acc: 0.3822\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6970 - acc: 0.5056 - val_loss: 0.6952 - val_acc: 0.4599\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7007 - acc: 0.5024 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6960 - acc: 0.5022 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6966 - acc: 0.4993 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6991 - acc: 0.5039 - val_loss: 0.6951 - val_acc: 0.6178\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6948 - acc: 0.5045 - val_loss: 0.6952 - val_acc: 0.4504\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6972 - acc: 0.4996 - val_loss: 0.6952 - val_acc: 0.3822\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6971 - acc: 0.5001 - val_loss: 0.6953 - val_acc: 0.3822\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6968 - acc: 0.4947 - val_loss: 0.6954 - val_acc: 0.3822\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6975 - acc: 0.5001 - val_loss: 0.6955 - val_acc: 0.3822\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6982 - acc: 0.4858 - val_loss: 0.6956 - val_acc: 0.3822\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6936 - acc: 0.5039 - val_loss: 0.6957 - val_acc: 0.3822\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7001 - acc: 0.4904 - val_loss: 0.6958 - val_acc: 0.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6976 - acc: 0.4817 - val_loss: 0.6959 - val_acc: 0.3822\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6948 - acc: 0.4852 - val_loss: 0.6960 - val_acc: 0.3822\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7004 - acc: 0.4745 - val_loss: 0.6961 - val_acc: 0.3822\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6951 - acc: 0.4846 - val_loss: 0.6961 - val_acc: 0.3822\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6973 - acc: 0.4774 - val_loss: 0.6962 - val_acc: 0.3822\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6953 - acc: 0.4783 - val_loss: 0.6962 - val_acc: 0.3822\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6994 - acc: 0.4768 - val_loss: 0.6961 - val_acc: 0.3822\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6924 - acc: 0.4780 - val_loss: 0.6961 - val_acc: 0.3822\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.6953 - acc: 0.4734 - val_loss: 0.6960 - val_acc: 0.3822\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6985 - acc: 0.4973 - val_loss: 0.6959 - val_acc: 0.3822\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7000 - acc: 0.4809 - val_loss: 0.6958 - val_acc: 0.3822\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6981 - acc: 0.4858 - val_loss: 0.6958 - val_acc: 0.3822\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6962 - acc: 0.4803 - val_loss: 0.6957 - val_acc: 0.3822\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6977 - acc: 0.4786 - val_loss: 0.6956 - val_acc: 0.3822\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6963 - acc: 0.5007 - val_loss: 0.6956 - val_acc: 0.3822\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6937 - acc: 0.4915 - val_loss: 0.6956 - val_acc: 0.3822\n",
      "sample weight :  [1.74308438e-04 6.42939649e-05 5.48153864e-05 ... 5.66769835e-05\n",
      " 5.62866960e-05 5.48193656e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7142 - acc: 0.4130 - val_loss: 0.6883 - val_acc: 0.3814\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7059 - acc: 0.4320 - val_loss: 0.6875 - val_acc: 0.3814\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7067 - acc: 0.4613 - val_loss: 0.6893 - val_acc: 0.6186\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7008 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.6186\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7036 - acc: 0.5309 - val_loss: 0.6977 - val_acc: 0.6186\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7038 - acc: 0.5559 - val_loss: 0.7016 - val_acc: 0.6186\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7030 - acc: 0.5654 - val_loss: 0.7037 - val_acc: 0.6186\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7104 - acc: 0.5741 - val_loss: 0.7040 - val_acc: 0.6186\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7043 - acc: 0.5827 - val_loss: 0.7029 - val_acc: 0.6186\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7059 - acc: 0.5789 - val_loss: 0.7009 - val_acc: 0.6186\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7028 - acc: 0.5605 - val_loss: 0.6987 - val_acc: 0.6186\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7020 - acc: 0.5637 - val_loss: 0.6964 - val_acc: 0.6186\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6995 - acc: 0.5657 - val_loss: 0.6944 - val_acc: 0.6186\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7043 - acc: 0.5344 - val_loss: 0.6927 - val_acc: 0.6186\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6988 - acc: 0.5372 - val_loss: 0.6915 - val_acc: 0.6186\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7007 - acc: 0.5303 - val_loss: 0.6906 - val_acc: 0.6186\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7070 - acc: 0.4996 - val_loss: 0.6899 - val_acc: 0.6186\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6995 - acc: 0.5246 - val_loss: 0.6896 - val_acc: 0.6186\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7051 - acc: 0.5272 - val_loss: 0.6894 - val_acc: 0.6186\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6944 - acc: 0.5093 - val_loss: 0.6893 - val_acc: 0.6186\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7007 - acc: 0.4996 - val_loss: 0.6894 - val_acc: 0.6186\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6992 - acc: 0.5050 - val_loss: 0.6897 - val_acc: 0.6186\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6990 - acc: 0.5062 - val_loss: 0.6900 - val_acc: 0.6186\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7006 - acc: 0.5116 - val_loss: 0.6905 - val_acc: 0.6186\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7024 - acc: 0.5013 - val_loss: 0.6910 - val_acc: 0.6186\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6931 - acc: 0.5275 - val_loss: 0.6916 - val_acc: 0.6186\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6976 - acc: 0.5329 - val_loss: 0.6923 - val_acc: 0.6186\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7021 - acc: 0.5361 - val_loss: 0.6928 - val_acc: 0.6186\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6965 - acc: 0.5467 - val_loss: 0.6934 - val_acc: 0.6186\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6959 - acc: 0.5482 - val_loss: 0.6938 - val_acc: 0.6186\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6971 - acc: 0.5562 - val_loss: 0.6942 - val_acc: 0.6186\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7005 - acc: 0.5557 - val_loss: 0.6944 - val_acc: 0.6186\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6929 - acc: 0.5499 - val_loss: 0.6945 - val_acc: 0.6186\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6961 - acc: 0.5539 - val_loss: 0.6944 - val_acc: 0.6186\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6968 - acc: 0.5588 - val_loss: 0.6942 - val_acc: 0.6186\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6959 - acc: 0.5496 - val_loss: 0.6939 - val_acc: 0.6186\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6992 - acc: 0.5444 - val_loss: 0.6935 - val_acc: 0.6186\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6962 - acc: 0.5516 - val_loss: 0.6932 - val_acc: 0.6186\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6975 - acc: 0.5557 - val_loss: 0.6929 - val_acc: 0.6186\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7017 - acc: 0.5372 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "Epoch 41/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6982 - acc: 0.5280 - val_loss: 0.6923 - val_acc: 0.6186\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6981 - acc: 0.5352 - val_loss: 0.6921 - val_acc: 0.6186\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6983 - acc: 0.5407 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6980 - acc: 0.5364 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6989 - acc: 0.5289 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6936 - acc: 0.5214 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6972 - acc: 0.5364 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6959 - acc: 0.5370 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7002 - acc: 0.5306 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6971 - acc: 0.5407 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6962 - acc: 0.5427 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7011 - acc: 0.5352 - val_loss: 0.6920 - val_acc: 0.6186\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6981 - acc: 0.5398 - val_loss: 0.6920 - val_acc: 0.6186\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6975 - acc: 0.5384 - val_loss: 0.6921 - val_acc: 0.6186\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6969 - acc: 0.5352 - val_loss: 0.6923 - val_acc: 0.6186\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7005 - acc: 0.5375 - val_loss: 0.6924 - val_acc: 0.6186\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6966 - acc: 0.5620 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6952 - acc: 0.5444 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6959 - acc: 0.5306 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6913 - acc: 0.5439 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6948 - acc: 0.5528 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6996 - acc: 0.5390 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6916 - acc: 0.5462 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6960 - acc: 0.5603 - val_loss: 0.6927 - val_acc: 0.6186\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6941 - acc: 0.5528 - val_loss: 0.6927 - val_acc: 0.6186\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6975 - acc: 0.5393 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6938 - acc: 0.5617 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6978 - acc: 0.5499 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6989 - acc: 0.5536 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6969 - acc: 0.5519 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "sample weight :  [1.83866682e-04 6.79072184e-05 5.27752089e-05 ... 5.40435838e-05\n",
      " 5.42484204e-05 5.20581338e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7515 - acc: 0.6031 - val_loss: 0.7523 - val_acc: 0.6204\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7362 - acc: 0.6028 - val_loss: 0.7394 - val_acc: 0.6204\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7230 - acc: 0.5928 - val_loss: 0.7291 - val_acc: 0.6204\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7126 - acc: 0.5812 - val_loss: 0.7214 - val_acc: 0.6204\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7056 - acc: 0.5611 - val_loss: 0.7162 - val_acc: 0.6204\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7082 - acc: 0.5234 - val_loss: 0.7134 - val_acc: 0.6204\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6931 - acc: 0.5036 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6892 - acc: 0.4743 - val_loss: 0.7143 - val_acc: 0.3796\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6913 - acc: 0.4469 - val_loss: 0.7168 - val_acc: 0.3796\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6909 - acc: 0.4285 - val_loss: 0.7194 - val_acc: 0.3796\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6963 - acc: 0.4242 - val_loss: 0.7211 - val_acc: 0.3796\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7000 - acc: 0.4193 - val_loss: 0.7217 - val_acc: 0.3796\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6911 - acc: 0.4139 - val_loss: 0.7212 - val_acc: 0.3796\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6957 - acc: 0.4173 - val_loss: 0.7200 - val_acc: 0.3796\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6983 - acc: 0.4156 - val_loss: 0.7185 - val_acc: 0.3796\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6971 - acc: 0.4265 - val_loss: 0.7170 - val_acc: 0.3796\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6935 - acc: 0.4271 - val_loss: 0.7156 - val_acc: 0.3796\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6966 - acc: 0.4294 - val_loss: 0.7145 - val_acc: 0.3796\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6879 - acc: 0.4409 - val_loss: 0.7137 - val_acc: 0.3796\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6958 - acc: 0.4412 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6910 - acc: 0.4579 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6906 - acc: 0.4636 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6948 - acc: 0.4797 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6961 - acc: 0.4705 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6886 - acc: 0.5085 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6920 - acc: 0.4866 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6881 - acc: 0.5042 - val_loss: 0.7132 - val_acc: 0.3796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6930 - acc: 0.4835 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6937 - acc: 0.4993 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6928 - acc: 0.4932 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6920 - acc: 0.4866 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6898 - acc: 0.4895 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6909 - acc: 0.4892 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6864 - acc: 0.4803 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6882 - acc: 0.4768 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6883 - acc: 0.4711 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6920 - acc: 0.4564 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6870 - acc: 0.4745 - val_loss: 0.7129 - val_acc: 0.3796\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6886 - acc: 0.4731 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6912 - acc: 0.4593 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6865 - acc: 0.4619 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6881 - acc: 0.4760 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6872 - acc: 0.4518 - val_loss: 0.7133 - val_acc: 0.3796\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6824 - acc: 0.4504 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6891 - acc: 0.4400 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6860 - acc: 0.4487 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6881 - acc: 0.4464 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6881 - acc: 0.4406 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6817 - acc: 0.4487 - val_loss: 0.7134 - val_acc: 0.3796\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6930 - acc: 0.4527 - val_loss: 0.7133 - val_acc: 0.3796\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6923 - acc: 0.4498 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6829 - acc: 0.4636 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6876 - acc: 0.4567 - val_loss: 0.7132 - val_acc: 0.3796\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6920 - acc: 0.4438 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6885 - acc: 0.4731 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6893 - acc: 0.4789 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6911 - acc: 0.4484 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6849 - acc: 0.4605 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6917 - acc: 0.4573 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6888 - acc: 0.4559 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6892 - acc: 0.4582 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6865 - acc: 0.4613 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6874 - acc: 0.4599 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.6914 - acc: 0.4590 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6885 - acc: 0.4754 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6894 - acc: 0.4461 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6883 - acc: 0.4651 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6879 - acc: 0.4596 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6890 - acc: 0.4397 - val_loss: 0.7130 - val_acc: 0.3796\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6876 - acc: 0.4596 - val_loss: 0.7131 - val_acc: 0.3796\n",
      "sample weight :  [1.73522035e-04 6.40829693e-05 5.60767695e-05 ... 5.73968133e-05\n",
      " 5.76908132e-05 5.51819862e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7159 - acc: 0.4274 - val_loss: 0.6871 - val_acc: 0.3796\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7088 - acc: 0.4438 - val_loss: 0.6808 - val_acc: 0.3796\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7063 - acc: 0.4711 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7071 - acc: 0.5022 - val_loss: 0.6758 - val_acc: 0.6204\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7068 - acc: 0.5217 - val_loss: 0.6755 - val_acc: 0.6204\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7100 - acc: 0.5347 - val_loss: 0.6756 - val_acc: 0.6204\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7094 - acc: 0.5565 - val_loss: 0.6756 - val_acc: 0.6204\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7120 - acc: 0.5490 - val_loss: 0.6755 - val_acc: 0.6204\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7065 - acc: 0.5499 - val_loss: 0.6756 - val_acc: 0.6204\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7054 - acc: 0.5390 - val_loss: 0.6758 - val_acc: 0.6204\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7102 - acc: 0.5482 - val_loss: 0.6763 - val_acc: 0.6204\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7082 - acc: 0.5191 - val_loss: 0.6769 - val_acc: 0.6204\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7055 - acc: 0.5039 - val_loss: 0.6777 - val_acc: 0.3796\n",
      "Epoch 14/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7030 - acc: 0.5010 - val_loss: 0.6784 - val_acc: 0.3796\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7003 - acc: 0.5050 - val_loss: 0.6791 - val_acc: 0.3796\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7003 - acc: 0.5024 - val_loss: 0.6794 - val_acc: 0.3796\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7059 - acc: 0.4826 - val_loss: 0.6796 - val_acc: 0.3796\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7050 - acc: 0.4748 - val_loss: 0.6794 - val_acc: 0.3796\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7059 - acc: 0.4783 - val_loss: 0.6791 - val_acc: 0.3796\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7030 - acc: 0.5001 - val_loss: 0.6787 - val_acc: 0.3796\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7046 - acc: 0.4861 - val_loss: 0.6782 - val_acc: 0.3796\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7110 - acc: 0.4886 - val_loss: 0.6777 - val_acc: 0.3796\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7057 - acc: 0.4869 - val_loss: 0.6773 - val_acc: 0.6204\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7076 - acc: 0.5036 - val_loss: 0.6769 - val_acc: 0.6204\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6984 - acc: 0.5116 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7062 - acc: 0.5096 - val_loss: 0.6763 - val_acc: 0.6204\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7064 - acc: 0.5188 - val_loss: 0.6761 - val_acc: 0.6204\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6989 - acc: 0.5372 - val_loss: 0.6760 - val_acc: 0.6204\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7047 - acc: 0.5418 - val_loss: 0.6759 - val_acc: 0.6204\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7011 - acc: 0.5194 - val_loss: 0.6759 - val_acc: 0.6204\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7086 - acc: 0.5260 - val_loss: 0.6760 - val_acc: 0.6204\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7054 - acc: 0.5263 - val_loss: 0.6761 - val_acc: 0.6204\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7005 - acc: 0.5266 - val_loss: 0.6762 - val_acc: 0.6204\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6999 - acc: 0.5266 - val_loss: 0.6764 - val_acc: 0.6204\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7070 - acc: 0.5168 - val_loss: 0.6766 - val_acc: 0.6204\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7045 - acc: 0.5114 - val_loss: 0.6768 - val_acc: 0.6204\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7028 - acc: 0.5050 - val_loss: 0.6771 - val_acc: 0.6204\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7069 - acc: 0.4973 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7009 - acc: 0.4884 - val_loss: 0.6774 - val_acc: 0.6204\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6991 - acc: 0.5099 - val_loss: 0.6775 - val_acc: 0.6204\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7034 - acc: 0.4904 - val_loss: 0.6775 - val_acc: 0.4435\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7048 - acc: 0.5027 - val_loss: 0.6775 - val_acc: 0.5513\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7037 - acc: 0.5045 - val_loss: 0.6774 - val_acc: 0.6204\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7052 - acc: 0.4993 - val_loss: 0.6773 - val_acc: 0.6204\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6989 - acc: 0.5004 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7074 - acc: 0.5108 - val_loss: 0.6770 - val_acc: 0.6204\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7059 - acc: 0.5079 - val_loss: 0.6769 - val_acc: 0.6204\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7016 - acc: 0.5108 - val_loss: 0.6767 - val_acc: 0.6204\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7047 - acc: 0.5024 - val_loss: 0.6767 - val_acc: 0.6204\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6994 - acc: 0.5183 - val_loss: 0.6766 - val_acc: 0.6204\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7012 - acc: 0.5105 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6993 - acc: 0.5131 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7013 - acc: 0.5269 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7010 - acc: 0.5062 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7004 - acc: 0.5234 - val_loss: 0.6765 - val_acc: 0.6204\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7014 - acc: 0.5211 - val_loss: 0.6766 - val_acc: 0.6204\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7008 - acc: 0.5329 - val_loss: 0.6767 - val_acc: 0.6204\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7008 - acc: 0.5206 - val_loss: 0.6768 - val_acc: 0.6204\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7087 - acc: 0.5131 - val_loss: 0.6769 - val_acc: 0.6204\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7001 - acc: 0.5174 - val_loss: 0.6770 - val_acc: 0.6204\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7048 - acc: 0.5085 - val_loss: 0.6771 - val_acc: 0.6204\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6980 - acc: 0.5116 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6987 - acc: 0.5237 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6991 - acc: 0.5016 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6959 - acc: 0.5111 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6987 - acc: 0.5183 - val_loss: 0.6772 - val_acc: 0.6204\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7003 - acc: 0.5157 - val_loss: 0.6771 - val_acc: 0.6204\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6978 - acc: 0.5168 - val_loss: 0.6770 - val_acc: 0.6204\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7037 - acc: 0.5007 - val_loss: 0.6770 - val_acc: 0.6204\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7010 - acc: 0.5131 - val_loss: 0.6769 - val_acc: 0.6204\n",
      "sample weight :  [1.75871896e-04 6.49135943e-05 5.54780564e-05 ... 5.67223397e-05\n",
      " 5.71308025e-05 5.44723045e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7616 - acc: 0.3914 - val_loss: 0.7451 - val_acc: 0.3900\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7438 - acc: 0.3911 - val_loss: 0.7293 - val_acc: 0.3900\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7309 - acc: 0.3934 - val_loss: 0.7158 - val_acc: 0.3900\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7198 - acc: 0.3989 - val_loss: 0.7046 - val_acc: 0.3900\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7132 - acc: 0.3986 - val_loss: 0.6958 - val_acc: 0.3900\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7150 - acc: 0.4176 - val_loss: 0.6892 - val_acc: 0.3900\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7039 - acc: 0.4481 - val_loss: 0.6849 - val_acc: 0.3900\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7022 - acc: 0.4754 - val_loss: 0.6826 - val_acc: 0.6100\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7059 - acc: 0.5114 - val_loss: 0.6819 - val_acc: 0.6100\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6975 - acc: 0.5413 - val_loss: 0.6819 - val_acc: 0.6100\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7046 - acc: 0.5301 - val_loss: 0.6822 - val_acc: 0.6100\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7092 - acc: 0.5571 - val_loss: 0.6823 - val_acc: 0.6100\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7071 - acc: 0.5582 - val_loss: 0.6822 - val_acc: 0.6100\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7007 - acc: 0.5574 - val_loss: 0.6820 - val_acc: 0.6100\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7058 - acc: 0.5421 - val_loss: 0.6819 - val_acc: 0.6100\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7030 - acc: 0.5565 - val_loss: 0.6818 - val_acc: 0.6100\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7066 - acc: 0.5456 - val_loss: 0.6820 - val_acc: 0.6100\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7025 - acc: 0.5226 - val_loss: 0.6824 - val_acc: 0.6100\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7074 - acc: 0.5082 - val_loss: 0.6830 - val_acc: 0.6100\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7121 - acc: 0.4886 - val_loss: 0.6837 - val_acc: 0.3900\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7011 - acc: 0.4866 - val_loss: 0.6846 - val_acc: 0.3900\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7043 - acc: 0.4743 - val_loss: 0.6854 - val_acc: 0.3900\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7005 - acc: 0.4757 - val_loss: 0.6862 - val_acc: 0.3900\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7053 - acc: 0.4518 - val_loss: 0.6869 - val_acc: 0.3900\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7064 - acc: 0.4576 - val_loss: 0.6875 - val_acc: 0.3900\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7023 - acc: 0.4573 - val_loss: 0.6879 - val_acc: 0.3900\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7028 - acc: 0.4478 - val_loss: 0.6882 - val_acc: 0.3900\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7007 - acc: 0.4567 - val_loss: 0.6883 - val_acc: 0.3900\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7000 - acc: 0.4521 - val_loss: 0.6883 - val_acc: 0.3900\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7003 - acc: 0.4464 - val_loss: 0.6881 - val_acc: 0.3900\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7072 - acc: 0.4351 - val_loss: 0.6878 - val_acc: 0.3900\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7068 - acc: 0.4458 - val_loss: 0.6874 - val_acc: 0.3900\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7010 - acc: 0.4464 - val_loss: 0.6869 - val_acc: 0.3900\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7030 - acc: 0.4602 - val_loss: 0.6864 - val_acc: 0.3900\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7022 - acc: 0.4530 - val_loss: 0.6859 - val_acc: 0.3900\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6983 - acc: 0.4630 - val_loss: 0.6854 - val_acc: 0.3900\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6986 - acc: 0.4665 - val_loss: 0.6850 - val_acc: 0.3900\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7045 - acc: 0.4780 - val_loss: 0.6846 - val_acc: 0.3900\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6975 - acc: 0.4869 - val_loss: 0.6842 - val_acc: 0.3900\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7030 - acc: 0.4861 - val_loss: 0.6839 - val_acc: 0.3900\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6953 - acc: 0.4863 - val_loss: 0.6837 - val_acc: 0.3900\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6972 - acc: 0.4967 - val_loss: 0.6835 - val_acc: 0.3900\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7013 - acc: 0.4976 - val_loss: 0.6834 - val_acc: 0.3900\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7002 - acc: 0.4990 - val_loss: 0.6833 - val_acc: 0.3900\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6978 - acc: 0.4907 - val_loss: 0.6833 - val_acc: 0.3900\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7038 - acc: 0.5033 - val_loss: 0.6833 - val_acc: 0.3900\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6974 - acc: 0.4993 - val_loss: 0.6833 - val_acc: 0.3900\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7012 - acc: 0.4953 - val_loss: 0.6833 - val_acc: 0.3900\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7038 - acc: 0.4840 - val_loss: 0.6834 - val_acc: 0.3900\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7011 - acc: 0.4976 - val_loss: 0.6836 - val_acc: 0.3900\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7057 - acc: 0.4921 - val_loss: 0.6837 - val_acc: 0.3900\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7027 - acc: 0.4725 - val_loss: 0.6839 - val_acc: 0.3900\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6985 - acc: 0.4866 - val_loss: 0.6840 - val_acc: 0.3900\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6996 - acc: 0.4846 - val_loss: 0.6842 - val_acc: 0.3900\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6935 - acc: 0.4953 - val_loss: 0.6843 - val_acc: 0.3900\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6992 - acc: 0.4705 - val_loss: 0.6845 - val_acc: 0.3900\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7035 - acc: 0.4823 - val_loss: 0.6846 - val_acc: 0.3900\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6966 - acc: 0.4780 - val_loss: 0.6848 - val_acc: 0.3900\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6977 - acc: 0.4838 - val_loss: 0.6849 - val_acc: 0.3900\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7012 - acc: 0.4653 - val_loss: 0.6850 - val_acc: 0.3900\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7024 - acc: 0.4556 - val_loss: 0.6851 - val_acc: 0.3900\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6979 - acc: 0.4731 - val_loss: 0.6852 - val_acc: 0.3900\n",
      "Epoch 63/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7025 - acc: 0.4490 - val_loss: 0.6852 - val_acc: 0.3900\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6950 - acc: 0.4674 - val_loss: 0.6851 - val_acc: 0.3900\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6987 - acc: 0.4659 - val_loss: 0.6851 - val_acc: 0.3900\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7067 - acc: 0.4567 - val_loss: 0.6850 - val_acc: 0.3900\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6963 - acc: 0.4711 - val_loss: 0.6849 - val_acc: 0.3900\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7000 - acc: 0.4625 - val_loss: 0.6848 - val_acc: 0.3900\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6975 - acc: 0.4720 - val_loss: 0.6847 - val_acc: 0.3900\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6968 - acc: 0.4817 - val_loss: 0.6846 - val_acc: 0.3900\n",
      "sample weight :  [1.70397663e-04 6.28889519e-05 5.71842117e-05 ... 5.84583821e-05\n",
      " 5.89098251e-05 5.61405614e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6943 - acc: 0.5516 - val_loss: 0.7136 - val_acc: 0.6057\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6933 - acc: 0.5105 - val_loss: 0.7157 - val_acc: 0.6057\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6953 - acc: 0.5099 - val_loss: 0.7163 - val_acc: 0.3943\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6924 - acc: 0.4958 - val_loss: 0.7160 - val_acc: 0.3900\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6876 - acc: 0.4930 - val_loss: 0.7152 - val_acc: 0.6057\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6927 - acc: 0.5039 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6915 - acc: 0.5013 - val_loss: 0.7135 - val_acc: 0.6057\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6895 - acc: 0.5232 - val_loss: 0.7131 - val_acc: 0.6057\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6825 - acc: 0.5453 - val_loss: 0.7131 - val_acc: 0.6057\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6922 - acc: 0.5421 - val_loss: 0.7132 - val_acc: 0.6057\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6916 - acc: 0.5275 - val_loss: 0.7134 - val_acc: 0.6057\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6887 - acc: 0.5384 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6876 - acc: 0.5237 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6917 - acc: 0.5234 - val_loss: 0.7144 - val_acc: 0.6057\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6928 - acc: 0.5134 - val_loss: 0.7146 - val_acc: 0.6057\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6949 - acc: 0.5022 - val_loss: 0.7147 - val_acc: 0.6057\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6883 - acc: 0.5214 - val_loss: 0.7148 - val_acc: 0.6057\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6879 - acc: 0.5053 - val_loss: 0.7148 - val_acc: 0.6057\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6892 - acc: 0.4993 - val_loss: 0.7147 - val_acc: 0.6057\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6888 - acc: 0.5200 - val_loss: 0.7146 - val_acc: 0.6057\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6854 - acc: 0.5243 - val_loss: 0.7144 - val_acc: 0.6057\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6917 - acc: 0.5151 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6885 - acc: 0.5157 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6913 - acc: 0.5232 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6857 - acc: 0.5341 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6851 - acc: 0.5338 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6871 - acc: 0.5505 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6911 - acc: 0.5410 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6867 - acc: 0.5249 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6878 - acc: 0.5257 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6858 - acc: 0.5324 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6876 - acc: 0.5272 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6922 - acc: 0.5237 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6859 - acc: 0.5387 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6874 - acc: 0.5131 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6864 - acc: 0.5390 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6856 - acc: 0.5255 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6855 - acc: 0.5341 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6892 - acc: 0.5295 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6909 - acc: 0.5229 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6874 - acc: 0.5209 - val_loss: 0.7143 - val_acc: 0.6057\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6863 - acc: 0.5375 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6859 - acc: 0.5269 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6872 - acc: 0.5329 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6848 - acc: 0.5416 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6893 - acc: 0.5255 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6894 - acc: 0.5203 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6865 - acc: 0.5410 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6865 - acc: 0.5358 - val_loss: 0.7140 - val_acc: 0.6057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6879 - acc: 0.5372 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6864 - acc: 0.5485 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6867 - acc: 0.5510 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6872 - acc: 0.5280 - val_loss: 0.7143 - val_acc: 0.6057\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6845 - acc: 0.5473 - val_loss: 0.7143 - val_acc: 0.6057\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6862 - acc: 0.5430 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6852 - acc: 0.5413 - val_loss: 0.7142 - val_acc: 0.6057\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6835 - acc: 0.5580 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6860 - acc: 0.5269 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6874 - acc: 0.5232 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6857 - acc: 0.5237 - val_loss: 0.7141 - val_acc: 0.6057\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6839 - acc: 0.5522 - val_loss: 0.7140 - val_acc: 0.6057\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6867 - acc: 0.5464 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6835 - acc: 0.5528 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6874 - acc: 0.5559 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6866 - acc: 0.5482 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6863 - acc: 0.5459 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6869 - acc: 0.5542 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6839 - acc: 0.5603 - val_loss: 0.7138 - val_acc: 0.6057\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6842 - acc: 0.5534 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6834 - acc: 0.5562 - val_loss: 0.7139 - val_acc: 0.6057\n",
      "sample weight :  [1.75562528e-04 6.46429106e-05 5.58486118e-05 ... 5.70145869e-05\n",
      " 5.73841231e-05 5.46232089e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7304 - acc: 0.6014 - val_loss: 0.6648 - val_acc: 0.5953\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7193 - acc: 0.5838 - val_loss: 0.6645 - val_acc: 0.5953\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7125 - acc: 0.5597 - val_loss: 0.6661 - val_acc: 0.5953\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7114 - acc: 0.5318 - val_loss: 0.6693 - val_acc: 0.4047\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7119 - acc: 0.4953 - val_loss: 0.6733 - val_acc: 0.4047\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7122 - acc: 0.4662 - val_loss: 0.6775 - val_acc: 0.4047\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7109 - acc: 0.4346 - val_loss: 0.6807 - val_acc: 0.4047\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7029 - acc: 0.4257 - val_loss: 0.6826 - val_acc: 0.4047\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7159 - acc: 0.4282 - val_loss: 0.6831 - val_acc: 0.4047\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7121 - acc: 0.4346 - val_loss: 0.6824 - val_acc: 0.4047\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7128 - acc: 0.4208 - val_loss: 0.6810 - val_acc: 0.4047\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7031 - acc: 0.4254 - val_loss: 0.6793 - val_acc: 0.4047\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7120 - acc: 0.4277 - val_loss: 0.6774 - val_acc: 0.4047\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7116 - acc: 0.4305 - val_loss: 0.6755 - val_acc: 0.4047\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7054 - acc: 0.4593 - val_loss: 0.6738 - val_acc: 0.4047\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7057 - acc: 0.4748 - val_loss: 0.6722 - val_acc: 0.4047\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7057 - acc: 0.4656 - val_loss: 0.6710 - val_acc: 0.4047\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7030 - acc: 0.4702 - val_loss: 0.6699 - val_acc: 0.4047\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7074 - acc: 0.4941 - val_loss: 0.6691 - val_acc: 0.4047\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7081 - acc: 0.5050 - val_loss: 0.6685 - val_acc: 0.5953\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7072 - acc: 0.5013 - val_loss: 0.6680 - val_acc: 0.5953\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7099 - acc: 0.4881 - val_loss: 0.6678 - val_acc: 0.5953\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7071 - acc: 0.5073 - val_loss: 0.6677 - val_acc: 0.5953\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7043 - acc: 0.5171 - val_loss: 0.6678 - val_acc: 0.5953\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7114 - acc: 0.5027 - val_loss: 0.6680 - val_acc: 0.5953\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7017 - acc: 0.5033 - val_loss: 0.6683 - val_acc: 0.5953\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7060 - acc: 0.4996 - val_loss: 0.6687 - val_acc: 0.5953\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7098 - acc: 0.4881 - val_loss: 0.6692 - val_acc: 0.4047\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7056 - acc: 0.4909 - val_loss: 0.6698 - val_acc: 0.4047\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7060 - acc: 0.4838 - val_loss: 0.6704 - val_acc: 0.4047\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7016 - acc: 0.4889 - val_loss: 0.6710 - val_acc: 0.4047\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7066 - acc: 0.4754 - val_loss: 0.6717 - val_acc: 0.4047\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7029 - acc: 0.4797 - val_loss: 0.6722 - val_acc: 0.4047\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7083 - acc: 0.4642 - val_loss: 0.6728 - val_acc: 0.4047\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7061 - acc: 0.4515 - val_loss: 0.6733 - val_acc: 0.4047\n",
      "Epoch 36/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7092 - acc: 0.4484 - val_loss: 0.6736 - val_acc: 0.4047\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7022 - acc: 0.4547 - val_loss: 0.6739 - val_acc: 0.4047\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7022 - acc: 0.4492 - val_loss: 0.6741 - val_acc: 0.4047\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7064 - acc: 0.4366 - val_loss: 0.6740 - val_acc: 0.4047\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6986 - acc: 0.4547 - val_loss: 0.6739 - val_acc: 0.4047\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7049 - acc: 0.4550 - val_loss: 0.6737 - val_acc: 0.4047\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7044 - acc: 0.4530 - val_loss: 0.6734 - val_acc: 0.4047\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6999 - acc: 0.4605 - val_loss: 0.6731 - val_acc: 0.4047\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7040 - acc: 0.4501 - val_loss: 0.6727 - val_acc: 0.4047\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7027 - acc: 0.4584 - val_loss: 0.6723 - val_acc: 0.4047\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7022 - acc: 0.4708 - val_loss: 0.6719 - val_acc: 0.4047\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6989 - acc: 0.4829 - val_loss: 0.6716 - val_acc: 0.4047\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7021 - acc: 0.4714 - val_loss: 0.6713 - val_acc: 0.4047\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7058 - acc: 0.4616 - val_loss: 0.6711 - val_acc: 0.4047\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7030 - acc: 0.4786 - val_loss: 0.6709 - val_acc: 0.4047\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6994 - acc: 0.4849 - val_loss: 0.6708 - val_acc: 0.4047\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7049 - acc: 0.4780 - val_loss: 0.6707 - val_acc: 0.4047\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6997 - acc: 0.4797 - val_loss: 0.6708 - val_acc: 0.4047\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7047 - acc: 0.4720 - val_loss: 0.6708 - val_acc: 0.4047\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7012 - acc: 0.4838 - val_loss: 0.6708 - val_acc: 0.4047\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7063 - acc: 0.4754 - val_loss: 0.6709 - val_acc: 0.4047\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7002 - acc: 0.4886 - val_loss: 0.6710 - val_acc: 0.4047\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7070 - acc: 0.4648 - val_loss: 0.6712 - val_acc: 0.4047\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7009 - acc: 0.4737 - val_loss: 0.6713 - val_acc: 0.4047\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7050 - acc: 0.4748 - val_loss: 0.6715 - val_acc: 0.4047\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7037 - acc: 0.4720 - val_loss: 0.6717 - val_acc: 0.4047\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6998 - acc: 0.4556 - val_loss: 0.6719 - val_acc: 0.4047\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6991 - acc: 0.4659 - val_loss: 0.6721 - val_acc: 0.4047\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6995 - acc: 0.4527 - val_loss: 0.6724 - val_acc: 0.4047\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7008 - acc: 0.4567 - val_loss: 0.6725 - val_acc: 0.4047\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7043 - acc: 0.4507 - val_loss: 0.6726 - val_acc: 0.4047\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6983 - acc: 0.4613 - val_loss: 0.6726 - val_acc: 0.4047\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7016 - acc: 0.4504 - val_loss: 0.6725 - val_acc: 0.4047\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7047 - acc: 0.4438 - val_loss: 0.6724 - val_acc: 0.4047\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7036 - acc: 0.4484 - val_loss: 0.6722 - val_acc: 0.4047\n",
      "sample weight :  [1.69465241e-04 6.22730831e-05 5.82794360e-05 ... 5.91372531e-05\n",
      " 5.95447249e-05 5.65525676e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7097 - acc: 0.4165 - val_loss: 0.7197 - val_acc: 0.3909\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6992 - acc: 0.4674 - val_loss: 0.7192 - val_acc: 0.3909\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7000 - acc: 0.4892 - val_loss: 0.7213 - val_acc: 0.6091\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6881 - acc: 0.5275 - val_loss: 0.7258 - val_acc: 0.6091\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6800 - acc: 0.5712 - val_loss: 0.7318 - val_acc: 0.6091\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6870 - acc: 0.5882 - val_loss: 0.7380 - val_acc: 0.6091\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6885 - acc: 0.6034 - val_loss: 0.7426 - val_acc: 0.6091\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6916 - acc: 0.6054 - val_loss: 0.7446 - val_acc: 0.6091\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6859 - acc: 0.6011 - val_loss: 0.7443 - val_acc: 0.6091\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6894 - acc: 0.6066 - val_loss: 0.7424 - val_acc: 0.6091\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6903 - acc: 0.6074 - val_loss: 0.7397 - val_acc: 0.6091\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6879 - acc: 0.6022 - val_loss: 0.7366 - val_acc: 0.6091\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6879 - acc: 0.5953 - val_loss: 0.7335 - val_acc: 0.6091\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6801 - acc: 0.6068 - val_loss: 0.7308 - val_acc: 0.6091\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6842 - acc: 0.5979 - val_loss: 0.7285 - val_acc: 0.6091\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6849 - acc: 0.5778 - val_loss: 0.7268 - val_acc: 0.6091\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6851 - acc: 0.5781 - val_loss: 0.7254 - val_acc: 0.6091\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6894 - acc: 0.5626 - val_loss: 0.7244 - val_acc: 0.6091\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6845 - acc: 0.5496 - val_loss: 0.7238 - val_acc: 0.6091\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6894 - acc: 0.5436 - val_loss: 0.7235 - val_acc: 0.6091\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6912 - acc: 0.5464 - val_loss: 0.7234 - val_acc: 0.6091\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6832 - acc: 0.5594 - val_loss: 0.7235 - val_acc: 0.6091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6847 - acc: 0.5631 - val_loss: 0.7238 - val_acc: 0.6091\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6879 - acc: 0.5410 - val_loss: 0.7243 - val_acc: 0.6091\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6827 - acc: 0.5649 - val_loss: 0.7249 - val_acc: 0.6091\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6889 - acc: 0.5660 - val_loss: 0.7256 - val_acc: 0.6091\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6854 - acc: 0.5689 - val_loss: 0.7264 - val_acc: 0.6091\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6809 - acc: 0.5660 - val_loss: 0.7273 - val_acc: 0.6091\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6841 - acc: 0.5847 - val_loss: 0.7281 - val_acc: 0.6091\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6799 - acc: 0.5778 - val_loss: 0.7288 - val_acc: 0.6091\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6868 - acc: 0.5962 - val_loss: 0.7295 - val_acc: 0.6091\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6869 - acc: 0.5936 - val_loss: 0.7301 - val_acc: 0.6091\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6814 - acc: 0.5974 - val_loss: 0.7305 - val_acc: 0.6091\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6900 - acc: 0.5959 - val_loss: 0.7307 - val_acc: 0.6091\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6832 - acc: 0.5994 - val_loss: 0.7308 - val_acc: 0.6091\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6913 - acc: 0.6002 - val_loss: 0.7306 - val_acc: 0.6091\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6847 - acc: 0.5976 - val_loss: 0.7303 - val_acc: 0.6091\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6867 - acc: 0.5994 - val_loss: 0.7299 - val_acc: 0.6091\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6823 - acc: 0.6011 - val_loss: 0.7295 - val_acc: 0.6091\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6834 - acc: 0.5864 - val_loss: 0.7291 - val_acc: 0.6091\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6794 - acc: 0.5988 - val_loss: 0.7287 - val_acc: 0.6091\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6810 - acc: 0.5974 - val_loss: 0.7282 - val_acc: 0.6091\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6870 - acc: 0.5827 - val_loss: 0.7278 - val_acc: 0.6091\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6870 - acc: 0.5861 - val_loss: 0.7275 - val_acc: 0.6091\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6816 - acc: 0.5850 - val_loss: 0.7272 - val_acc: 0.6091\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6818 - acc: 0.5928 - val_loss: 0.7271 - val_acc: 0.6091\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6805 - acc: 0.5936 - val_loss: 0.7270 - val_acc: 0.6091\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6828 - acc: 0.5902 - val_loss: 0.7271 - val_acc: 0.6091\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6826 - acc: 0.5864 - val_loss: 0.7272 - val_acc: 0.6091\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6780 - acc: 0.5884 - val_loss: 0.7273 - val_acc: 0.6091\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6851 - acc: 0.5844 - val_loss: 0.7275 - val_acc: 0.6091\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6834 - acc: 0.5974 - val_loss: 0.7276 - val_acc: 0.6091\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6846 - acc: 0.5988 - val_loss: 0.7278 - val_acc: 0.6091\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6846 - acc: 0.5856 - val_loss: 0.7280 - val_acc: 0.6091\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6836 - acc: 0.5939 - val_loss: 0.7282 - val_acc: 0.6091\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6844 - acc: 0.5876 - val_loss: 0.7284 - val_acc: 0.6091\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6846 - acc: 0.5905 - val_loss: 0.7285 - val_acc: 0.6091\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.6842 - acc: 0.5948 - val_loss: 0.7287 - val_acc: 0.6091\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6800 - acc: 0.6008 - val_loss: 0.7288 - val_acc: 0.6091\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6795 - acc: 0.5959 - val_loss: 0.7289 - val_acc: 0.6091\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6827 - acc: 0.6063 - val_loss: 0.7289 - val_acc: 0.6091\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6784 - acc: 0.6014 - val_loss: 0.7289 - val_acc: 0.6091\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6826 - acc: 0.5936 - val_loss: 0.7288 - val_acc: 0.6091\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6830 - acc: 0.5971 - val_loss: 0.7287 - val_acc: 0.6091\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6817 - acc: 0.6031 - val_loss: 0.7285 - val_acc: 0.6091\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6838 - acc: 0.5982 - val_loss: 0.7283 - val_acc: 0.6091\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6832 - acc: 0.6020 - val_loss: 0.7282 - val_acc: 0.6091\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6851 - acc: 0.6017 - val_loss: 0.7281 - val_acc: 0.6091\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6848 - acc: 0.5971 - val_loss: 0.7280 - val_acc: 0.6091\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6815 - acc: 0.6054 - val_loss: 0.7280 - val_acc: 0.6091\n",
      "sample weight :  [1.90342818e-04 6.99972451e-05 5.17222231e-05 ... 5.24802190e-05\n",
      " 5.29548699e-05 5.02224072e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7063 - acc: 0.3934 - val_loss: 0.7034 - val_acc: 0.3891\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6941 - acc: 0.4118 - val_loss: 0.7032 - val_acc: 0.3891\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6961 - acc: 0.4314 - val_loss: 0.7049 - val_acc: 0.3891\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6946 - acc: 0.4547 - val_loss: 0.7078 - val_acc: 0.3891\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6949 - acc: 0.4889 - val_loss: 0.7110 - val_acc: 0.6109\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6934 - acc: 0.5024 - val_loss: 0.7135 - val_acc: 0.6109\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6981 - acc: 0.5191 - val_loss: 0.7146 - val_acc: 0.6109\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6967 - acc: 0.5306 - val_loss: 0.7145 - val_acc: 0.6109\n",
      "Epoch 9/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6922 - acc: 0.5306 - val_loss: 0.7135 - val_acc: 0.6109\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6887 - acc: 0.5444 - val_loss: 0.7120 - val_acc: 0.6109\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6992 - acc: 0.5076 - val_loss: 0.7104 - val_acc: 0.6109\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6976 - acc: 0.5007 - val_loss: 0.7087 - val_acc: 0.3891\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6907 - acc: 0.4981 - val_loss: 0.7074 - val_acc: 0.3891\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6911 - acc: 0.4852 - val_loss: 0.7062 - val_acc: 0.3891\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6977 - acc: 0.4656 - val_loss: 0.7054 - val_acc: 0.3891\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6921 - acc: 0.4478 - val_loss: 0.7048 - val_acc: 0.3891\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6946 - acc: 0.4423 - val_loss: 0.7045 - val_acc: 0.3891\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6920 - acc: 0.4389 - val_loss: 0.7043 - val_acc: 0.3891\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6966 - acc: 0.4438 - val_loss: 0.7041 - val_acc: 0.3891\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6916 - acc: 0.4317 - val_loss: 0.7042 - val_acc: 0.3891\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6911 - acc: 0.4354 - val_loss: 0.7043 - val_acc: 0.3891\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6947 - acc: 0.4248 - val_loss: 0.7045 - val_acc: 0.3891\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6967 - acc: 0.4412 - val_loss: 0.7047 - val_acc: 0.3891\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6976 - acc: 0.4406 - val_loss: 0.7051 - val_acc: 0.3891\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6876 - acc: 0.4642 - val_loss: 0.7055 - val_acc: 0.3891\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6947 - acc: 0.4386 - val_loss: 0.7059 - val_acc: 0.3891\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6909 - acc: 0.4607 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6918 - acc: 0.4443 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6900 - acc: 0.4653 - val_loss: 0.7071 - val_acc: 0.3891\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6913 - acc: 0.4768 - val_loss: 0.7074 - val_acc: 0.3891\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6896 - acc: 0.4806 - val_loss: 0.7077 - val_acc: 0.3891\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6956 - acc: 0.4768 - val_loss: 0.7078 - val_acc: 0.3891\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6928 - acc: 0.4794 - val_loss: 0.7079 - val_acc: 0.3891\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6914 - acc: 0.4731 - val_loss: 0.7079 - val_acc: 0.3891\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6889 - acc: 0.4812 - val_loss: 0.7077 - val_acc: 0.3891\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6882 - acc: 0.4809 - val_loss: 0.7075 - val_acc: 0.3891\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6874 - acc: 0.4852 - val_loss: 0.7072 - val_acc: 0.3891\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6926 - acc: 0.4682 - val_loss: 0.7070 - val_acc: 0.3891\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6900 - acc: 0.4688 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6901 - acc: 0.4711 - val_loss: 0.7065 - val_acc: 0.3891\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6919 - acc: 0.4610 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6906 - acc: 0.4409 - val_loss: 0.7062 - val_acc: 0.3891\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6886 - acc: 0.4550 - val_loss: 0.7061 - val_acc: 0.3891\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6886 - acc: 0.4628 - val_loss: 0.7060 - val_acc: 0.3891\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6931 - acc: 0.4573 - val_loss: 0.7060 - val_acc: 0.3891\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6862 - acc: 0.4564 - val_loss: 0.7061 - val_acc: 0.3891\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6880 - acc: 0.4590 - val_loss: 0.7062 - val_acc: 0.3891\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6876 - acc: 0.4619 - val_loss: 0.7062 - val_acc: 0.3891\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6870 - acc: 0.4593 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6919 - acc: 0.4478 - val_loss: 0.7064 - val_acc: 0.3891\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6933 - acc: 0.4372 - val_loss: 0.7065 - val_acc: 0.3891\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6925 - acc: 0.4412 - val_loss: 0.7066 - val_acc: 0.3891\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6882 - acc: 0.4541 - val_loss: 0.7066 - val_acc: 0.3891\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6849 - acc: 0.4524 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6882 - acc: 0.4504 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6903 - acc: 0.4538 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6900 - acc: 0.4561 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6909 - acc: 0.4527 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6873 - acc: 0.4449 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6894 - acc: 0.4530 - val_loss: 0.7067 - val_acc: 0.3891\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6859 - acc: 0.4504 - val_loss: 0.7066 - val_acc: 0.3891\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6858 - acc: 0.4561 - val_loss: 0.7066 - val_acc: 0.3891\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6885 - acc: 0.4349 - val_loss: 0.7065 - val_acc: 0.3891\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6892 - acc: 0.4420 - val_loss: 0.7065 - val_acc: 0.3891\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6832 - acc: 0.4541 - val_loss: 0.7064 - val_acc: 0.3891\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6895 - acc: 0.4308 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6859 - acc: 0.4504 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6887 - acc: 0.4308 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6845 - acc: 0.4619 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6876 - acc: 0.4449 - val_loss: 0.7063 - val_acc: 0.3891\n",
      "sample weight :  [1.82078402e-04 6.69693074e-05 5.45003843e-05 ... 5.51010498e-05\n",
      " 5.57043965e-05 5.27402812e-05]\n",
      "x sum 1644947.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7088 - acc: 0.5502 - val_loss: 0.6808 - val_acc: 0.5919\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7063 - acc: 0.5151 - val_loss: 0.6773 - val_acc: 0.4081\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7051 - acc: 0.4829 - val_loss: 0.6760 - val_acc: 0.4081\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7058 - acc: 0.4530 - val_loss: 0.6758 - val_acc: 0.4081\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7026 - acc: 0.4510 - val_loss: 0.6760 - val_acc: 0.4081\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7012 - acc: 0.4676 - val_loss: 0.6765 - val_acc: 0.4081\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7093 - acc: 0.4622 - val_loss: 0.6773 - val_acc: 0.4081\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7039 - acc: 0.4823 - val_loss: 0.6784 - val_acc: 0.4081\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7061 - acc: 0.5073 - val_loss: 0.6794 - val_acc: 0.5919\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7048 - acc: 0.5047 - val_loss: 0.6800 - val_acc: 0.5919\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7030 - acc: 0.4978 - val_loss: 0.6804 - val_acc: 0.5919\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7022 - acc: 0.5091 - val_loss: 0.6806 - val_acc: 0.5919\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7066 - acc: 0.5111 - val_loss: 0.6803 - val_acc: 0.5919\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7024 - acc: 0.5165 - val_loss: 0.6799 - val_acc: 0.5919\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7056 - acc: 0.5091 - val_loss: 0.6794 - val_acc: 0.5919\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7014 - acc: 0.5073 - val_loss: 0.6787 - val_acc: 0.4081\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7086 - acc: 0.4953 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7095 - acc: 0.4852 - val_loss: 0.6777 - val_acc: 0.4081\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7056 - acc: 0.4748 - val_loss: 0.6774 - val_acc: 0.4081\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7007 - acc: 0.4855 - val_loss: 0.6771 - val_acc: 0.4081\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7092 - acc: 0.4728 - val_loss: 0.6770 - val_acc: 0.4081\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7022 - acc: 0.4757 - val_loss: 0.6769 - val_acc: 0.4081\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6987 - acc: 0.4645 - val_loss: 0.6770 - val_acc: 0.4081\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7014 - acc: 0.4789 - val_loss: 0.6772 - val_acc: 0.4081\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6982 - acc: 0.4720 - val_loss: 0.6775 - val_acc: 0.4081\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7033 - acc: 0.4708 - val_loss: 0.6779 - val_acc: 0.4081\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7025 - acc: 0.4924 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6992 - acc: 0.4806 - val_loss: 0.6786 - val_acc: 0.4081\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7009 - acc: 0.5030 - val_loss: 0.6789 - val_acc: 0.4081\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7036 - acc: 0.5033 - val_loss: 0.6790 - val_acc: 0.4081\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7062 - acc: 0.4898 - val_loss: 0.6790 - val_acc: 0.4081\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6972 - acc: 0.5059 - val_loss: 0.6790 - val_acc: 0.4081\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7025 - acc: 0.4978 - val_loss: 0.6788 - val_acc: 0.4081\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7012 - acc: 0.4967 - val_loss: 0.6787 - val_acc: 0.4081\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6953 - acc: 0.5022 - val_loss: 0.6785 - val_acc: 0.4081\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6958 - acc: 0.4967 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7046 - acc: 0.4763 - val_loss: 0.6779 - val_acc: 0.4081\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7023 - acc: 0.4912 - val_loss: 0.6777 - val_acc: 0.4081\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7019 - acc: 0.4593 - val_loss: 0.6775 - val_acc: 0.4081\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7017 - acc: 0.4553 - val_loss: 0.6775 - val_acc: 0.4081\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6982 - acc: 0.4907 - val_loss: 0.6775 - val_acc: 0.4081\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6989 - acc: 0.4800 - val_loss: 0.6777 - val_acc: 0.4081\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7002 - acc: 0.4768 - val_loss: 0.6779 - val_acc: 0.4081\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7005 - acc: 0.4645 - val_loss: 0.6780 - val_acc: 0.4081\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6982 - acc: 0.4840 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7001 - acc: 0.4886 - val_loss: 0.6784 - val_acc: 0.4081\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7030 - acc: 0.4800 - val_loss: 0.6785 - val_acc: 0.4081\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6987 - acc: 0.4803 - val_loss: 0.6785 - val_acc: 0.4081\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7009 - acc: 0.4938 - val_loss: 0.6785 - val_acc: 0.4081\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6982 - acc: 0.4921 - val_loss: 0.6784 - val_acc: 0.4081\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6991 - acc: 0.4978 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6974 - acc: 0.4789 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6989 - acc: 0.4806 - val_loss: 0.6781 - val_acc: 0.4081\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6991 - acc: 0.4835 - val_loss: 0.6780 - val_acc: 0.4081\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6995 - acc: 0.4685 - val_loss: 0.6779 - val_acc: 0.4081\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7010 - acc: 0.4697 - val_loss: 0.6778 - val_acc: 0.4081\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6959 - acc: 0.4731 - val_loss: 0.6778 - val_acc: 0.4081\n",
      "Epoch 58/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 888ms/step - loss: 0.6991 - acc: 0.4783 - val_loss: 0.6779 - val_acc: 0.4081\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7010 - acc: 0.4639 - val_loss: 0.6780 - val_acc: 0.4081\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6989 - acc: 0.4849 - val_loss: 0.6781 - val_acc: 0.4081\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7034 - acc: 0.4653 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7000 - acc: 0.4708 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6995 - acc: 0.4734 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7007 - acc: 0.4806 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7013 - acc: 0.4964 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6977 - acc: 0.4861 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6972 - acc: 0.4978 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7017 - acc: 0.4743 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6993 - acc: 0.4674 - val_loss: 0.6782 - val_acc: 0.4081\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7009 - acc: 0.4642 - val_loss: 0.6783 - val_acc: 0.4081\n",
      "sample weight :  [1.79878514e-04 6.62100247e-05 5.52541734e-05 ... 5.60935702e-05\n",
      " 5.67379275e-05 5.34333127e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6910 - acc: 0.4849 - val_loss: 0.7167 - val_acc: 0.3952\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6876 - acc: 0.4944 - val_loss: 0.7167 - val_acc: 0.3952\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6849 - acc: 0.4921 - val_loss: 0.7167 - val_acc: 0.3952\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6897 - acc: 0.4932 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6947 - acc: 0.4858 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6923 - acc: 0.4970 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6888 - acc: 0.4964 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6880 - acc: 0.4872 - val_loss: 0.7171 - val_acc: 0.3952\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6963 - acc: 0.4849 - val_loss: 0.7172 - val_acc: 0.3952\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6875 - acc: 0.4835 - val_loss: 0.7171 - val_acc: 0.3952\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6897 - acc: 0.4786 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6900 - acc: 0.4835 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6907 - acc: 0.4861 - val_loss: 0.7167 - val_acc: 0.6048\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6839 - acc: 0.5059 - val_loss: 0.7166 - val_acc: 0.6048\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6889 - acc: 0.5016 - val_loss: 0.7166 - val_acc: 0.6048\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6912 - acc: 0.5042 - val_loss: 0.7166 - val_acc: 0.6048\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6892 - acc: 0.4955 - val_loss: 0.7166 - val_acc: 0.6048\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6922 - acc: 0.4935 - val_loss: 0.7167 - val_acc: 0.3952\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6917 - acc: 0.5122 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6866 - acc: 0.4955 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6849 - acc: 0.4869 - val_loss: 0.7171 - val_acc: 0.3952\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6877 - acc: 0.4884 - val_loss: 0.7172 - val_acc: 0.3952\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6883 - acc: 0.4734 - val_loss: 0.7172 - val_acc: 0.3952\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6897 - acc: 0.4659 - val_loss: 0.7171 - val_acc: 0.3952\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6863 - acc: 0.4869 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6900 - acc: 0.4861 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6860 - acc: 0.4953 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6883 - acc: 0.4924 - val_loss: 0.7167 - val_acc: 0.3952\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6860 - acc: 0.4964 - val_loss: 0.7167 - val_acc: 0.6048\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6850 - acc: 0.5088 - val_loss: 0.7167 - val_acc: 0.3960\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6867 - acc: 0.5099 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6900 - acc: 0.5019 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6846 - acc: 0.5033 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6869 - acc: 0.4918 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6927 - acc: 0.4636 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6871 - acc: 0.4907 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6873 - acc: 0.4760 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6874 - acc: 0.4863 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6861 - acc: 0.4921 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6895 - acc: 0.4740 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6831 - acc: 0.5010 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6882 - acc: 0.4852 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6848 - acc: 0.5030 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6892 - acc: 0.4812 - val_loss: 0.7169 - val_acc: 0.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6873 - acc: 0.4881 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6850 - acc: 0.4875 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6864 - acc: 0.4898 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6870 - acc: 0.4786 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6836 - acc: 0.4884 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6863 - acc: 0.4757 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6856 - acc: 0.4829 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6849 - acc: 0.4895 - val_loss: 0.7168 - val_acc: 0.3952\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6830 - acc: 0.5036 - val_loss: 0.7168 - val_acc: 0.3960\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6867 - acc: 0.4961 - val_loss: 0.7167 - val_acc: 0.4564\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6822 - acc: 0.5093 - val_loss: 0.7167 - val_acc: 0.4823\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6868 - acc: 0.5013 - val_loss: 0.7167 - val_acc: 0.4668\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6857 - acc: 0.4967 - val_loss: 0.7167 - val_acc: 0.4521\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6843 - acc: 0.5073 - val_loss: 0.7168 - val_acc: 0.4374\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6825 - acc: 0.5065 - val_loss: 0.7168 - val_acc: 0.4116\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6864 - acc: 0.4832 - val_loss: 0.7169 - val_acc: 0.3943\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6863 - acc: 0.4754 - val_loss: 0.7169 - val_acc: 0.3952\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6835 - acc: 0.4820 - val_loss: 0.7170 - val_acc: 0.3952\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6862 - acc: 0.4786 - val_loss: 0.7171 - val_acc: 0.3952\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6847 - acc: 0.4832 - val_loss: 0.7171 - val_acc: 0.3960\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6815 - acc: 0.4852 - val_loss: 0.7170 - val_acc: 0.3926\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6838 - acc: 0.4777 - val_loss: 0.7169 - val_acc: 0.4331\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6812 - acc: 0.4737 - val_loss: 0.7168 - val_acc: 0.4400\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6821 - acc: 0.4953 - val_loss: 0.7168 - val_acc: 0.4297\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6824 - acc: 0.5070 - val_loss: 0.7168 - val_acc: 0.4297\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6806 - acc: 0.4884 - val_loss: 0.7168 - val_acc: 0.4236\n",
      "sample weight :  [1.80470998e-04 6.70421624e-05 5.72473038e-05 ... 5.70306167e-05\n",
      " 5.81529025e-05 5.37584770e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7518 - acc: 0.6068 - val_loss: 0.6714 - val_acc: 0.6281\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7437 - acc: 0.6040 - val_loss: 0.6605 - val_acc: 0.6281\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7391 - acc: 0.5893 - val_loss: 0.6520 - val_acc: 0.6281\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7347 - acc: 0.5758 - val_loss: 0.6460 - val_acc: 0.6281\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7174 - acc: 0.5692 - val_loss: 0.6424 - val_acc: 0.6281\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7227 - acc: 0.5404 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7203 - acc: 0.4846 - val_loss: 0.6406 - val_acc: 0.3719\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7249 - acc: 0.4838 - val_loss: 0.6413 - val_acc: 0.3719\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7253 - acc: 0.4582 - val_loss: 0.6420 - val_acc: 0.3719\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7220 - acc: 0.4510 - val_loss: 0.6424 - val_acc: 0.3719\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7261 - acc: 0.4550 - val_loss: 0.6423 - val_acc: 0.3719\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7324 - acc: 0.4550 - val_loss: 0.6419 - val_acc: 0.3719\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7176 - acc: 0.4584 - val_loss: 0.6413 - val_acc: 0.3719\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7200 - acc: 0.4596 - val_loss: 0.6409 - val_acc: 0.3719\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7190 - acc: 0.4722 - val_loss: 0.6406 - val_acc: 0.3719\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7181 - acc: 0.4817 - val_loss: 0.6406 - val_acc: 0.3719\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7159 - acc: 0.4964 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7194 - acc: 0.5059 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7230 - acc: 0.5111 - val_loss: 0.6414 - val_acc: 0.6281\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7153 - acc: 0.5303 - val_loss: 0.6418 - val_acc: 0.6281\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7195 - acc: 0.5246 - val_loss: 0.6422 - val_acc: 0.6281\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7150 - acc: 0.5326 - val_loss: 0.6426 - val_acc: 0.6281\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7205 - acc: 0.5381 - val_loss: 0.6428 - val_acc: 0.6281\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7128 - acc: 0.5522 - val_loss: 0.6430 - val_acc: 0.6281\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7119 - acc: 0.5493 - val_loss: 0.6431 - val_acc: 0.6281\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7161 - acc: 0.5421 - val_loss: 0.6430 - val_acc: 0.6281\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7178 - acc: 0.5467 - val_loss: 0.6429 - val_acc: 0.6281\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7191 - acc: 0.5476 - val_loss: 0.6428 - val_acc: 0.6281\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7217 - acc: 0.5298 - val_loss: 0.6425 - val_acc: 0.6281\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7183 - acc: 0.5318 - val_loss: 0.6422 - val_acc: 0.6281\n",
      "Epoch 31/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7118 - acc: 0.5358 - val_loss: 0.6419 - val_acc: 0.6281\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7120 - acc: 0.5326 - val_loss: 0.6417 - val_acc: 0.6281\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7207 - acc: 0.5180 - val_loss: 0.6414 - val_acc: 0.6281\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7160 - acc: 0.5139 - val_loss: 0.6412 - val_acc: 0.6281\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7155 - acc: 0.5186 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7181 - acc: 0.5171 - val_loss: 0.6409 - val_acc: 0.6281\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7184 - acc: 0.5022 - val_loss: 0.6408 - val_acc: 0.6281\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7168 - acc: 0.5065 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7118 - acc: 0.5168 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7181 - acc: 0.5019 - val_loss: 0.6406 - val_acc: 0.6281\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7202 - acc: 0.5168 - val_loss: 0.6406 - val_acc: 0.6186\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7168 - acc: 0.4973 - val_loss: 0.6406 - val_acc: 0.5315\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7189 - acc: 0.5145 - val_loss: 0.6406 - val_acc: 0.5798\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7134 - acc: 0.5042 - val_loss: 0.6406 - val_acc: 0.6281\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7153 - acc: 0.4970 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7222 - acc: 0.4973 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7137 - acc: 0.5105 - val_loss: 0.6407 - val_acc: 0.6281\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7151 - acc: 0.5010 - val_loss: 0.6408 - val_acc: 0.6281\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7209 - acc: 0.5053 - val_loss: 0.6409 - val_acc: 0.6281\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7127 - acc: 0.5157 - val_loss: 0.6409 - val_acc: 0.6281\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7143 - acc: 0.5160 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7127 - acc: 0.5338 - val_loss: 0.6411 - val_acc: 0.6281\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7149 - acc: 0.5255 - val_loss: 0.6411 - val_acc: 0.6281\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7215 - acc: 0.5154 - val_loss: 0.6412 - val_acc: 0.6281\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7143 - acc: 0.5142 - val_loss: 0.6412 - val_acc: 0.6281\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7158 - acc: 0.5116 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7128 - acc: 0.5269 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7153 - acc: 0.5263 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7174 - acc: 0.5278 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7171 - acc: 0.5381 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7167 - acc: 0.5347 - val_loss: 0.6413 - val_acc: 0.6281\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7153 - acc: 0.5309 - val_loss: 0.6412 - val_acc: 0.6281\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7132 - acc: 0.5125 - val_loss: 0.6412 - val_acc: 0.6281\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7160 - acc: 0.5407 - val_loss: 0.6411 - val_acc: 0.6281\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7105 - acc: 0.5246 - val_loss: 0.6411 - val_acc: 0.6281\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7169 - acc: 0.5183 - val_loss: 0.6411 - val_acc: 0.6281\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7133 - acc: 0.5197 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7148 - acc: 0.5197 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7130 - acc: 0.5232 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7106 - acc: 0.5203 - val_loss: 0.6410 - val_acc: 0.6281\n",
      "sample weight :  [1.84227178e-04 6.83817970e-05 5.63696533e-05 ... 5.59521629e-05\n",
      " 5.71393260e-05 5.27831886e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8700 - acc: 0.6129 - val_loss: 0.7368 - val_acc: 0.6204\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.8384 - acc: 0.6117 - val_loss: 0.7130 - val_acc: 0.6204\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8109 - acc: 0.6120 - val_loss: 0.6930 - val_acc: 0.6204\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7752 - acc: 0.6074 - val_loss: 0.6768 - val_acc: 0.6204\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7593 - acc: 0.6063 - val_loss: 0.6642 - val_acc: 0.6204\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7459 - acc: 0.5916 - val_loss: 0.6552 - val_acc: 0.6204\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7297 - acc: 0.5801 - val_loss: 0.6496 - val_acc: 0.6204\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7214 - acc: 0.5332 - val_loss: 0.6473 - val_acc: 0.6204\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7287 - acc: 0.5148 - val_loss: 0.6481 - val_acc: 0.3796\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7110 - acc: 0.4754 - val_loss: 0.6513 - val_acc: 0.3796\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7161 - acc: 0.4567 - val_loss: 0.6557 - val_acc: 0.3796\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7234 - acc: 0.4331 - val_loss: 0.6598 - val_acc: 0.3796\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7352 - acc: 0.4305 - val_loss: 0.6624 - val_acc: 0.3796\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7261 - acc: 0.4202 - val_loss: 0.6633 - val_acc: 0.3796\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7346 - acc: 0.4280 - val_loss: 0.6625 - val_acc: 0.3796\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7366 - acc: 0.4242 - val_loss: 0.6607 - val_acc: 0.3796\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7371 - acc: 0.4205 - val_loss: 0.6584 - val_acc: 0.3796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7223 - acc: 0.4432 - val_loss: 0.6559 - val_acc: 0.3796\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7299 - acc: 0.4300 - val_loss: 0.6536 - val_acc: 0.3796\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7217 - acc: 0.4377 - val_loss: 0.6516 - val_acc: 0.3796\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7291 - acc: 0.4452 - val_loss: 0.6500 - val_acc: 0.3796\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7145 - acc: 0.4590 - val_loss: 0.6489 - val_acc: 0.3796\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7133 - acc: 0.4720 - val_loss: 0.6481 - val_acc: 0.3796\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7128 - acc: 0.4674 - val_loss: 0.6476 - val_acc: 0.3796\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7169 - acc: 0.4886 - val_loss: 0.6473 - val_acc: 0.3796\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7167 - acc: 0.4858 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7120 - acc: 0.4967 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7233 - acc: 0.5165 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7172 - acc: 0.5134 - val_loss: 0.6473 - val_acc: 0.6204\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7290 - acc: 0.5033 - val_loss: 0.6474 - val_acc: 0.6204\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7130 - acc: 0.5295 - val_loss: 0.6474 - val_acc: 0.6204\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7204 - acc: 0.5252 - val_loss: 0.6474 - val_acc: 0.6204\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7171 - acc: 0.5188 - val_loss: 0.6474 - val_acc: 0.6204\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7086 - acc: 0.5283 - val_loss: 0.6474 - val_acc: 0.6204\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7183 - acc: 0.5125 - val_loss: 0.6473 - val_acc: 0.6204\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7213 - acc: 0.5160 - val_loss: 0.6473 - val_acc: 0.6204\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7167 - acc: 0.5246 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7171 - acc: 0.5154 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7165 - acc: 0.5148 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7105 - acc: 0.5122 - val_loss: 0.6472 - val_acc: 0.6204\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7125 - acc: 0.4973 - val_loss: 0.6473 - val_acc: 0.3796\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7118 - acc: 0.4918 - val_loss: 0.6473 - val_acc: 0.3796\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7197 - acc: 0.4964 - val_loss: 0.6474 - val_acc: 0.3796\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7146 - acc: 0.4817 - val_loss: 0.6476 - val_acc: 0.3796\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7163 - acc: 0.4892 - val_loss: 0.6477 - val_acc: 0.3796\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7098 - acc: 0.4734 - val_loss: 0.6478 - val_acc: 0.3796\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7136 - acc: 0.4826 - val_loss: 0.6480 - val_acc: 0.3796\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7155 - acc: 0.4725 - val_loss: 0.6481 - val_acc: 0.3796\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7137 - acc: 0.4840 - val_loss: 0.6482 - val_acc: 0.3796\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7108 - acc: 0.4794 - val_loss: 0.6483 - val_acc: 0.3796\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7183 - acc: 0.4697 - val_loss: 0.6484 - val_acc: 0.3796\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7054 - acc: 0.4786 - val_loss: 0.6484 - val_acc: 0.3796\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7124 - acc: 0.4674 - val_loss: 0.6484 - val_acc: 0.3796\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7157 - acc: 0.4731 - val_loss: 0.6484 - val_acc: 0.3796\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7214 - acc: 0.4587 - val_loss: 0.6483 - val_acc: 0.3796\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7074 - acc: 0.4806 - val_loss: 0.6482 - val_acc: 0.3796\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7162 - acc: 0.4674 - val_loss: 0.6482 - val_acc: 0.3796\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7220 - acc: 0.4665 - val_loss: 0.6481 - val_acc: 0.3796\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7150 - acc: 0.4688 - val_loss: 0.6480 - val_acc: 0.3796\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7160 - acc: 0.4783 - val_loss: 0.6479 - val_acc: 0.3796\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7167 - acc: 0.4780 - val_loss: 0.6478 - val_acc: 0.3796\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7223 - acc: 0.4748 - val_loss: 0.6478 - val_acc: 0.3796\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7129 - acc: 0.4826 - val_loss: 0.6477 - val_acc: 0.3796\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7045 - acc: 0.4930 - val_loss: 0.6476 - val_acc: 0.3796\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7229 - acc: 0.4774 - val_loss: 0.6476 - val_acc: 0.3796\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7226 - acc: 0.4794 - val_loss: 0.6476 - val_acc: 0.3796\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7160 - acc: 0.4674 - val_loss: 0.6475 - val_acc: 0.3796\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7116 - acc: 0.4907 - val_loss: 0.6475 - val_acc: 0.3796\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7117 - acc: 0.4757 - val_loss: 0.6475 - val_acc: 0.3796\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7143 - acc: 0.4757 - val_loss: 0.6475 - val_acc: 0.3796\n",
      "sample weight :  [1.80859391e-04 6.70716711e-05 5.76093608e-05 ... 5.71048038e-05\n",
      " 5.83336009e-05 5.38331113e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7067 - acc: 0.3943 - val_loss: 0.7612 - val_acc: 0.3874\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7025 - acc: 0.3969 - val_loss: 0.7537 - val_acc: 0.3874\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6877 - acc: 0.4153 - val_loss: 0.7483 - val_acc: 0.3874\n",
      "Epoch 4/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6932 - acc: 0.4320 - val_loss: 0.7447 - val_acc: 0.3874\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6829 - acc: 0.4587 - val_loss: 0.7428 - val_acc: 0.3874\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6813 - acc: 0.4768 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6831 - acc: 0.5076 - val_loss: 0.7427 - val_acc: 0.6126\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6845 - acc: 0.5237 - val_loss: 0.7435 - val_acc: 0.6126\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6920 - acc: 0.5321 - val_loss: 0.7441 - val_acc: 0.6126\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6837 - acc: 0.5542 - val_loss: 0.7444 - val_acc: 0.6126\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6875 - acc: 0.5539 - val_loss: 0.7443 - val_acc: 0.6126\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6825 - acc: 0.5447 - val_loss: 0.7439 - val_acc: 0.6126\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6774 - acc: 0.5574 - val_loss: 0.7434 - val_acc: 0.6126\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6870 - acc: 0.5404 - val_loss: 0.7429 - val_acc: 0.6126\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6846 - acc: 0.5260 - val_loss: 0.7425 - val_acc: 0.6126\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6761 - acc: 0.5349 - val_loss: 0.7423 - val_acc: 0.6126\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6856 - acc: 0.5073 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6831 - acc: 0.5042 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6806 - acc: 0.5033 - val_loss: 0.7424 - val_acc: 0.3874\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6742 - acc: 0.4935 - val_loss: 0.7426 - val_acc: 0.3874\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6829 - acc: 0.4722 - val_loss: 0.7428 - val_acc: 0.3874\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6796 - acc: 0.4780 - val_loss: 0.7430 - val_acc: 0.3874\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6831 - acc: 0.4685 - val_loss: 0.7431 - val_acc: 0.3874\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6766 - acc: 0.4763 - val_loss: 0.7432 - val_acc: 0.3874\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6851 - acc: 0.4766 - val_loss: 0.7432 - val_acc: 0.3874\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6803 - acc: 0.4613 - val_loss: 0.7432 - val_acc: 0.3874\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6827 - acc: 0.4656 - val_loss: 0.7431 - val_acc: 0.3874\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6808 - acc: 0.4740 - val_loss: 0.7430 - val_acc: 0.3874\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6813 - acc: 0.4613 - val_loss: 0.7429 - val_acc: 0.3874\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6777 - acc: 0.4780 - val_loss: 0.7428 - val_acc: 0.3874\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6826 - acc: 0.4771 - val_loss: 0.7426 - val_acc: 0.3874\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6792 - acc: 0.4823 - val_loss: 0.7425 - val_acc: 0.3874\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6773 - acc: 0.4866 - val_loss: 0.7424 - val_acc: 0.3874\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6798 - acc: 0.4780 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6842 - acc: 0.4907 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6820 - acc: 0.4886 - val_loss: 0.7422 - val_acc: 0.3874\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6763 - acc: 0.5033 - val_loss: 0.7422 - val_acc: 0.3874\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6854 - acc: 0.4843 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6790 - acc: 0.5108 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6799 - acc: 0.5016 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6768 - acc: 0.5102 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6814 - acc: 0.5079 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6840 - acc: 0.4981 - val_loss: 0.7422 - val_acc: 0.6126\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6822 - acc: 0.4935 - val_loss: 0.7422 - val_acc: 0.3874\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6793 - acc: 0.5039 - val_loss: 0.7422 - val_acc: 0.3874\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6836 - acc: 0.4944 - val_loss: 0.7422 - val_acc: 0.3874\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6757 - acc: 0.4924 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6797 - acc: 0.4846 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6788 - acc: 0.5016 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6791 - acc: 0.4838 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6761 - acc: 0.4984 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6759 - acc: 0.4797 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6818 - acc: 0.4817 - val_loss: 0.7424 - val_acc: 0.3874\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6779 - acc: 0.4886 - val_loss: 0.7424 - val_acc: 0.3874\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6846 - acc: 0.4791 - val_loss: 0.7424 - val_acc: 0.3874\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6789 - acc: 0.4751 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6784 - acc: 0.4789 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6788 - acc: 0.4797 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6809 - acc: 0.4852 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6824 - acc: 0.4797 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6809 - acc: 0.4846 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6787 - acc: 0.4823 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6795 - acc: 0.4878 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6798 - acc: 0.4855 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6814 - acc: 0.4832 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6805 - acc: 0.4722 - val_loss: 0.7423 - val_acc: 0.3874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6802 - acc: 0.4907 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6809 - acc: 0.4855 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6756 - acc: 0.4938 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6792 - acc: 0.4783 - val_loss: 0.7423 - val_acc: 0.3874\n",
      "sample weight :  [1.78583226e-04 6.62426227e-05 5.83843908e-05 ... 5.77810736e-05\n",
      " 5.90635099e-05 5.45246360e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7172 - acc: 0.3995 - val_loss: 0.7152 - val_acc: 0.3822\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7058 - acc: 0.4070 - val_loss: 0.7090 - val_acc: 0.3822\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6972 - acc: 0.4300 - val_loss: 0.7051 - val_acc: 0.3822\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7003 - acc: 0.4541 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6924 - acc: 0.4938 - val_loss: 0.7031 - val_acc: 0.6178\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6935 - acc: 0.5252 - val_loss: 0.7038 - val_acc: 0.6178\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7022 - acc: 0.5335 - val_loss: 0.7046 - val_acc: 0.6178\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7011 - acc: 0.5456 - val_loss: 0.7050 - val_acc: 0.6178\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7047 - acc: 0.5459 - val_loss: 0.7049 - val_acc: 0.6178\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7013 - acc: 0.5582 - val_loss: 0.7045 - val_acc: 0.6178\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6950 - acc: 0.5513 - val_loss: 0.7039 - val_acc: 0.6178\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6970 - acc: 0.5321 - val_loss: 0.7034 - val_acc: 0.6178\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6977 - acc: 0.5223 - val_loss: 0.7031 - val_acc: 0.6178\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6924 - acc: 0.5220 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6994 - acc: 0.5171 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6972 - acc: 0.4895 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6971 - acc: 0.4814 - val_loss: 0.7035 - val_acc: 0.3822\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7020 - acc: 0.4590 - val_loss: 0.7037 - val_acc: 0.3822\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6936 - acc: 0.4797 - val_loss: 0.7040 - val_acc: 0.3822\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6934 - acc: 0.4699 - val_loss: 0.7041 - val_acc: 0.3822\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6929 - acc: 0.4642 - val_loss: 0.7041 - val_acc: 0.3822\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6959 - acc: 0.4628 - val_loss: 0.7041 - val_acc: 0.3822\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6966 - acc: 0.4599 - val_loss: 0.7040 - val_acc: 0.3822\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6930 - acc: 0.4676 - val_loss: 0.7038 - val_acc: 0.3822\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6929 - acc: 0.4688 - val_loss: 0.7037 - val_acc: 0.3822\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6913 - acc: 0.4751 - val_loss: 0.7035 - val_acc: 0.3822\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6948 - acc: 0.4791 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6985 - acc: 0.4636 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6940 - acc: 0.4760 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6964 - acc: 0.4820 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6899 - acc: 0.4999 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6977 - acc: 0.4892 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6902 - acc: 0.5168 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6945 - acc: 0.4950 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6926 - acc: 0.5024 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6917 - acc: 0.5010 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6893 - acc: 0.5249 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6894 - acc: 0.5056 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6937 - acc: 0.4993 - val_loss: 0.7030 - val_acc: 0.6178\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6992 - acc: 0.4990 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6931 - acc: 0.5050 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6906 - acc: 0.5010 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6860 - acc: 0.4947 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6899 - acc: 0.4976 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6929 - acc: 0.4973 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6900 - acc: 0.4766 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6938 - acc: 0.4932 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6908 - acc: 0.4961 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6964 - acc: 0.4722 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6965 - acc: 0.4832 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6951 - acc: 0.4691 - val_loss: 0.7033 - val_acc: 0.3822\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6962 - acc: 0.4766 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 53/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6941 - acc: 0.4881 - val_loss: 0.7032 - val_acc: 0.3822\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6935 - acc: 0.4829 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6973 - acc: 0.4889 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6932 - acc: 0.4771 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6933 - acc: 0.4921 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6898 - acc: 0.4838 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6887 - acc: 0.4996 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6938 - acc: 0.4909 - val_loss: 0.7030 - val_acc: 0.3917\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6882 - acc: 0.5062 - val_loss: 0.7030 - val_acc: 0.4556\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6901 - acc: 0.5004 - val_loss: 0.7030 - val_acc: 0.5039\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6899 - acc: 0.5085 - val_loss: 0.7030 - val_acc: 0.4616\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6955 - acc: 0.4932 - val_loss: 0.7030 - val_acc: 0.4029\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6927 - acc: 0.4889 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6942 - acc: 0.4907 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6890 - acc: 0.5030 - val_loss: 0.7030 - val_acc: 0.3822\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6942 - acc: 0.4918 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6941 - acc: 0.4780 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6913 - acc: 0.4783 - val_loss: 0.7031 - val_acc: 0.3822\n",
      "sample weight :  [1.75848097e-04 6.52522149e-05 5.94214907e-05 ... 5.86625482e-05\n",
      " 6.00462873e-05 5.53732234e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6736 - acc: 0.5036 - val_loss: 0.7626 - val_acc: 0.3840\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6776 - acc: 0.4780 - val_loss: 0.7635 - val_acc: 0.3840\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6833 - acc: 0.4754 - val_loss: 0.7617 - val_acc: 0.3840\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6774 - acc: 0.4904 - val_loss: 0.7595 - val_acc: 0.6160\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6776 - acc: 0.4984 - val_loss: 0.7581 - val_acc: 0.6160\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6865 - acc: 0.5093 - val_loss: 0.7579 - val_acc: 0.6160\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6760 - acc: 0.5203 - val_loss: 0.7587 - val_acc: 0.6160\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6799 - acc: 0.5099 - val_loss: 0.7598 - val_acc: 0.3840\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6764 - acc: 0.5004 - val_loss: 0.7608 - val_acc: 0.3840\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6792 - acc: 0.4912 - val_loss: 0.7619 - val_acc: 0.3840\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6790 - acc: 0.4849 - val_loss: 0.7627 - val_acc: 0.3840\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6762 - acc: 0.4927 - val_loss: 0.7627 - val_acc: 0.3840\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6744 - acc: 0.4849 - val_loss: 0.7623 - val_acc: 0.3840\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6759 - acc: 0.4886 - val_loss: 0.7619 - val_acc: 0.3840\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6745 - acc: 0.4918 - val_loss: 0.7613 - val_acc: 0.3840\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6717 - acc: 0.4889 - val_loss: 0.7606 - val_acc: 0.3840\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6725 - acc: 0.4780 - val_loss: 0.7598 - val_acc: 0.3840\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6750 - acc: 0.5145 - val_loss: 0.7591 - val_acc: 0.6160\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6694 - acc: 0.5214 - val_loss: 0.7588 - val_acc: 0.6160\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6748 - acc: 0.5019 - val_loss: 0.7588 - val_acc: 0.6160\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6773 - acc: 0.5076 - val_loss: 0.7588 - val_acc: 0.6160\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6793 - acc: 0.5145 - val_loss: 0.7590 - val_acc: 0.6160\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6769 - acc: 0.4967 - val_loss: 0.7594 - val_acc: 0.6160\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6771 - acc: 0.4921 - val_loss: 0.7601 - val_acc: 0.3840\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6784 - acc: 0.4918 - val_loss: 0.7608 - val_acc: 0.3840\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6748 - acc: 0.5022 - val_loss: 0.7612 - val_acc: 0.3840\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6737 - acc: 0.4978 - val_loss: 0.7614 - val_acc: 0.3840\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6746 - acc: 0.4858 - val_loss: 0.7615 - val_acc: 0.3840\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6757 - acc: 0.4852 - val_loss: 0.7614 - val_acc: 0.3840\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6726 - acc: 0.4861 - val_loss: 0.7611 - val_acc: 0.3840\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6733 - acc: 0.4892 - val_loss: 0.7608 - val_acc: 0.3840\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6746 - acc: 0.4915 - val_loss: 0.7605 - val_acc: 0.3840\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6701 - acc: 0.4955 - val_loss: 0.7601 - val_acc: 0.3840\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6779 - acc: 0.4829 - val_loss: 0.7598 - val_acc: 0.3840\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6735 - acc: 0.4981 - val_loss: 0.7595 - val_acc: 0.6160\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6719 - acc: 0.5134 - val_loss: 0.7593 - val_acc: 0.6160\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6728 - acc: 0.4976 - val_loss: 0.7594 - val_acc: 0.6160\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6712 - acc: 0.5111 - val_loss: 0.7595 - val_acc: 0.6160\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6761 - acc: 0.4953 - val_loss: 0.7597 - val_acc: 0.3840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6759 - acc: 0.4967 - val_loss: 0.7599 - val_acc: 0.3840\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6724 - acc: 0.4987 - val_loss: 0.7602 - val_acc: 0.3840\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6723 - acc: 0.5007 - val_loss: 0.7606 - val_acc: 0.3840\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6735 - acc: 0.4958 - val_loss: 0.7609 - val_acc: 0.3840\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6720 - acc: 0.5007 - val_loss: 0.7611 - val_acc: 0.3840\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6739 - acc: 0.4771 - val_loss: 0.7614 - val_acc: 0.3840\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6747 - acc: 0.4930 - val_loss: 0.7614 - val_acc: 0.3840\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6729 - acc: 0.4771 - val_loss: 0.7613 - val_acc: 0.3840\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6696 - acc: 0.4817 - val_loss: 0.7611 - val_acc: 0.3840\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6714 - acc: 0.4858 - val_loss: 0.7608 - val_acc: 0.3840\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6730 - acc: 0.4892 - val_loss: 0.7603 - val_acc: 0.3840\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6730 - acc: 0.4757 - val_loss: 0.7599 - val_acc: 0.3840\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6721 - acc: 0.4832 - val_loss: 0.7597 - val_acc: 0.4504\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6725 - acc: 0.4978 - val_loss: 0.7595 - val_acc: 0.6178\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6715 - acc: 0.5039 - val_loss: 0.7595 - val_acc: 0.6160\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6714 - acc: 0.4927 - val_loss: 0.7595 - val_acc: 0.6186\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6703 - acc: 0.5111 - val_loss: 0.7597 - val_acc: 0.3848\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6718 - acc: 0.5142 - val_loss: 0.7600 - val_acc: 0.3840\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6741 - acc: 0.4875 - val_loss: 0.7603 - val_acc: 0.3840\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6753 - acc: 0.4838 - val_loss: 0.7607 - val_acc: 0.3840\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6749 - acc: 0.4835 - val_loss: 0.7611 - val_acc: 0.3840\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6691 - acc: 0.4786 - val_loss: 0.7614 - val_acc: 0.3840\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6724 - acc: 0.4855 - val_loss: 0.7615 - val_acc: 0.3840\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6712 - acc: 0.4748 - val_loss: 0.7616 - val_acc: 0.3840\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6724 - acc: 0.4510 - val_loss: 0.7615 - val_acc: 0.3840\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6719 - acc: 0.4768 - val_loss: 0.7613 - val_acc: 0.3840\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6753 - acc: 0.4791 - val_loss: 0.7611 - val_acc: 0.3840\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6747 - acc: 0.4881 - val_loss: 0.7608 - val_acc: 0.3840\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6720 - acc: 0.4938 - val_loss: 0.7604 - val_acc: 0.3840\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6708 - acc: 0.4869 - val_loss: 0.7602 - val_acc: 0.3840\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6720 - acc: 0.4817 - val_loss: 0.7600 - val_acc: 0.3840\n",
      "sample weight :  [1.75449554e-04 6.50488320e-05 5.97025183e-05 ... 5.88317915e-05\n",
      " 6.02280819e-05 5.55325797e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7969 - acc: 0.3842 - val_loss: 0.7176 - val_acc: 0.3917\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7774 - acc: 0.3863 - val_loss: 0.7006 - val_acc: 0.3917\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7591 - acc: 0.3871 - val_loss: 0.6860 - val_acc: 0.3917\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7343 - acc: 0.3932 - val_loss: 0.6740 - val_acc: 0.3917\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7255 - acc: 0.4107 - val_loss: 0.6647 - val_acc: 0.3917\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7215 - acc: 0.4239 - val_loss: 0.6582 - val_acc: 0.3917\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7209 - acc: 0.4668 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7087 - acc: 0.5157 - val_loss: 0.6535 - val_acc: 0.6083\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7075 - acc: 0.5496 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7154 - acc: 0.5818 - val_loss: 0.6561 - val_acc: 0.6083\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7219 - acc: 0.5815 - val_loss: 0.6573 - val_acc: 0.6083\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7225 - acc: 0.5902 - val_loss: 0.6575 - val_acc: 0.6083\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7246 - acc: 0.5758 - val_loss: 0.6570 - val_acc: 0.6083\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7184 - acc: 0.5818 - val_loss: 0.6560 - val_acc: 0.6083\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7191 - acc: 0.5787 - val_loss: 0.6550 - val_acc: 0.6083\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7170 - acc: 0.5723 - val_loss: 0.6541 - val_acc: 0.6083\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7197 - acc: 0.5614 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7183 - acc: 0.5528 - val_loss: 0.6535 - val_acc: 0.6083\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7047 - acc: 0.5410 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7110 - acc: 0.5370 - val_loss: 0.6540 - val_acc: 0.6083\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7097 - acc: 0.5200 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7074 - acc: 0.5047 - val_loss: 0.6550 - val_acc: 0.3917\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7082 - acc: 0.5076 - val_loss: 0.6556 - val_acc: 0.3917\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7143 - acc: 0.4932 - val_loss: 0.6561 - val_acc: 0.3917\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7143 - acc: 0.4912 - val_loss: 0.6565 - val_acc: 0.3917\n",
      "Epoch 26/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7118 - acc: 0.4820 - val_loss: 0.6568 - val_acc: 0.3917\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7120 - acc: 0.4846 - val_loss: 0.6570 - val_acc: 0.3917\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7127 - acc: 0.4803 - val_loss: 0.6570 - val_acc: 0.3917\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7115 - acc: 0.4840 - val_loss: 0.6570 - val_acc: 0.3917\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7110 - acc: 0.4628 - val_loss: 0.6567 - val_acc: 0.3917\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7152 - acc: 0.4697 - val_loss: 0.6564 - val_acc: 0.3917\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7082 - acc: 0.4970 - val_loss: 0.6561 - val_acc: 0.3917\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7155 - acc: 0.4789 - val_loss: 0.6557 - val_acc: 0.3917\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7065 - acc: 0.4812 - val_loss: 0.6554 - val_acc: 0.3917\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7137 - acc: 0.4909 - val_loss: 0.6550 - val_acc: 0.3917\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7140 - acc: 0.5007 - val_loss: 0.6547 - val_acc: 0.6083\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7126 - acc: 0.5059 - val_loss: 0.6544 - val_acc: 0.6083\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7078 - acc: 0.5134 - val_loss: 0.6542 - val_acc: 0.6083\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7111 - acc: 0.5232 - val_loss: 0.6540 - val_acc: 0.6083\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7075 - acc: 0.5197 - val_loss: 0.6538 - val_acc: 0.6083\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7151 - acc: 0.5232 - val_loss: 0.6537 - val_acc: 0.6083\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7155 - acc: 0.5160 - val_loss: 0.6537 - val_acc: 0.6083\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7072 - acc: 0.5424 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7108 - acc: 0.5519 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7081 - acc: 0.5470 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7132 - acc: 0.5329 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7091 - acc: 0.5332 - val_loss: 0.6536 - val_acc: 0.6083\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7086 - acc: 0.5387 - val_loss: 0.6537 - val_acc: 0.6083\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7123 - acc: 0.5278 - val_loss: 0.6537 - val_acc: 0.6083\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7101 - acc: 0.5234 - val_loss: 0.6537 - val_acc: 0.6083\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7080 - acc: 0.5436 - val_loss: 0.6538 - val_acc: 0.6083\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7159 - acc: 0.5183 - val_loss: 0.6538 - val_acc: 0.6083\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7148 - acc: 0.5174 - val_loss: 0.6539 - val_acc: 0.6083\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7155 - acc: 0.5056 - val_loss: 0.6540 - val_acc: 0.6083\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7074 - acc: 0.5278 - val_loss: 0.6540 - val_acc: 0.6083\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7100 - acc: 0.5154 - val_loss: 0.6541 - val_acc: 0.6083\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7075 - acc: 0.5131 - val_loss: 0.6542 - val_acc: 0.6083\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7136 - acc: 0.5315 - val_loss: 0.6543 - val_acc: 0.6083\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7063 - acc: 0.5246 - val_loss: 0.6543 - val_acc: 0.6083\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7080 - acc: 0.5174 - val_loss: 0.6544 - val_acc: 0.6083\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7088 - acc: 0.5180 - val_loss: 0.6544 - val_acc: 0.6083\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7109 - acc: 0.5200 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7165 - acc: 0.4967 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7051 - acc: 0.5033 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7040 - acc: 0.5200 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7074 - acc: 0.5197 - val_loss: 0.6545 - val_acc: 0.6083\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7170 - acc: 0.5050 - val_loss: 0.6544 - val_acc: 0.6083\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7104 - acc: 0.5085 - val_loss: 0.6544 - val_acc: 0.6083\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7130 - acc: 0.5134 - val_loss: 0.6543 - val_acc: 0.6083\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7107 - acc: 0.5209 - val_loss: 0.6543 - val_acc: 0.6083\n",
      "sample weight :  [1.78446500e-04 6.62975006e-05 5.86161857e-05 ... 5.78872447e-05\n",
      " 5.94744096e-05 5.45920356e-05]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_1436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/70\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7292 - acc: 0.6091 - val_loss: 0.6946 - val_acc: 0.6083\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7214 - acc: 0.5976 - val_loss: 0.6908 - val_acc: 0.6083\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7121 - acc: 0.5882 - val_loss: 0.6887 - val_acc: 0.6083\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7100 - acc: 0.5697 - val_loss: 0.6884 - val_acc: 0.6083\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7058 - acc: 0.5453 - val_loss: 0.6899 - val_acc: 0.6083\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7023 - acc: 0.5148 - val_loss: 0.6927 - val_acc: 0.3917\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7066 - acc: 0.4803 - val_loss: 0.6961 - val_acc: 0.3917\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6975 - acc: 0.4490 - val_loss: 0.6994 - val_acc: 0.3917\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7008 - acc: 0.4607 - val_loss: 0.7019 - val_acc: 0.3917\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6998 - acc: 0.4216 - val_loss: 0.7029 - val_acc: 0.3917\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7012 - acc: 0.4282 - val_loss: 0.7027 - val_acc: 0.3917\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7038 - acc: 0.4288 - val_loss: 0.7016 - val_acc: 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7038 - acc: 0.4245 - val_loss: 0.7000 - val_acc: 0.3917\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7014 - acc: 0.4357 - val_loss: 0.6982 - val_acc: 0.3917\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6966 - acc: 0.4513 - val_loss: 0.6964 - val_acc: 0.3917\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6957 - acc: 0.4533 - val_loss: 0.6949 - val_acc: 0.3917\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7007 - acc: 0.4478 - val_loss: 0.6935 - val_acc: 0.3917\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7013 - acc: 0.4665 - val_loss: 0.6924 - val_acc: 0.3917\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6929 - acc: 0.4705 - val_loss: 0.6915 - val_acc: 0.3917\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6942 - acc: 0.4878 - val_loss: 0.6909 - val_acc: 0.3917\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6983 - acc: 0.5076 - val_loss: 0.6904 - val_acc: 0.6083\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7006 - acc: 0.4938 - val_loss: 0.6900 - val_acc: 0.6083\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6973 - acc: 0.5125 - val_loss: 0.6898 - val_acc: 0.6083\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7001 - acc: 0.5013 - val_loss: 0.6897 - val_acc: 0.6083\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6994 - acc: 0.5206 - val_loss: 0.6896 - val_acc: 0.6083\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6952 - acc: 0.5240 - val_loss: 0.6897 - val_acc: 0.6083\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6944 - acc: 0.5062 - val_loss: 0.6897 - val_acc: 0.6083\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7006 - acc: 0.5079 - val_loss: 0.6899 - val_acc: 0.6083\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6965 - acc: 0.5004 - val_loss: 0.6901 - val_acc: 0.6083\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7027 - acc: 0.5082 - val_loss: 0.6903 - val_acc: 0.6083\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6988 - acc: 0.4927 - val_loss: 0.6906 - val_acc: 0.6083\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7036 - acc: 0.4878 - val_loss: 0.6909 - val_acc: 0.3917\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6906 - acc: 0.5047 - val_loss: 0.6913 - val_acc: 0.3917\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7050 - acc: 0.4861 - val_loss: 0.6917 - val_acc: 0.3917\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6956 - acc: 0.4852 - val_loss: 0.6921 - val_acc: 0.3917\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6997 - acc: 0.4743 - val_loss: 0.6925 - val_acc: 0.3917\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7048 - acc: 0.4656 - val_loss: 0.6928 - val_acc: 0.3917\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6984 - acc: 0.4605 - val_loss: 0.6932 - val_acc: 0.3917\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6994 - acc: 0.4561 - val_loss: 0.6934 - val_acc: 0.3917\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6998 - acc: 0.4628 - val_loss: 0.6936 - val_acc: 0.3917\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6934 - acc: 0.4757 - val_loss: 0.6937 - val_acc: 0.3917\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6940 - acc: 0.4633 - val_loss: 0.6936 - val_acc: 0.3917\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6961 - acc: 0.4751 - val_loss: 0.6935 - val_acc: 0.3917\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6945 - acc: 0.4633 - val_loss: 0.6933 - val_acc: 0.3917\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6955 - acc: 0.4679 - val_loss: 0.6931 - val_acc: 0.3917\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6966 - acc: 0.4625 - val_loss: 0.6929 - val_acc: 0.3917\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6977 - acc: 0.4642 - val_loss: 0.6926 - val_acc: 0.3917\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6949 - acc: 0.4832 - val_loss: 0.6923 - val_acc: 0.3917\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6947 - acc: 0.4835 - val_loss: 0.6921 - val_acc: 0.3917\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6943 - acc: 0.4809 - val_loss: 0.6919 - val_acc: 0.3917\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6953 - acc: 0.4861 - val_loss: 0.6917 - val_acc: 0.3917\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6926 - acc: 0.4849 - val_loss: 0.6916 - val_acc: 0.3917\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6954 - acc: 0.4861 - val_loss: 0.6914 - val_acc: 0.3917\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6926 - acc: 0.4927 - val_loss: 0.6914 - val_acc: 0.3917\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6949 - acc: 0.5007 - val_loss: 0.6914 - val_acc: 0.3917\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6969 - acc: 0.4924 - val_loss: 0.6914 - val_acc: 0.3917\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6935 - acc: 0.4973 - val_loss: 0.6915 - val_acc: 0.3917\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6954 - acc: 0.4990 - val_loss: 0.6916 - val_acc: 0.3917\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6985 - acc: 0.4814 - val_loss: 0.6917 - val_acc: 0.3917\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6961 - acc: 0.4872 - val_loss: 0.6918 - val_acc: 0.3917\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6950 - acc: 0.4814 - val_loss: 0.6920 - val_acc: 0.3917\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6980 - acc: 0.4760 - val_loss: 0.6922 - val_acc: 0.3917\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6985 - acc: 0.4768 - val_loss: 0.6923 - val_acc: 0.3917\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6941 - acc: 0.4688 - val_loss: 0.6925 - val_acc: 0.3917\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6981 - acc: 0.4642 - val_loss: 0.6927 - val_acc: 0.3917\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6986 - acc: 0.4748 - val_loss: 0.6928 - val_acc: 0.3917\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6946 - acc: 0.4671 - val_loss: 0.6928 - val_acc: 0.3917\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6927 - acc: 0.4699 - val_loss: 0.6929 - val_acc: 0.3917\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6970 - acc: 0.4541 - val_loss: 0.6929 - val_acc: 0.3917\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6971 - acc: 0.4538 - val_loss: 0.6929 - val_acc: 0.3917\n",
      "Adaboost accuracy : 0.7605177993527508, precision : 0.791231732776618, recall : 0.8168103448275862, f1 : 0.8038176033934252, roc_auc : 0.7463306181188174\n",
      "CPU times: user 41min 24s, sys: 4h 32min 51s, total: 5h 14min 15s\n",
      "Wall time: 21min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1, restore_best_weights=True)\n",
    "#     cb_checkpoint = ModelCheckpoint(filepath='./models/adaboost_lstm.h5', monitor='val_acc',\n",
    "#                                     verbose=1, save_best_only=True)\n",
    "    base_estimator = MyKerasClassifier(build_fn=get_model, epochs=300, batch_size=10000,\n",
    "                                       validation_split=0.25, callbacks=[early_stop])\n",
    "#     base_estimator = MyKerasClassifier(build_fn=get_model, epochs=50, batch_size=128, validation_split=0.25)\n",
    "\n",
    "    boosted_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=60, random_state=42, learning_rate=1.2)\n",
    "    \n",
    "    print(\"Adaboost LSTM Start\")\n",
    "    boosted_classifier.fit(X_train, y_train)\n",
    "    preds = boosted_classifier.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f'Adaboost accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.2707135 , 0.7292865 ],\n",
       "        [0.07444376, 0.92555624],\n",
       "        [0.04450702, 0.955493  ],\n",
       "        ...,\n",
       "        [0.0898302 , 0.9101698 ],\n",
       "        [0.11763357, 0.8823664 ],\n",
       "        [0.23773056, 0.76226944]], dtype=float32),\n",
       " array([[0.40409738, 0.5959026 ],\n",
       "        [0.24302235, 0.7569776 ],\n",
       "        [0.19565073, 0.80434924],\n",
       "        ...,\n",
       "        [0.26112202, 0.73887795],\n",
       "        [0.29030725, 0.7096927 ],\n",
       "        [0.3814843 , 0.6185157 ]], dtype=float32),\n",
       " array([[0.4275194 , 0.5724806 ],\n",
       "        [0.31221482, 0.6877852 ],\n",
       "        [0.27394864, 0.72605133],\n",
       "        ...,\n",
       "        [0.32597783, 0.6740222 ],\n",
       "        [0.34771815, 0.6522818 ],\n",
       "        [0.4120743 , 0.5879257 ]], dtype=float32),\n",
       " array([[0.44819024, 0.5518098 ],\n",
       "        [0.35904843, 0.64095163],\n",
       "        [0.32766244, 0.6723376 ],\n",
       "        ...,\n",
       "        [0.36968783, 0.6303122 ],\n",
       "        [0.386842  , 0.613158  ],\n",
       "        [0.4362423 , 0.56375766]], dtype=float32),\n",
       " array([[0.45480263, 0.54519737],\n",
       "        [0.3826213 , 0.6173788 ],\n",
       "        [0.35666934, 0.6433307 ],\n",
       "        ...,\n",
       "        [0.3913297 , 0.6086703 ],\n",
       "        [0.4053086 , 0.5946914 ],\n",
       "        [0.4451933 , 0.55480677]], dtype=float32),\n",
       " array([[0.4644036 , 0.5355964 ],\n",
       "        [0.40365812, 0.5963419 ],\n",
       "        [0.3815246 , 0.6184754 ],\n",
       "        ...,\n",
       "        [0.41104507, 0.58895487],\n",
       "        [0.4228616 , 0.5771384 ],\n",
       "        [0.45636874, 0.5436312 ]], dtype=float32),\n",
       " array([[0.46838757, 0.5316124 ],\n",
       "        [0.41608614, 0.58391386],\n",
       "        [0.3968882 , 0.60311174],\n",
       "        ...,\n",
       "        [0.4224691 , 0.5775309 ],\n",
       "        [0.43266946, 0.56733054],\n",
       "        [0.4614913 , 0.53850865]], dtype=float32),\n",
       " array([[0.47129667, 0.52870333],\n",
       "        [0.42544317, 0.5745568 ],\n",
       "        [0.40850702, 0.591493  ],\n",
       "        ...,\n",
       "        [0.43100914, 0.5689908 ],\n",
       "        [0.44000477, 0.55999523],\n",
       "        [0.4652416 , 0.5347584 ]], dtype=float32),\n",
       " array([[0.4764173 , 0.52358276],\n",
       "        [0.43645516, 0.5635448 ],\n",
       "        [0.42111388, 0.5788861 ],\n",
       "        ...,\n",
       "        [0.4409075 , 0.55909246],\n",
       "        [0.44869924, 0.55130076],\n",
       "        [0.47079974, 0.5292003 ]], dtype=float32),\n",
       " array([[0.47837898, 0.521621  ],\n",
       "        [0.44236884, 0.5576312 ],\n",
       "        [0.42850366, 0.5714963 ],\n",
       "        ...,\n",
       "        [0.44638044, 0.55361956],\n",
       "        [0.45340687, 0.5465932 ],\n",
       "        [0.4733159 , 0.5266841 ]], dtype=float32),\n",
       " array([[0.48069483, 0.5193052 ],\n",
       "        [0.44302705, 0.5569729 ],\n",
       "        [0.43246025, 0.5675397 ],\n",
       "        ...,\n",
       "        [0.45838726, 0.54161274],\n",
       "        [0.45388782, 0.54611224],\n",
       "        [0.47193423, 0.5280658 ]], dtype=float32),\n",
       " array([[0.484773  , 0.51522696],\n",
       "        [0.45026723, 0.5497328 ],\n",
       "        [0.44059384, 0.5594061 ],\n",
       "        ...,\n",
       "        [0.4643508 , 0.5356492 ],\n",
       "        [0.46012706, 0.53987294],\n",
       "        [0.476658  , 0.523342  ]], dtype=float32),\n",
       " array([[0.48627615, 0.51372385],\n",
       "        [0.45315224, 0.5468477 ],\n",
       "        [0.4461089 , 0.5538911 ],\n",
       "        ...,\n",
       "        [0.4677741 , 0.53222597],\n",
       "        [0.4614619 , 0.5385381 ],\n",
       "        [0.47764054, 0.52235943]], dtype=float32),\n",
       " array([[0.4878522 , 0.51214784],\n",
       "        [0.45707172, 0.5429283 ],\n",
       "        [0.45052412, 0.54947585],\n",
       "        ...,\n",
       "        [0.47066596, 0.52933407],\n",
       "        [0.464798  , 0.535202  ],\n",
       "        [0.47983158, 0.5201685 ]], dtype=float32),\n",
       " array([[0.48641735, 0.51358265],\n",
       "        [0.4576951 , 0.5423049 ],\n",
       "        [0.45157883, 0.54842114],\n",
       "        ...,\n",
       "        [0.47038084, 0.52961916],\n",
       "        [0.4649033 , 0.5350967 ],\n",
       "        [0.47893274, 0.52106726]], dtype=float32),\n",
       " array([[0.4876996 , 0.51230043],\n",
       "        [0.4608232 , 0.5391768 ],\n",
       "        [0.4550325 , 0.5449675 ],\n",
       "        ...,\n",
       "        [0.47267562, 0.5273244 ],\n",
       "        [0.46753734, 0.53246266],\n",
       "        [0.4806692 , 0.5193308 ]], dtype=float32),\n",
       " array([[0.490852  , 0.50914806],\n",
       "        [0.4655424 , 0.53445756],\n",
       "        [0.46008423, 0.5399158 ],\n",
       "        ...,\n",
       "        [0.4767041 , 0.5232959 ],\n",
       "        [0.47186258, 0.5281374 ],\n",
       "        [0.48423162, 0.5157684 ]], dtype=float32),\n",
       " array([[0.48817357, 0.51182646],\n",
       "        [0.4642777 , 0.5357223 ],\n",
       "        [0.45912573, 0.54087424],\n",
       "        ...,\n",
       "        [0.474815  , 0.525185  ],\n",
       "        [0.47024474, 0.5297553 ],\n",
       "        [0.4819201 , 0.51807994]], dtype=float32),\n",
       " array([[0.49263623, 0.5073638 ],\n",
       "        [0.46997526, 0.5300247 ],\n",
       "        [0.46508774, 0.5349123 ],\n",
       "        ...,\n",
       "        [0.47997284, 0.52002716],\n",
       "        [0.47563776, 0.5243622 ],\n",
       "        [0.48670876, 0.51329124]], dtype=float32),\n",
       " array([[0.49058497, 0.509415  ],\n",
       "        [0.46906593, 0.5309341 ],\n",
       "        [0.46442184, 0.53557813],\n",
       "        ...,\n",
       "        [0.4785591 , 0.52144086],\n",
       "        [0.47444052, 0.5255595 ],\n",
       "        [0.48495537, 0.5150446 ]], dtype=float32),\n",
       " array([[0.49084464, 0.50915533],\n",
       "        [0.470349  , 0.529651  ],\n",
       "        [0.46592492, 0.53407514],\n",
       "        ...,\n",
       "        [0.47938937, 0.52061063],\n",
       "        [0.47546712, 0.5245329 ],\n",
       "        [0.48548114, 0.51451886]], dtype=float32),\n",
       " array([[0.491688  , 0.508312  ],\n",
       "        [0.47209823, 0.52790177],\n",
       "        [0.46798125, 0.5320188 ],\n",
       "        ...,\n",
       "        [0.48076707, 0.5192329 ],\n",
       "        [0.47698578, 0.52301425],\n",
       "        [0.48654604, 0.5134539 ]], dtype=float32),\n",
       " array([[0.4918458 , 0.5081542 ],\n",
       "        [0.47311172, 0.52688825],\n",
       "        [0.46917176, 0.53082824],\n",
       "        ...,\n",
       "        [0.48140088, 0.51859915],\n",
       "        [0.47778454, 0.5222155 ],\n",
       "        [0.48692417, 0.5130758 ]], dtype=float32),\n",
       " array([[0.49043337, 0.5095666 ],\n",
       "        [0.47248277, 0.52751726],\n",
       "        [0.46870935, 0.53129065],\n",
       "        ...,\n",
       "        [0.48042598, 0.51957405],\n",
       "        [0.47696105, 0.5230389 ],\n",
       "        [0.48571867, 0.5142814 ]], dtype=float32),\n",
       " array([[0.49204218, 0.5079579 ],\n",
       "        [0.47480378, 0.52519625],\n",
       "        [0.47118008, 0.5288199 ],\n",
       "        ...,\n",
       "        [0.48243418, 0.51756585],\n",
       "        [0.47910598, 0.520894  ],\n",
       "        [0.48751584, 0.51248413]], dtype=float32),\n",
       " array([[0.49310878, 0.5068912 ],\n",
       "        [0.47653112, 0.52346885],\n",
       "        [0.47304618, 0.5269539 ],\n",
       "        ...,\n",
       "        [0.48386884, 0.51613116],\n",
       "        [0.480669  , 0.51933104],\n",
       "        [0.48875442, 0.51124555]], dtype=float32),\n",
       " array([[0.4930328 , 0.5069671 ],\n",
       "        [0.4770697 , 0.52293026],\n",
       "        [0.47371307, 0.52628696],\n",
       "        ...,\n",
       "        [0.48413455, 0.5158654 ],\n",
       "        [0.48105347, 0.5189465 ],\n",
       "        [0.48883903, 0.5111609 ]], dtype=float32),\n",
       " array([[0.49334973, 0.5066503 ],\n",
       "        [0.47795582, 0.5220442 ],\n",
       "        [0.47471884, 0.5252812 ],\n",
       "        ...,\n",
       "        [0.4847687 , 0.5152313 ],\n",
       "        [0.48179665, 0.5182033 ],\n",
       "        [0.48930517, 0.51069486]], dtype=float32),\n",
       " array([[0.4922118 , 0.50778824],\n",
       "        [0.4773485 , 0.52265143],\n",
       "        [0.47422302, 0.525777  ],\n",
       "        ...,\n",
       "        [0.4839272 , 0.5160728 ],\n",
       "        [0.48105675, 0.51894325],\n",
       "        [0.4883055 , 0.5116945 ]], dtype=float32),\n",
       " array([[0.4944748 , 0.50552523],\n",
       "        [0.48010316, 0.5198968 ],\n",
       "        [0.4770808 , 0.5229192 ],\n",
       "        ...,\n",
       "        [0.48646408, 0.5135359 ],\n",
       "        [0.4836883 , 0.5163117 ],\n",
       "        [0.49069846, 0.50930154]], dtype=float32),\n",
       " array([[0.49267057, 0.50732946],\n",
       "        [0.47876632, 0.5212337 ],\n",
       "        [0.47583967, 0.5241603 ],\n",
       "        ...,\n",
       "        [0.48492044, 0.51507956],\n",
       "        [0.48223394, 0.517766  ],\n",
       "        [0.4890169 , 0.5109831 ]], dtype=float32),\n",
       " array([[0.49463642, 0.5053636 ],\n",
       "        [0.48119238, 0.5188076 ],\n",
       "        [0.47835416, 0.52164584],\n",
       "        ...,\n",
       "        [0.48712635, 0.51287365],\n",
       "        [0.48454115, 0.5154588 ],\n",
       "        [0.4910892 , 0.50891083]], dtype=float32),\n",
       " array([[0.49344903, 0.5065509 ],\n",
       "        [0.4804127 , 0.5195873 ],\n",
       "        [0.47766247, 0.52233756],\n",
       "        ...,\n",
       "        [0.48616788, 0.51383215],\n",
       "        [0.4836604 , 0.5163396 ],\n",
       "        [0.4900085 , 0.5099915 ]], dtype=float32),\n",
       " array([[0.4949855 , 0.5050145 ],\n",
       "        [0.4823304 , 0.5176696 ],\n",
       "        [0.47966146, 0.5203386 ],\n",
       "        ...,\n",
       "        [0.4879178 , 0.5120822 ],\n",
       "        [0.48548347, 0.5145165 ],\n",
       "        [0.4916457 , 0.5083543 ]], dtype=float32),\n",
       " array([[0.4945182 , 0.5054818 ],\n",
       "        [0.48222688, 0.5177731 ],\n",
       "        [0.47963357, 0.52036643],\n",
       "        ...,\n",
       "        [0.4876542 , 0.5123458 ],\n",
       "        [0.48528835, 0.5147117 ],\n",
       "        [0.49127367, 0.5087263 ]], dtype=float32),\n",
       " array([[0.4941929 , 0.5058071 ],\n",
       "        [0.4822436 , 0.5177564 ],\n",
       "        [0.47972378, 0.5202762 ],\n",
       "        ...,\n",
       "        [0.48751947, 0.5124805 ],\n",
       "        [0.48521957, 0.5147804 ],\n",
       "        [0.49103802, 0.508962  ]], dtype=float32),\n",
       " array([[0.49480346, 0.5051965 ],\n",
       "        [0.48332453, 0.5166755 ],\n",
       "        [0.48082533, 0.51917464],\n",
       "        ...,\n",
       "        [0.48835835, 0.5116417 ],\n",
       "        [0.4861793 , 0.5138207 ],\n",
       "        [0.49170706, 0.5082929 ]], dtype=float32),\n",
       " array([[0.49418178, 0.5058182 ],\n",
       "        [0.48300558, 0.5169944 ],\n",
       "        [0.4805724 , 0.5194276 ],\n",
       "        ...,\n",
       "        [0.4879059 , 0.51209414],\n",
       "        [0.48578525, 0.51421475],\n",
       "        [0.49116585, 0.5088342 ]], dtype=float32),\n",
       " array([[0.4958883 , 0.5041117 ],\n",
       "        [0.48499873, 0.51500124],\n",
       "        [0.48262745, 0.51737255],\n",
       "        ...,\n",
       "        [0.48977274, 0.51022726],\n",
       "        [0.48770785, 0.51229215],\n",
       "        [0.49294955, 0.50705045]], dtype=float32),\n",
       " array([[0.49524513, 0.50475484],\n",
       "        [0.48462868, 0.5153714 ],\n",
       "        [0.48231557, 0.5176844 ],\n",
       "        ...,\n",
       "        [0.4892827 , 0.51071733],\n",
       "        [0.48726857, 0.51273143],\n",
       "        [0.49237978, 0.5076202 ]], dtype=float32),\n",
       " array([[0.4972457 , 0.50275433],\n",
       "        [0.486882  , 0.51311797],\n",
       "        [0.48462474, 0.5153753 ],\n",
       "        ...,\n",
       "        [0.49142748, 0.50857246],\n",
       "        [0.48945978, 0.5105402 ],\n",
       "        [0.49445   , 0.50554997]], dtype=float32),\n",
       " array([[0.49465868, 0.5053413 ],\n",
       "        [0.4845433 , 0.51545674],\n",
       "        [0.48234016, 0.5176599 ],\n",
       "        ...,\n",
       "        [0.4889794 , 0.51102054],\n",
       "        [0.487059  , 0.512941  ],\n",
       "        [0.49192983, 0.50807023]], dtype=float32),\n",
       " array([[0.49458468, 0.5054153 ],\n",
       "        [0.48470524, 0.51529473],\n",
       "        [0.4825525 , 0.51744753],\n",
       "        ...,\n",
       "        [0.48903713, 0.51096284],\n",
       "        [0.4871616 , 0.5128384 ],\n",
       "        [0.49191874, 0.5080812 ]], dtype=float32),\n",
       " array([[0.49568868, 0.50431126],\n",
       "        [0.48603287, 0.5139671 ],\n",
       "        [0.4839283 , 0.51607174],\n",
       "        ...,\n",
       "        [0.49026656, 0.50973344],\n",
       "        [0.48843396, 0.51156604],\n",
       "        [0.49308345, 0.5069165 ]], dtype=float32),\n",
       " array([[0.49560693, 0.50439304],\n",
       "        [0.4861662 , 0.5138338 ],\n",
       "        [0.48410797, 0.515892  ],\n",
       "        ...,\n",
       "        [0.4903053 , 0.50969476],\n",
       "        [0.48851353, 0.5114865 ],\n",
       "        [0.49305916, 0.50694084]], dtype=float32),\n",
       " array([[0.49578065, 0.5042193 ],\n",
       "        [0.48654515, 0.51345485],\n",
       "        [0.48453137, 0.5154686 ],\n",
       "        ...,\n",
       "        [0.49059406, 0.5094059 ],\n",
       "        [0.48884094, 0.51115906],\n",
       "        [0.49328828, 0.50671166]], dtype=float32),\n",
       " array([[0.49613306, 0.503867  ],\n",
       "        [0.48709545, 0.5129046 ],\n",
       "        [0.48512408, 0.51487595],\n",
       "        ...,\n",
       "        [0.49105722, 0.5089428 ],\n",
       "        [0.48934126, 0.51065874],\n",
       "        [0.49369326, 0.5063067 ]], dtype=float32),\n",
       " array([[0.49649405, 0.50350595],\n",
       "        [0.48764434, 0.5123556 ],\n",
       "        [0.48571518, 0.51428485],\n",
       "        ...,\n",
       "        [0.49152356, 0.50847644],\n",
       "        [0.4898432 , 0.5101568 ],\n",
       "        [0.49410474, 0.50589526]], dtype=float32),\n",
       " array([[0.49602675, 0.50397325],\n",
       "        [0.4875574 , 0.5124426 ],\n",
       "        [0.48576766, 0.51423234],\n",
       "        ...,\n",
       "        [0.49128723, 0.5087128 ],\n",
       "        [0.4896377 , 0.51036227],\n",
       "        [0.49356812, 0.5064319 ]], dtype=float32),\n",
       " array([[0.49568054, 0.5043195 ],\n",
       "        [0.4873811 , 0.5126189 ],\n",
       "        [0.48562607, 0.5143739 ],\n",
       "        ...,\n",
       "        [0.49103624, 0.50896376],\n",
       "        [0.4894193 , 0.5105807 ],\n",
       "        [0.49327075, 0.50672925]], dtype=float32),\n",
       " array([[0.49658144, 0.50341856],\n",
       "        [0.48844504, 0.51155496],\n",
       "        [0.486724  , 0.513276  ],\n",
       "        ...,\n",
       "        [0.49202722, 0.5079728 ],\n",
       "        [0.49044245, 0.5095576 ],\n",
       "        [0.49421877, 0.5057813 ]], dtype=float32),\n",
       " array([[0.497023  , 0.502977  ],\n",
       "        [0.48904806, 0.51095194],\n",
       "        [0.48735842, 0.51264155],\n",
       "        ...,\n",
       "        [0.49255615, 0.50744385],\n",
       "        [0.49100316, 0.50899684],\n",
       "        [0.49470457, 0.5052954 ]], dtype=float32),\n",
       " array([[0.49548522, 0.50451475],\n",
       "        [0.4876501 , 0.5123499 ],\n",
       "        [0.48599023, 0.5140097 ],\n",
       "        ...,\n",
       "        [0.49110356, 0.5088964 ],\n",
       "        [0.48957095, 0.510429  ],\n",
       "        [0.49321392, 0.5067861 ]], dtype=float32),\n",
       " array([[0.49697503, 0.503025  ],\n",
       "        [0.48928636, 0.51071364],\n",
       "        [0.48765552, 0.5123445 ],\n",
       "        ...,\n",
       "        [0.4926746 , 0.5073254 ],\n",
       "        [0.4911701 , 0.5088299 ],\n",
       "        [0.4947461 , 0.5052539 ]], dtype=float32),\n",
       " array([[0.49658167, 0.5034183 ],\n",
       "        [0.4890302 , 0.5109698 ],\n",
       "        [0.48743752, 0.5125625 ],\n",
       "        ...,\n",
       "        [0.4923617 , 0.5076383 ],\n",
       "        [0.4908837 , 0.5091163 ],\n",
       "        [0.4943872 , 0.5056128 ]], dtype=float32),\n",
       " array([[0.49667624, 0.5033238 ],\n",
       "        [0.48926166, 0.5107383 ],\n",
       "        [0.48769668, 0.5123033 ],\n",
       "        ...,\n",
       "        [0.49253237, 0.5074677 ],\n",
       "        [0.49108052, 0.5089195 ],\n",
       "        [0.49452072, 0.5054792 ]], dtype=float32),\n",
       " array([[0.49640656, 0.50359344],\n",
       "        [0.48912677, 0.51087326],\n",
       "        [0.48759082, 0.5124092 ],\n",
       "        ...,\n",
       "        [0.49233457, 0.5076654 ],\n",
       "        [0.49091172, 0.5090883 ],\n",
       "        [0.49428743, 0.5057126 ]], dtype=float32),\n",
       " array([[0.49773195, 0.502268  ],\n",
       "        [0.49057505, 0.5094249 ],\n",
       "        [0.48906365, 0.5109363 ],\n",
       "        ...,\n",
       "        [0.49372965, 0.50627035],\n",
       "        [0.49233016, 0.50766987],\n",
       "        [0.4956491 , 0.5043509 ]], dtype=float32),\n",
       " array([[0.49655554, 0.50344443],\n",
       "        [0.48952174, 0.51047826],\n",
       "        [0.48803657, 0.5119634 ],\n",
       "        ...,\n",
       "        [0.49262154, 0.50737846],\n",
       "        [0.49124545, 0.50875455],\n",
       "        [0.49450612, 0.5054939 ]], dtype=float32),\n",
       " array([[0.49643716, 0.50356287],\n",
       "        [0.48952076, 0.5104793 ],\n",
       "        [0.48806068, 0.51193935],\n",
       "        ...,\n",
       "        [0.49256852, 0.5074315 ],\n",
       "        [0.49121583, 0.5087842 ],\n",
       "        [0.49442187, 0.50557816]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in boosted_classifier.staged_predict_proba(X_test)]\n",
    "len(a[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = [i for i in boosted_classifier.staged_predict(X_test)]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7637540453074434,\n",
       " 0.7650485436893204,\n",
       " 0.7624595469255664,\n",
       " 0.7637540453074434,\n",
       " 0.7637540453074434,\n",
       " 0.7631067961165049,\n",
       " 0.7631067961165049,\n",
       " 0.7644012944983819,\n",
       " 0.7637540453074434,\n",
       " 0.7624595469255664,\n",
       " 0.7572815533980582,\n",
       " 0.7618122977346279,\n",
       " 0.7618122977346279,\n",
       " 0.7611650485436893,\n",
       " 0.7585760517799353,\n",
       " 0.7598705501618123,\n",
       " 0.7637540453074434,\n",
       " 0.7579288025889968,\n",
       " 0.7618122977346279,\n",
       " 0.7585760517799353,\n",
       " 0.7585760517799353,\n",
       " 0.7611650485436893,\n",
       " 0.7592233009708738,\n",
       " 0.7579288025889968,\n",
       " 0.7592233009708738,\n",
       " 0.7618122977346279,\n",
       " 0.7592233009708738,\n",
       " 0.7598705501618123,\n",
       " 0.7579288025889968,\n",
       " 0.7624595469255664,\n",
       " 0.7579288025889968,\n",
       " 0.7618122977346279,\n",
       " 0.7579288025889968,\n",
       " 0.7618122977346279,\n",
       " 0.7585760517799353,\n",
       " 0.7585760517799353,\n",
       " 0.7592233009708738,\n",
       " 0.7579288025889968,\n",
       " 0.7631067961165049,\n",
       " 0.7592233009708738,\n",
       " 0.7579288025889968,\n",
       " 0.7572815533980582,\n",
       " 0.7572815533980582,\n",
       " 0.7598705501618123,\n",
       " 0.7598705501618123,\n",
       " 0.7598705501618123,\n",
       " 0.7611650485436893,\n",
       " 0.7618122977346279,\n",
       " 0.7611650485436893,\n",
       " 0.7579288025889968,\n",
       " 0.7611650485436893,\n",
       " 0.7624595469255664,\n",
       " 0.7566343042071197,\n",
       " 0.7618122977346279,\n",
       " 0.7598705501618123,\n",
       " 0.7592233009708738,\n",
       " 0.7592233009708738,\n",
       " 0.7598705501618123,\n",
       " 0.7592233009708738,\n",
       " 0.7579288025889968]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = [accuracy_score(y_test,i) for i in boosted_classifier.staged_predict(X_test)]\n",
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .fit(new_x, new_y) : Adaboost accuracy : 0.7501618122977346, precision : 0.7742914979757085, recall : 0.8243534482758621, f1 : 0.7985386221294364, roc_auc : 0.7314635960990331\n",
    "- .fit(new_x, new_y, **kwargs) : accuracy : 0.7430420711974111, precision : 0.7734294541709578, recall : 0.8092672413793104, f1 : 0.7909426013691417, roc_auc : 0.7263516109651819\n",
    "- .fit(new_x, new_y, sample_weight=sample_weight) : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7430420711974111, precision : 0.7734294541709578, recall : 0.8092672413793104, f1 : 0.7909426013691417, roc_auc : 0.7263516109651819\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = boosted_classifier.predict(X_test)\n",
    "\n",
    "y_pred_test[y_pred_test>0.5]=1\n",
    "y_pred_test[y_pred_test<=0.5]=0\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4fc3a096-2c5e-42aa-8ed7-0d35dd718c6c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f891f3f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f881728e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f803f70a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f803f0760> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3f4d161d-ae84-45e1-b949-b9e25640463a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3f4d161d-ae84-45e1-b949-b9e25640463a/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1df849c0a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1df83455e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd4262df0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd4264610> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://aea38500-abca-43c1-9f03-3d652beb35d0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://aea38500-abca-43c1-9f03-3d652beb35d0/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d987c3f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d7809a6a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd425cf10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d9871ba60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d8af8a47-726a-41d3-be0d-0593228ced6d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d8af8a47-726a-41d3-be0d-0593228ced6d/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d147e3ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d146eb7c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d14692280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d1469e8e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f103218e-4d08-43a8-b7ad-52bd21b3ac7f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f103218e-4d08-43a8-b7ad-52bd21b3ac7f/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc6d7070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc6d7820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc69d2e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc662af0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d990fedd-2b25-49b4-969d-be78df877613/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d990fedd-2b25-49b4-969d-be78df877613/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c9878d880> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98698340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98665220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98629310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6789a93-f575-469c-93b0-687ba122780c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6789a93-f575-469c-93b0-687ba122780c/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c6867d940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c685861c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c6855b520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c68518370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a414dbcf-accd-4e11-a6f7-61ffa027a2fe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a414dbcf-accd-4e11-a6f7-61ffa027a2fe/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c1071c9a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c10624520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c105ca190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c105cffa0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://878dedc5-d1ab-447a-9325-76d09d8e4c61/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://878dedc5-d1ab-447a-9325-76d09d8e4c61/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd060d940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd05191c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd04bab20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd05195e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9d9a03cd-e0f8-48d3-83b3-5dc29a0c49b3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9d9a03cd-e0f8-48d3-83b3-5dc29a0c49b3/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd0556b80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b76216700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b7617c850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b7612b430> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4b6df1-1710-4b94-b145-4df49eb2c1df/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4b6df1-1710-4b94-b145-4df49eb2c1df/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b4421a9d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b44123370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b4412ae50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b440b53d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6882bb5a-c30f-45d5-a61f-6f5376d4b070/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6882bb5a-c30f-45d5-a61f-6f5376d4b070/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0410a220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0410ab80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ae47dd460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0415ec10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://928e318e-066e-448b-b9e4-fa49130710d1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://928e318e-066e-448b-b9e4-fa49130710d1/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc21b340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc21b160> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc12ea00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc0b82e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2dec7e68-30b3-412b-8dc2-4baace97d62b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2dec7e68-30b3-412b-8dc2-4baace97d62b/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c10daf0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c7d82e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c7d8b20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c741ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d6187611-ec92-4789-a080-27933b012dcc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d6187611-ec92-4789-a080-27933b012dcc/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a4403ef40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c0a1820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c081940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a24730ee0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://499bb4db-f428-4561-bc88-a98f49c11e17/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://499bb4db-f428-4561-bc88-a98f49c11e17/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a08115400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a08115190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19e47e5e50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19e476b490> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12e1fa1c-0401-497a-90da-48a9b4f0b715/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12e1fa1c-0401-497a-90da-48a9b4f0b715/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac7c1bb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac6c9550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac6f2cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac694130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://94288a7f-24f6-4f72-9a74-76d071b01a68/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://94288a7f-24f6-4f72-9a74-76d071b01a68/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac70b370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac70b100> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac7783a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f197c53eeb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://53037386-12b4-4385-b5cb-98f69aed3181/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://53037386-12b4-4385-b5cb-98f69aed3181/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac724fa0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f33ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f197c68e9a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924eb8a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://56c8a39b-d555-4124-a103-af0a24f06b89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://56c8a39b-d555-4124-a103-af0a24f06b89/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f74430> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f741c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1915f02eb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1915e80040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "joblib.dump(boosted_classifier, './models/adaboost_lstm.pkl') \n",
    "reload_model = joblib.load('./models/adaboost_lstm.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.14671701, 0.853283  ],\n",
       "        [0.15134184, 0.84865814],\n",
       "        [0.09548907, 0.9045109 ],\n",
       "        ...,\n",
       "        [0.12648392, 0.8735161 ],\n",
       "        [0.10223823, 0.89776176],\n",
       "        [0.23039924, 0.76960075]], dtype=float32),\n",
       " array([[0.8154902 , 0.18450987],\n",
       "        [0.8216686 , 0.17833138],\n",
       "        [0.0754172 , 0.9245828 ],\n",
       "        ...,\n",
       "        [0.20071441, 0.7992856 ],\n",
       "        [0.06067883, 0.9393212 ],\n",
       "        [0.0725329 , 0.9274671 ]], dtype=float32),\n",
       " array([[0.34155625, 0.6584438 ],\n",
       "        [0.34451336, 0.6554866 ],\n",
       "        [0.03459236, 0.9654076 ],\n",
       "        ...,\n",
       "        [0.08024294, 0.919757  ],\n",
       "        [0.04676704, 0.95323294],\n",
       "        [0.12316583, 0.8768342 ]], dtype=float32),\n",
       " array([[0.5092239 , 0.49077615],\n",
       "        [0.60728794, 0.3927121 ],\n",
       "        [0.16986866, 0.8301313 ],\n",
       "        ...,\n",
       "        [0.2854696 , 0.7145304 ],\n",
       "        [0.20876725, 0.79123276],\n",
       "        [0.24563938, 0.7543606 ]], dtype=float32),\n",
       " array([[0.53762466, 0.46237534],\n",
       "        [0.3876752 , 0.61232483],\n",
       "        [0.31962258, 0.6803774 ],\n",
       "        ...,\n",
       "        [0.1786738 , 0.8213262 ],\n",
       "        [0.13316381, 0.8668362 ],\n",
       "        [0.25848332, 0.74151665]], dtype=float32),\n",
       " array([[0.6718085 , 0.32819152],\n",
       "        [0.5533874 , 0.44661257],\n",
       "        [0.4907666 , 0.5092334 ],\n",
       "        ...,\n",
       "        [0.33372712, 0.66627294],\n",
       "        [0.27552   , 0.72448003],\n",
       "        [0.27862334, 0.72137666]], dtype=float32),\n",
       " array([[0.6895289 , 0.3104711 ],\n",
       "        [0.532257  , 0.46774295],\n",
       "        [0.35844734, 0.6415527 ],\n",
       "        ...,\n",
       "        [0.41690388, 0.5830961 ],\n",
       "        [0.22477764, 0.77522236],\n",
       "        [0.33066702, 0.669333  ]], dtype=float32),\n",
       " array([[0.781638  , 0.218362  ],\n",
       "        [0.35055503, 0.649445  ],\n",
       "        [0.2350894 , 0.76491064],\n",
       "        ...,\n",
       "        [0.27061033, 0.72938967],\n",
       "        [0.38543686, 0.61456317],\n",
       "        [0.39992878, 0.6000712 ]], dtype=float32),\n",
       " array([[0.6388767 , 0.3611233 ],\n",
       "        [0.50825036, 0.49174964],\n",
       "        [0.1569146 , 0.8430854 ],\n",
       "        ...,\n",
       "        [0.42381823, 0.57618177],\n",
       "        [0.26027748, 0.73972255],\n",
       "        [0.47262856, 0.52737147]], dtype=float32),\n",
       " array([[0.7226777 , 0.2773223 ],\n",
       "        [0.5956339 , 0.40436608],\n",
       "        [0.27807134, 0.72192866],\n",
       "        ...,\n",
       "        [0.33660552, 0.6633945 ],\n",
       "        [0.20430657, 0.7956934 ],\n",
       "        [0.37866393, 0.62133604]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in boosted_classifier.staged_predict_proba(X_test)]\n",
    "len(a[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7682847896440129,\n",
       " 0.6220064724919094,\n",
       " 0.7592233009708738,\n",
       " 0.6517799352750809,\n",
       " 0.7391585760517799,\n",
       " 0.6660194174757281,\n",
       " 0.7249190938511327,\n",
       " 0.6724919093851133,\n",
       " 0.7171521035598706,\n",
       " 0.6964401294498382]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(y_test,i) for i in boosted_classifier.staged_predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13636364, 0.18618371, 0.77088202, 0.80480714, 0.13529329])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.MyKerasClassifier at 0x7f46dd507910>,\n",
       " <__main__.MyKerasClassifier at 0x7f4773ba2760>,\n",
       " <__main__.MyKerasClassifier at 0x7f4758831640>,\n",
       " <__main__.MyKerasClassifier at 0x7f475b6ee2b0>,\n",
       " <__main__.MyKerasClassifier at 0x7f473e39f100>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19136202, 0.19596451, 0.16152457, 0.14712343, 0.16450197])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
